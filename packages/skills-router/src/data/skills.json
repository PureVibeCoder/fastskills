[
  {
    "id": "skill-from-masters",
    "name": "skill-from-masters",
    "description": "Help users create high-quality skills by discovering and incorporating proven methodologies from domain experts. Use this skill BEFORE skill-creator when users want to create a new skill - it enhances skill-creator by first identifying expert frameworks and best practices to incorporate. Triggers on",
    "category": "skill-dev",
    "source": "unknown",
    "triggers": [
      "masters",
      "skill-creator",
      "users",
      "high-quality",
      "discovering",
      "incorporating",
      "proven",
      "methodologies",
      "domain",
      "experts"
    ],
    "path": "/Users/marovole/GitHub/fastskills/skill-from-masters/skill-from-masters",
    "fullDescription": "\n# Skill From Masters\n\nCreate skills that embody the wisdom of domain masters. This skill helps users discover and incorporate proven methodologies from recognized experts before generating a skill.\n\n## Core Philosophy\n\nMost professional domains have outstanding practitioners who have codified their methods through books, talks, interviews, and frameworks. A skill built on these proven methodologies is far more valuable than one created from scratch.\n\n## Workflow\n\n### Step 1: Understand the Skill Intent\n\nAsk the user:\n- What skill do they want to create?\n- What specific tasks should it handle?\n- What quality bar are they aiming for?\n\n### Step 2: Identify Relevant Domains\n\nMap the skill to one or more methodology domains. A single skill may span multiple domains.\n\nExample mappings:\n- \"Sales email skill\" â†’ Sales, Writing, Persuasion\n- \"User interview skill\" â†’ User Research, Interviewing, Product Discovery\n- \"Presentation skill\" â†’ Storytelling, Visual Design, Persuasion\n- \"Code review skill\" â†’ Software Engineering, Feedback, Communication\n\n### Step 3: Surface Expert Methodologies\n\nConsult `references/methodology-database.md` for known frameworks. For each relevant domain, present:\n- Key experts and their core contributions\n- Specific frameworks, principles, or processes\n- Source materials (books, talks, interviews)\n\nIf the domain isn't covered in the database, search the web to find recognized experts and their methodologies.\n\n### Step 4: Collaborative Selection\n\nPresent the methodologies to the user and discuss:\n- Which frameworks resonate with their goals?\n- Are there conflicts between methodologies to resolve?\n- Should they combine multiple approaches?\n- Any specific principles they want to emphasize or exclude?\n\nGuide the user to select 1-3 primary methodologies that will form the skill's foundation.\n\n### Step 5: Extract Actionable Principles\n\nFor each selected methodology, distill:\n- Core principles (the \"why\")\n- Concrete steps or processes (the \"how\")\n- Quality c"
  },
  {
    "id": "planning-with-files",
    "name": "planning-with-files",
    "description": "Transforms workflow to use Manus-style persistent markdown files for planning, progress tracking, and knowledge storage. Use when starting complex tasks, multi-step projects, research tasks, or when the user mentions planning, organizing work, tracking progress, or wants structured output.",
    "category": "scientific",
    "source": "unknown",
    "triggers": [
      "planning",
      "progress",
      "tracking",
      "tasks",
      "transforms",
      "workflow",
      "manus-style",
      "persistent",
      "markdown",
      "knowledge"
    ],
    "path": "/Users/marovole/GitHub/fastskills/planning-with-files/planning-with-files",
    "fullDescription": "\n# Planning with Files\n\nWork like Manus: Use persistent markdown files as your \"working memory on disk.\"\n\n## Quick Start\n\nBefore ANY complex task:\n\n1. **Create `task_plan.md`** in the working directory\n2. **Define phases** with checkboxes\n3. **Update after each phase** - mark [x] and change status\n4. **Read before deciding** - refresh goals in attention window\n\n## The 3-File Pattern\n\nFor every non-trivial task, create THREE files:\n\n| File | Purpose | When to Update |\n|------|---------|----------------|\n| `task_plan.md` | Track phases and progress | After each phase |\n| `notes.md` | Store findings and research | During research |\n| `[deliverable].md` | Final output | At completion |\n\n## Core Workflow\n\n```\nLoop 1: Create task_plan.md with goal and phases\nLoop 2: Research â†’ save to notes.md â†’ update task_plan.md\nLoop 3: Read notes.md â†’ create deliverable â†’ update task_plan.md\nLoop 4: Deliver final output\n```\n\n### The Loop in Detail\n\n**Before each major action:**\n```bash\nRead task_plan.md  # Refresh goals in attention window\n```\n\n**After each phase:**\n```bash\nEdit task_plan.md  # Mark [x], update status\n```\n\n**When storing information:**\n```bash\nWrite notes.md     # Don't stuff context, store in file\n```\n\n## task_plan.md Template\n\nCreate this file FIRST for any complex task:\n\n```markdown\n# Task Plan: [Brief Description]\n\n## Goal\n[One sentence describing the end state]\n\n## Phases\n- [ ] Phase 1: Plan and setup\n- [ ] Phase 2: Research/gather information\n- [ ] Phase 3: Execute/build\n- [ ] Phase 4: Review and deliver\n\n## Key Questions\n1. [Question to answer]\n2. [Question to answer]\n\n## Decisions Made\n- [Decision]: [Rationale]\n\n## Errors Encountered\n- [Error]: [Resolution]\n\n## Status\n**Currently in Phase X** - [What I'm doing now]\n```\n\n## notes.md Template\n\nFor research and findings:\n\n```markdown\n# Notes: [Topic]\n\n## Sources\n\n### Source 1: [Name]\n- URL: [link]\n- Key points:\n  - [Finding]\n  - [Finding]\n\n## Synthesized Findings\n\n### [Category]\n- [Finding]\n- [Finding]\n```\n\n## Cr"
  },
  {
    "id": "webapp-testing",
    "name": "webapp-testing",
    "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
    "category": "frontend",
    "source": "composio",
    "triggers": [
      "webapp",
      "testing",
      "browser",
      "interacting",
      "local",
      "web",
      "applications",
      "playwright",
      "verifying",
      "frontend"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/webapp-testing",
    "fullDescription": "\n# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task â†’ Is it static HTML?\n    â”œâ”€ Yes â†’ Read HTML file directly to identify selectors\n    â”‚         â”œâ”€ Success â†’ Write Playwright script using selectors\n    â”‚         â””â”€ Fails/Incomplete â†’ Treat as dynamic (below)\n    â”‚\n    â””â”€ No (dynamic webapp) â†’ Is the server already running?\n        â”œâ”€ No â†’ Run: python scripts/with_server.py --help\n        â”‚        Then use the helper + write simplified Playwright script\n        â”‚\n        â””â”€ Yes â†’ Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch"
  },
  {
    "id": "youtube-downloader",
    "name": "youtube-downloader",
    "description": "Download YouTube videos with customizable quality and format options. Use this skill when the user asks to download, save, or grab YouTube videos. Supports various quality settings (best, 1080p, 720p, 480p, 360p), multiple formats (mp4, webm, mkv), and audio-only downloads as MP3.",
    "category": "media",
    "source": "composio",
    "triggers": [
      "youtube",
      "downloader",
      "download",
      "videos",
      "quality",
      "customizable",
      "format",
      "options",
      "user",
      "asks"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/video-downloader",
    "fullDescription": "\n# YouTube Video Downloader\n\nDownload YouTube videos with full control over quality and format settings.\n\n## Quick Start\n\nThe simplest way to download a video:\n\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=VIDEO_ID\"\n```\n\nThis downloads the video in best available quality as MP4 to `/mnt/user-data/outputs/`.\n\n## Options\n\n### Quality Settings\n\nUse `-q` or `--quality` to specify video quality:\n\n- `best` (default): Highest quality available\n- `1080p`: Full HD\n- `720p`: HD\n- `480p`: Standard definition\n- `360p`: Lower quality\n- `worst`: Lowest quality available\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -q 720p\n```\n\n### Format Options\n\nUse `-f` or `--format` to specify output format (video downloads only):\n\n- `mp4` (default): Most compatible\n- `webm`: Modern format\n- `mkv`: Matroska container\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -f webm\n```\n\n### Audio Only\n\nUse `-a` or `--audio-only` to download only audio as MP3:\n\n```bash\npython scripts/download_video.py \"URL\" -a\n```\n\n### Custom Output Directory\n\nUse `-o` or `--output` to specify a different output directory:\n\n```bash\npython scripts/download_video.py \"URL\" -o /path/to/directory\n```\n\n## Complete Examples\n\n1. Download video in 1080p as MP4:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 1080p\n```\n\n2. Download audio only as MP3:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -a\n```\n\n3. Download in 720p as WebM to custom directory:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 720p -f webm -o /custom/path\n```\n\n## How It Works\n\nThe skill uses `yt-dlp`, a robust YouTube downloader that:\n- Automatically installs itself if not present\n- Fetches video information before downloading\n- Selects the best available streams matching your criteria\n- Merges video and audio streams when needed\n- Supports a wide range of YouTube video formats\n\n## Impor"
  },
  {
    "id": "theme-factory",
    "name": "theme-factory",
    "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
    "category": "frontend",
    "source": "composio",
    "triggers": [
      "theme",
      "factory",
      "artifacts",
      "styling",
      "slides",
      "docs",
      "reportings",
      "html",
      "landing",
      "pages"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/theme-factory",
    "fullDescription": "\n\n# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts an"
  },
  {
    "id": "template-skill",
    "name": "template-skill",
    "description": "Replace with description of the skill and when Claude should use it.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "template",
      "replace",
      "description",
      "claude",
      "template-skill"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/template-skill",
    "fullDescription": "\n# Insert instructions below\n"
  },
  {
    "id": "slack-gif-creator",
    "name": "slack-gif-creator",
    "description": "Toolkit for creating animated GIFs optimized for Slack, with validators for size constraints and composable animation primitives. This skill applies when users request animated GIFs or emoji animations for Slack from descriptions like \"make me a GIF for Slack of X doing Y\".",
    "category": "media",
    "source": "composio",
    "triggers": [
      "slack",
      "gif",
      "creator",
      "animated",
      "gifs",
      "optimized",
      "validators",
      "size",
      "constraints",
      "composable"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/slack-gif-creator",
    "fullDescription": "\n# Slack GIF Creator - Flexible Toolkit\n\nA toolkit for creating animated GIFs optimized for Slack. Provides validators for Slack's constraints, composable animation primitives, and optional helper utilities. **Apply these tools however needed to achieve the creative vision.**\n\n## Slack's Requirements\n\nSlack has specific requirements for GIFs based on their use:\n\n**Message GIFs:**\n- Max size: ~2MB\n- Optimal dimensions: 480x480\n- Typical FPS: 15-20\n- Color limit: 128-256\n- Duration: 2-5s\n\n**Emoji GIFs:**\n- Max size: 64KB (strict limit)\n- Optimal dimensions: 128x128\n- Typical FPS: 10-12\n- Color limit: 32-48\n- Duration: 1-2s\n\n**Emoji GIFs are challenging** - the 64KB limit is strict. Strategies that help:\n- Limit to 10-15 frames total\n- Use 32-48 colors maximum\n- Keep designs simple\n- Avoid gradients\n- Validate file size frequently\n\n## Toolkit Structure\n\nThis skill provides three types of tools:\n\n1. **Validators** - Check if a GIF meets Slack's requirements\n2. **Animation Primitives** - Composable building blocks for motion (shake, bounce, move, kaleidoscope)\n3. **Helper Utilities** - Optional functions for common needs (text, colors, effects)\n\n**Complete creative freedom is available in how these tools are applied.**\n\n## Core Validators\n\nTo ensure a GIF meets Slack's constraints, use these validators:\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# After creating your GIF, check if it meets requirements\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n# ... add your frames however you want ...\n\n# Save and check size\ninfo = builder.save('emoji.gif', num_colors=48, optimize_for_emoji=True)\n\n# The save method automatically warns if file exceeds limits\n# info dict contains: size_kb, size_mb, frame_count, duration_seconds\n```\n\n**File size validator**:\n```python\nfrom core.validators import check_slack_size\n\n# Check if GIF meets size limits\npasses, info = check_slack_size('emoji.gif', is_emoji=True)\n# Returns: (True/False, dict with size details)\n```\n\n**Dimension val"
  },
  {
    "id": "skill-share",
    "name": "skill-share",
    "description": "A skill that creates new Claude skills and automatically shares them on Slack using Rube for seamless team collaboration and skill discovery.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "share",
      "creates",
      "claude",
      "automatically",
      "shares",
      "slack",
      "rube",
      "seamless",
      "team",
      "collaboration"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/skill-share",
    "fullDescription": "\n## When to use this skill\n\nUse this skill when you need to:\n- **Create new Claude skills** with proper structure and metadata\n- **Generate skill packages** ready for distribution\n- **Automatically share created skills** on Slack channels for team visibility\n- **Validate skill structure** before sharing\n- **Package and distribute** skills to your team\n\nAlso use this skill when:\n- **User says he wants to create/share his skill** \n\nThis skill is ideal for:\n- Creating skills as part of team workflows\n- Building internal tools that need skill creation + team notification\n- Automating the skill development pipeline\n- Collaborative skill creation with team notifications\n\n## Key Features\n\n### 1. Skill Creation\n- Creates properly structured skill directories with SKILL.md\n- Generates standardized scripts/, references/, and assets/ directories\n- Auto-generates YAML frontmatter with required metadata\n- Enforces naming conventions (hyphen-case)\n\n### 2. Skill Validation\n- Validates SKILL.md format and required fields\n- Checks naming conventions\n- Ensures metadata completeness before packaging\n\n### 3. Skill Packaging\n- Creates distributable zip files\n- Includes all skill assets and documentation\n- Runs validation automatically before packaging\n\n### 4. Slack Integration via Rube\n- Automatically sends created skill information to designated Slack channels\n- Shares skill metadata (name, description, link)\n- Posts skill summary for team discovery\n- Provides direct links to skill files\n\n## How It Works\n\n1. **Initialization**: Provide skill name and description\n2. **Creation**: Skill directory is created with proper structure\n3. **Validation**: Skill metadata is validated for correctness\n4. **Packaging**: Skill is packaged into a distributable format\n5. **Slack Notification**: Skill details are posted to your team's Slack channel\n\n## Example Usage\n\n```\nWhen you ask Claude to create a skill called \"pdf-analyzer\":\n1. Creates /skill-pdf-analyzer/ with SKILL.md template\n2. Generates struc"
  },
  {
    "id": "mcp-builder",
    "name": "mcp-builder",
    "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
    "category": "ml-ai",
    "source": "composio",
    "triggers": [
      "mcp",
      "builder",
      "servers",
      "external",
      "services",
      "high-quality",
      "model",
      "context",
      "protocol",
      "enable"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/mcp-builder",
    "fullDescription": "\n# MCP Server Development Guide\n\n## Overview\n\nTo create high-quality MCP (Model Context Protocol) servers that enable LLMs to effectively interact with external services, use this skill. An MCP server provides tools that allow LLMs to access external services and APIs. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks using the tools provided.\n\n---\n\n# Process\n\n## ðŸš€ High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Agent-Centric Design Principles\n\nBefore diving into implementation, understand how to design tools for AI agents by reviewing these principles:\n\n**Build for Workflows, Not Just API Endpoints:**\n- Don't simply wrap existing API endpoints - build thoughtful, high-impact workflow tools\n- Consolidate related operations (e.g., `schedule_event` that both checks availability and creates event)\n- Focus on tools that enable complete tasks, not just individual API calls\n- Consider what workflows agents actually need to accomplish\n\n**Optimize for Limited Context:**\n- Agents have constrained context windows - make every token count\n- Return high-signal information, not exhaustive data dumps\n- Provide \"concise\" vs \"detailed\" response format options\n- Default to human-readable identifiers over technical codes (names over IDs)\n- Consider the agent's context budget as a scarce resource\n\n**Design Actionable Error Messages:**\n- Error messages should guide agents toward correct usage patterns\n- Suggest specific next steps: \"Try using filter='active_only' to reduce results\"\n- Make errors educational, not just diagnostic\n- Help agents learn proper tool usage through clear feedback\n\n**Follow Natural Task Subdivisions:**\n- Tool names should reflect how humans think about tasks\n- Group related tools with consistent prefixes for discoverability\n- Design tools around natural workflows, not just API structure\n\n**Use Evaluation-Driven Devel"
  },
  {
    "id": "skill-creator",
    "name": "skill-creator",
    "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
    "category": "knowledge",
    "source": "composio",
    "triggers": [
      "creator",
      "effective",
      "users",
      "update",
      "existing",
      "extends",
      "claude",
      "capabilities",
      "specialized",
      "knowledge"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/skill-creator",
    "fullDescription": "\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n"
  },
  {
    "id": "raffle-winner-picker",
    "name": "raffle-winner-picker",
    "description": "Picks random winners from lists, spreadsheets, or Google Sheets for giveaways, raffles, and contests. Ensures fair, unbiased selection with transparency.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "raffle",
      "winner",
      "picker",
      "picks",
      "random",
      "winners",
      "lists",
      "spreadsheets",
      "google",
      "sheets"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/raffle-winner-picker",
    "fullDescription": "\n# Raffle Winner Picker\n\nThis skill randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests.\n\n## When to Use This Skill\n\n- Running social media giveaways\n- Picking raffle winners at events\n- Randomly selecting participants for surveys or tests\n- Choosing winners from contest submissions\n- Fair distribution of limited spots or resources\n- Random team assignments\n\n## What This Skill Does\n\n1. **Random Selection**: Uses cryptographically random selection\n2. **Multiple Sources**: Works with CSV, Excel, Google Sheets, or plain lists\n3. **Multiple Winners**: Can pick one or multiple winners\n4. **Duplicate Prevention**: Ensures the same person can't win twice\n5. **Transparent Results**: Shows the selection process clearly\n6. **Winner Details**: Displays all relevant information about winners\n\n## How to Use\n\n### From Google Sheets\n\n```\nPick a random row from this Google Sheet to select a winner \nfor a giveaway: [Sheet URL]\n```\n\n### From Local File\n\n```\nPick 3 random winners from entries.csv\n```\n\n### From List\n\n```\nPick a random winner from this list:\n- Alice (alice@email.com)\n- Bob (bob@email.com)\n- Carol (carol@email.com)\n...\n```\n\n### Multiple Winners\n\n```\nPick 5 random winners from contest-entries.xlsx, \nmake sure no duplicates\n```\n\n## Example\n\n**User**: \"Pick a random row from this Google Sheet to select a winner for a giveaway.\"\n\n**Output**:\n```\nAccessing Google Sheet...\nTotal entries found: 247\n\nRandomly selecting winner...\n\nðŸŽ‰ WINNER SELECTED! ðŸŽ‰\n\nRow #142\nName: Sarah Johnson\nEmail: sarah.j@email.com\nEntry Date: March 10, 2024\nComment: \"Love your newsletter!\"\n\nSelection method: Cryptographically random\nTimestamp: 2024-03-15 14:32:18 UTC\n\nWould you like to:\n- Pick another winner (excluding Sarah)?\n- Export winner details?\n- Pick runner-ups?\n```\n\n**Inspired by:** Lenny's use case - picking a Sora 2 giveaway winner from his subscriber Slack community\n\n## Features\n\n### Fair Selection\n- Uses secure random number generation\n- No bias or"
  },
  {
    "id": "meeting-insights-analyzer",
    "name": "meeting-insights-analyzer",
    "description": "Analyzes meeting transcripts and recordings to uncover behavioral patterns, communication insights, and actionable feedback. Identifies when you avoid conflict, use filler words, dominate conversations, or miss opportunities to listen. Perfect for professionals seeking to improve their communication",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "meeting",
      "insights",
      "analyzer",
      "communication",
      "analyzes",
      "transcripts",
      "recordings",
      "uncover",
      "behavioral",
      "patterns"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/meeting-insights-analyzer",
    "fullDescription": "\n# Meeting Insights Analyzer\n\nThis skill transforms your meeting transcripts into actionable insights about your communication patterns, helping you become a more effective communicator and leader.\n\n## When to Use This Skill\n\n- Analyzing your communication patterns across multiple meetings\n- Getting feedback on your leadership and facilitation style\n- Identifying when you avoid difficult conversations\n- Understanding your speaking habits and filler words\n- Tracking improvement in communication skills over time\n- Preparing for performance reviews with concrete examples\n- Coaching team members on their communication style\n\n## What This Skill Does\n\n1. **Pattern Recognition**: Identifies recurring behaviors across meetings like:\n   - Conflict avoidance or indirect communication\n   - Speaking ratios and turn-taking\n   - Question-asking vs. statement-making patterns\n   - Active listening indicators\n   - Decision-making approaches\n\n2. **Communication Analysis**: Evaluates communication effectiveness:\n   - Clarity and directness\n   - Use of filler words and hedging language\n   - Tone and sentiment patterns\n   - Meeting control and facilitation\n\n3. **Actionable Feedback**: Provides specific, timestamped examples with:\n   - What happened\n   - Why it matters\n   - How to improve\n\n4. **Trend Tracking**: Compares patterns over time when analyzing multiple meetings\n\n## How to Use\n\n### Basic Setup\n\n1. Download your meeting transcripts to a folder (e.g., `~/meetings/`)\n2. Navigate to that folder in Claude Code\n3. Ask for the analysis you want\n\n### Quick Start Examples\n\n```\nAnalyze all meetings in this folder and tell me when I avoided conflict.\n```\n\n```\nLook at my meetings from the past month and identify my communication patterns.\n```\n\n```\nCompare my facilitation style between these two meeting folders.\n```\n\n### Advanced Analysis\n\n```\nAnalyze all transcripts in this folder and:\n1. Identify when I interrupted others\n2. Calculate my speaking ratio\n3. Find moments I avoided giving dir"
  },
  {
    "id": "lead-research-assistant",
    "name": "lead-research-assistant",
    "description": "Identifies high-quality leads for your product or service by analyzing your business, searching for target companies, and providing actionable contact strategies. Perfect for sales, business development, and marketing professionals.",
    "category": "scientific",
    "source": "composio",
    "triggers": [
      "lead",
      "assistant",
      "business",
      "identifies",
      "high-quality",
      "leads",
      "product",
      "service",
      "analyzing",
      "searching"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/lead-research-assistant",
    "fullDescription": "\n# Lead Research Assistant\n\nThis skill helps you identify and qualify potential leads for your business by analyzing your product/service, understanding your ideal customer profile, and providing actionable outreach strategies.\n\n## When to Use This Skill\n\n- Finding potential customers or clients for your product/service\n- Building a list of companies to reach out to for partnerships\n- Identifying target accounts for sales outreach\n- Researching companies that match your ideal customer profile\n- Preparing for business development activities\n\n## What This Skill Does\n\n1. **Understands Your Business**: Analyzes your product/service, value proposition, and target market\n2. **Identifies Target Companies**: Finds companies that match your ideal customer profile based on:\n   - Industry and sector\n   - Company size and location\n   - Technology stack and tools they use\n   - Growth stage and funding\n   - Pain points your product solves\n3. **Prioritizes Leads**: Ranks companies based on fit score and relevance\n4. **Provides Contact Strategies**: Suggests how to approach each lead with personalized messaging\n5. **Enriches Data**: Gathers relevant information about decision-makers and company context\n\n## How to Use\n\n### Basic Usage\n\nSimply describe your product/service and what you're looking for:\n\n```\nI'm building [product description]. Find me 10 companies in [location/industry] \nthat would be good leads for this.\n```\n\n### With Your Codebase\n\nFor even better results, run this from your product's source code directory:\n\n```\nLook at what I'm building in this repository and identify the top 10 companies \nin [location/industry] that would benefit from this product.\n```\n\n### Advanced Usage\n\nFor more targeted research:\n\n```\nMy product: [description]\nIdeal customer profile:\n- Industry: [industry]\n- Company size: [size range]\n- Location: [location]\n- Current pain points: [pain points]\n- Technologies they use: [tech stack]\n\nFind me 20 qualified leads with contact strategies for each.\n``"
  },
  {
    "id": "invoice-organizer",
    "name": "invoice-organizer",
    "description": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "invoice",
      "organizer",
      "automatically",
      "organizes",
      "invoices",
      "receipts",
      "tax",
      "preparation",
      "reading",
      "messy"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/invoice-organizer",
    "fullDescription": "\n# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, "
  },
  {
    "id": "internal-comms",
    "name": "internal-comms",
    "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident rep",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "internal",
      "comms",
      "updates",
      "write",
      "communications",
      "company",
      "reports",
      "resources",
      "kinds",
      "formats"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/internal-comms",
    "fullDescription": "\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n"
  },
  {
    "id": "image-enhancer",
    "name": "image-enhancer",
    "description": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
    "category": "media",
    "source": "composio",
    "triggers": [
      "image",
      "enhancer",
      "images",
      "improves",
      "quality",
      "especially",
      "screenshots",
      "enhancing",
      "resolution",
      "sharpness"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/image-enhancer",
    "fullDescription": "\n# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look betterâ€”sharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\nâœ“ Upscaled to 2560x1440 (retina)\nâœ“ Sharpened edges\nâœ“ Enhanced text clarity\nâœ“ Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n"
  },
  {
    "id": "file-organizer",
    "name": "file-organizer",
    "description": "Intelligently organizes your files and folders across your computer by understanding context, finding duplicates, suggesting better structures, and automating cleanup tasks. Reduces cognitive load and keeps your digital workspace tidy without manual effort.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "file",
      "organizer",
      "intelligently",
      "organizes",
      "folders",
      "across",
      "computer",
      "understanding",
      "context",
      "finding"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/file-organizer",
    "fullDescription": "\n# File Organizer\n\nThis skill acts as your personal organization assistant, helping you maintain a clean, logical file structure across your computer without the mental overhead of constant manual organization.\n\n## When to Use This Skill\n\n- Your Downloads folder is a chaotic mess\n- You can't find files because they're scattered everywhere\n- You have duplicate files taking up space\n- Your folder structure doesn't make sense anymore\n- You want to establish better organization habits\n- You're starting a new project and need a good structure\n- You're cleaning up before archiving old projects\n\n## What This Skill Does\n\n1. **Analyzes Current Structure**: Reviews your folders and files to understand what you have\n2. **Finds Duplicates**: Identifies duplicate files across your system\n3. **Suggests Organization**: Proposes logical folder structures based on your content\n4. **Automates Cleanup**: Moves, renames, and organizes files with your approval\n5. **Maintains Context**: Makes smart decisions based on file types, dates, and content\n6. **Reduces Clutter**: Identifies old files you probably don't need anymore\n\n## How to Use\n\n### From Your Home Directory\n\n```\ncd ~\n```\n\nThen run Claude Code and ask for help:\n\n```\nHelp me organize my Downloads folder\n```\n\n```\nFind duplicate files in my Documents folder\n```\n\n```\nReview my project directories and suggest improvements\n```\n\n### Specific Organization Tasks\n\n```\nOrganize these downloads into proper folders based on what they are\n```\n\n```\nFind duplicate files and help me decide which to keep\n```\n\n```\nClean up old files I haven't touched in 6+ months\n```\n\n```\nCreate a better folder structure for my [work/projects/photos/etc]\n```\n\n## Instructions\n\nWhen a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any file"
  },
  {
    "id": "domain-name-brainstormer",
    "name": "domain-name-brainstormer",
    "description": "Generates creative domain name ideas for your project and checks availability across multiple TLDs (.com, .io, .dev, .ai, etc.). Saves hours of brainstorming and manual checking.",
    "category": "ml-ai",
    "source": "composio",
    "triggers": [
      "domain",
      "name",
      "brainstormer",
      "generates",
      "creative",
      "ideas",
      "project",
      "checks",
      "availability",
      "across"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/domain-name-brainstormer",
    "fullDescription": "\n# Domain Name Brainstormer\n\nThis skill helps you find the perfect domain name for your project by generating creative options and checking what's actually available to register.\n\n## When to Use This Skill\n\n- Starting a new project or company\n- Launching a product or service\n- Creating a personal brand or portfolio site\n- Rebranding an existing project\n- Registering a domain for a side project\n- Finding available alternatives when your first choice is taken\n\n## What This Skill Does\n\n1. **Understands Your Project**: Analyzes what you're building and who it's for\n2. **Generates Creative Names**: Creates relevant, memorable domain options\n3. **Checks Availability**: Verifies which domains are actually available across multiple TLDs\n4. **Multiple Extensions**: Suggests .com, .io, .dev, .ai, .app, and more\n5. **Provides Alternatives**: Offers variations if top choices are taken\n6. **Branding Insights**: Explains why certain names work well\n\n## How to Use\n\n### Basic Brainstorming\n\n```\nI'm building a project management tool for remote teams. \nSuggest domain names.\n```\n\n```\nHelp me brainstorm domain names for a personal finance app\n```\n\n### Specific Preferences\n\n```\nI need a domain name for my AI writing assistant. \nPrefer short names with .ai or .io extension.\n```\n\n### With Keywords\n\n```\nSuggest domain names using the words \"pixel\" or \"studio\" \nfor my design agency\n```\n\n## Example\n\n**User**: \"I'm building a tool for developers to share code snippets. Suggest creative domain names.\"\n\n**Output**:\n```\nAnalyzing your project...\nTarget audience: Developers\nKey features: Code sharing, snippets, collaboration\n\nðŸŽ¯ Domain Name Suggestions\n\n## Available (.com)\n1. âœ“ snippetbox.com - Clear, memorable, available!\n   Why: Directly describes the product, easy to remember\n\n2. âœ“ codeclip.com - Short and snappy\n   Why: Implies quick code sharing, only 8 characters\n\n3. âœ“ devpaste.com - Developer-focused\n   Why: Familiar to devs (like pastebin), clear purpose\n\n## Available (Alternative TLDs)\n"
  },
  {
    "id": "developer-growth-analysis",
    "name": "developer-growth-analysis",
    "description": "Analyzes your recent Claude Code chat history to identify coding patterns, development gaps, and areas for improvement, curates relevant learning resources from HackerNews, and automatically sends a personalized growth report to your Slack DMs.",
    "category": "ml-ai",
    "source": "composio",
    "triggers": [
      "developer",
      "growth",
      "analyzes",
      "recent",
      "claude",
      "code",
      "chat",
      "history",
      "identify",
      "coding"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/developer-growth-analysis",
    "fullDescription": "\n# Developer Growth Analysis\n\nThis skill provides personalized feedback on your recent coding work by analyzing your Claude Code chat interactions and identifying patterns that reveal strengths and areas for growth.\n\n## When to Use This Skill\n\nUse this skill when you want to:\n- Understand your development patterns and habits from recent work\n- Identify specific technical gaps or recurring challenges\n- Discover which topics would benefit from deeper study\n- Get curated learning resources tailored to your actual work patterns\n- Track improvement areas across your recent projects\n- Find high-quality articles that directly address the skills you're developing\n\nThis skill is ideal for developers who want structured feedback on their growth without waiting for code reviews, and who prefer data-driven insights from their own work history.\n\n## What This Skill Does\n\nThis skill performs a six-step analysis of your development work:\n\n1. **Reads Your Chat History**: Accesses your local Claude Code chat history from the past 24-48 hours to understand what you've been working on.\n\n2. **Identifies Development Patterns**: Analyzes the types of problems you're solving, technologies you're using, challenges you encounter, and how you approach different kinds of tasks.\n\n3. **Detects Improvement Areas**: Recognizes patterns that suggest skill gaps, repeated struggles, inefficient approaches, or areas where you might benefit from deeper knowledge.\n\n4. **Generates a Personalized Report**: Creates a comprehensive report showing your work summary, identified improvement areas, and specific recommendations for growth.\n\n5. **Finds Learning Resources**: Uses HackerNews to curate high-quality articles and discussions directly relevant to your improvement areas, providing you with a reading list tailored to your actual development work.\n\n6. **Sends to Your Slack DMs**: Automatically delivers the complete report to your own Slack direct messages so you can reference it anytime, anywhere.\n\n## How"
  },
  {
    "id": "content-research-writer",
    "name": "content-research-writer",
    "description": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
    "category": "sci-communication",
    "source": "composio",
    "triggers": [
      "content",
      "writer",
      "writing",
      "assists",
      "high-quality",
      "conducting",
      "adding",
      "citations",
      "improving",
      "hooks"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/content-research-writer",
    "fullDescription": "\n# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   -"
  },
  {
    "id": "competitive-ads-extractor",
    "name": "competitive-ads-extractor",
    "description": "Extracts and analyzes competitors' ads from ad libraries (Facebook, LinkedIn, etc.) to understand what messaging, problems, and creative approaches are working. Helps inspire and improve your own ad campaigns.",
    "category": "skill-dev",
    "source": "composio",
    "triggers": [
      "competitive",
      "ads",
      "extractor",
      "extracts",
      "analyzes",
      "competitors",
      "libraries",
      "facebook",
      "linkedin",
      "etc"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/competitive-ads-extractor",
    "fullDescription": "\n# Competitive Ads Extractor\n\nThis skill extracts your competitors' ads from ad libraries and analyzes what's workingâ€”the problems they're highlighting, use cases they're targeting, and copy/creative that's resonating.\n\n## When to Use This Skill\n\n- Researching competitor ad strategies\n- Finding inspiration for your own ads\n- Understanding market positioning\n- Identifying successful ad patterns\n- Analyzing messaging that works\n- Discovering new use cases or pain points\n- Planning ad campaigns with proven concepts\n\n## What This Skill Does\n\n1. **Extracts Ads**: Scrapes ads from Facebook Ad Library, LinkedIn, etc.\n2. **Captures Screenshots**: Saves visual copies of all ads\n3. **Analyzes Messaging**: Identifies problems, use cases, and value props\n4. **Categorizes Ads**: Groups by theme, audience, or format\n5. **Identifies Patterns**: Finds common successful approaches\n6. **Provides Insights**: Explains why certain ads likely perform well\n\n## How to Use\n\n### Basic Extraction\n\n```\nExtract all current ads from [Competitor Name] on Facebook Ad Library\n```\n\n```\nScrape ads from [Company] and analyze their messaging\n```\n\n### Specific Analysis\n\n```\nGet all ads from [Competitor] focusing on their messaging \nabout [specific problem]. What pain points are they highlighting?\n```\n\n### Competitive Set\n\n```\nExtract ads from these 5 competitors: [list]. \nCompare their approaches and tell me what's working.\n```\n\n### Specific Platform\n\n```\nGet LinkedIn ads from [Competitor] and analyze their \nB2B positioning strategy\n```\n\n## Example\n\n**User**: \"Extract ads from Notion on Facebook Ad Library and tell me what messaging is working for them.\"\n\n**Process**:\n```\nAccessing Facebook Ad Library...\nSearching for: Notion\nFound: 23 active ads\n\nExtracting screenshots...\n[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%\n\nSaved to: competitor-ads/notion/\n- ad-001-collaboration.png\n- ad-002-productivity.png\n- ad-003-templates.png\n...\n\nAnalyzing messaging...\n```\n\n**Output**:\n```\n# Notion Ad Analysis\n\n## Overview\n- Total Ads: "
  },
  {
    "id": "changelog-generator",
    "name": "changelog-generator",
    "description": "Automatically creates user-facing changelogs from git commits by analyzing commit history, categorizing changes, and transforming technical commits into clear, customer-friendly release notes. Turns hours of manual changelog writing into minutes of automated generation.",
    "category": "sci-communication",
    "source": "composio",
    "triggers": [
      "changelog",
      "generator",
      "commits",
      "automatically",
      "creates",
      "user-facing",
      "changelogs",
      "git",
      "analyzing",
      "commit"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/changelog-generator",
    "fullDescription": "\n# Changelog Generator\n\nThis skill transforms technical git commits into polished, user-friendly changelogs that your customers and users will actually understand and appreciate.\n\n## When to Use This Skill\n\n- Preparing release notes for a new version\n- Creating weekly or monthly product update summaries\n- Documenting changes for customers\n- Writing changelog entries for app store submissions\n- Generating update notifications\n- Creating internal release documentation\n- Maintaining a public changelog/product updates page\n\n## What This Skill Does\n\n1. **Scans Git History**: Analyzes commits from a specific time period or between versions\n2. **Categorizes Changes**: Groups commits into logical categories (features, improvements, bug fixes, breaking changes, security)\n3. **Translates Technical â†’ User-Friendly**: Converts developer commits into customer language\n4. **Formats Professionally**: Creates clean, structured changelog entries\n5. **Filters Noise**: Excludes internal commits (refactoring, tests, etc.)\n6. **Follows Best Practices**: Applies changelog guidelines and your brand voice\n\n## How to Use\n\n### Basic Usage\n\nFrom your project repository:\n\n```\nCreate a changelog from commits since last release\n```\n\n```\nGenerate changelog for all commits from the past week\n```\n\n```\nCreate release notes for version 2.5.0\n```\n\n### With Specific Date Range\n\n```\nCreate a changelog for all commits between March 1 and March 15\n```\n\n### With Custom Guidelines\n\n```\nCreate a changelog for commits since v2.4.0, using my changelog \nguidelines from CHANGELOG_STYLE.md\n```\n\n## Example\n\n**User**: \"Create a changelog for commits from the past 7 days\"\n\n**Output**:\n```markdown\n# Updates - Week of March 10, 2024\n\n## âœ¨ New Features\n\n- **Team Workspaces**: Create separate workspaces for different \n  projects. Invite team members and keep everything organized.\n\n- **Keyboard Shortcuts**: Press ? to see all available shortcuts. \n  Navigate faster without touching your mouse.\n\n## ðŸ”§ Improvements\n\n- **Fa"
  },
  {
    "id": "canvas-design",
    "name": "canvas-design",
    "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
    "category": "data-viz",
    "source": "composio",
    "triggers": [
      "canvas",
      "design",
      "visual",
      "art",
      "piece",
      "beautiful",
      "png",
      "pdf",
      "documents",
      "philosophy"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/canvas-design",
    "fullDescription": "\nThese are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, an"
  },
  {
    "id": "brand-guidelines",
    "name": "brand-guidelines",
    "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
    "category": "data-viz",
    "source": "composio",
    "triggers": [
      "brand",
      "guidelines",
      "anthropic",
      "colors",
      "applies",
      "official",
      "typography",
      "sort",
      "artifact",
      "benefit"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/brand-guidelines",
    "fullDescription": "\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n"
  },
  {
    "id": "artifacts-builder",
    "name": "artifacts-builder",
    "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "category": "ml-ai",
    "source": "composio",
    "triggers": [
      "artifacts",
      "builder",
      "html",
      "shadcn",
      "suite",
      "tools",
      "elaborate",
      "multi-component",
      "claude",
      "modern"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/artifacts-builder",
    "fullDescription": "\n# Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- âœ… React + TypeScript (via Vite)\n- âœ… Tailwind CSS 3.4.1 with shadcn/ui theming system\n- âœ… Path aliases (`@/`) configured\n- âœ… 40+ shadcn/ui components pre-installed\n- âœ… All Radix UI dependencies included\n- âœ… Parcel configured for bundling (via .parcelrc)\n- âœ… Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n#"
  },
  {
    "id": "react-components",
    "name": "react-components",
    "description": "React ç»„ä»¶å¼€å‘ä¸“å®¶ã€‚\nç²¾é€š Hooksã€çŠ¶æ€ç®¡ç†å’Œç»„ä»¶è®¾è®¡æ¨¡å¼ã€‚\n",
    "category": "frontend",
    "source": "community",
    "triggers": [
      "react",
      "components",
      "hooks",
      "react-components"
    ],
    "path": "/Users/marovole/GitHub/fastskills/awesome-claude-skills/react-components",
    "fullDescription": "\n# React Components\n\nReact ç»„ä»¶å¼€å‘å’Œæž¶æž„æœ€ä½³å®žè·µã€‚\n\n## Core Principles\n\n### Component Design\n\n1. **Single Responsibility**\n   - Each component should have one primary responsibility\n   - Break down complex components into smaller, focused ones\n   - Prefer composition over inheritance\n\n2. **Props Interface**\n   - Define clear TypeScript interfaces for props\n   - Use descriptive prop names that indicate purpose\n   - Provide default props for optional values\n\n3. **State Management**\n   - Use `useState` for local component state\n   - Lift state up when needed by multiple components\n   - Use context for global state that doesn't change frequently\n\n### Hooks Best Practices\n\n1. **useState**\n   ```tsx\n   const [state, setState] = useState(initialValue);\n   // Always use the setter function, never mutate state directly\n   setState(newValue);\n   setState(prev => newValue);\n   ```\n\n2. **useEffect**\n   ```tsx\n   useEffect(() => {\n     // Side effects here\n     return () => {\n       // Cleanup\n     };\n   }, [dependencies]); // Only re-run when dependencies change\n   ```\n\n3. **useCallback** and **useMemo**\n   - Use `useCallback` for functions passed as props\n   - Use `useMemo` for expensive computations\n   - Don't optimize prematurely\n\n### Performance Optimization\n\n1. **React.memo**\n   ```tsx\n   const MemoizedComponent = React.memo(Component);\n   ```\n\n2. **Code Splitting**\n   ```tsx\n   const LazyComponent = lazy(() => import('./Component'));\n   ```\n\n3. **Virtualization** for long lists\n   - Use `react-window` or `react-virtualized`\n\n## Common Patterns\n\n### Compound Components\n```tsx\n// Parent manages state, children are sub-components\nconst Menu = ({ children }) => <div>{children}</div>;\nMenu.Item = ({ children }) => <div>{children}</div>;\n```\n\n### Render Props\n```tsx\n<DataProvider render={data => <ChildComponent data={data} />} />\n```\n\n### Custom Hooks\n```tsx\nconst useToggle = (initialValue = false) => {\n  const [value, setValue] = useState(initialValue);\n  const toggle = useCallback(() =>"
  },
  {
    "id": "docker",
    "name": "docker",
    "description": "Docker å®¹å™¨åŒ–ä¸“å®¶ã€‚\nä¼˜åŒ–é•œåƒæž„å»ºå’Œå®¹å™¨é…ç½®ã€‚\n",
    "category": "devops",
    "source": "community",
    "triggers": [
      "docker"
    ],
    "path": "/Users/marovole/GitHub/fastskills/awesome-claude-skills/docker",
    "fullDescription": "\n# Docker\n\nä¸“ä¸šçš„ Docker å®¹å™¨åŒ–è§£å†³æ–¹æ¡ˆã€‚\n\n## Core Concepts\n\n### Images vs Containers\n\n- **Image**: A read-only template with instructions for creating a container\n- **Container**: A runnable instance of an image\n\n### Basic Commands\n\n```bash\n# Build an image\ndocker build -t myapp:1.0 .\n\n# Run a container\ndocker run -d -p 8080:80 myapp:1.0\n\n# List running containers\ndocker ps\n\n# Stop a container\ndocker stop <container_id>\n\n# View logs\ndocker logs <container_id>\n\n# Execute command in running container\ndocker exec -it <container_id> /bin/bash\n```\n\n## Dockerfile Best Practices\n\n### Multi-Stage Builds\n```dockerfile\n# Build stage\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\n# Production stage\nFROM nginx:alpine\nCOPY --from=builder /app/dist /usr/share/nginx/html\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### Layer Optimization\n\n1. **Order layers by change frequency**\n   - Put rarely-changing instructions first\n   - Put frequently-changing instructions last\n\n2. **Combine related commands**\n   ```dockerfile\n   RUN apt-get update && apt-get install -y \\\n       package1 \\\n       package2 \\\n       && rm -rf /var/lib/apt/lists/*\n   ```\n\n3. **Use .dockerignore**\n   ```\n   node_modules\n   npm-debug.log\n   .git\n   .env\n   ```\n\n## Docker Compose\n\n### Basic Configuration\n```yaml\nversion: '3.8'\nservices:\n  web:\n    build: .\n    ports:\n      - \"8080:80\"\n    environment:\n      - NODE_ENV=production\n    depends_on:\n      - db\n\n  db:\n    image: postgres:15\n    volumes:\n      - postgres_data:/data\n    environment:\n      - POSTGRES_DB=mydb\n\nvolumes:\n  postgres_data:\n```\n\n### Development Setup\n```yaml\nservices:\n  app:\n    build: .\n    volumes:\n      - .:/app\n      - /app/node_modules\n    environment:\n      - NODE_ENV=development\n    ports:\n      - \"3000:3000\"\n```\n\n## Security Best Practices\n\n1. **Use specific image tags**, not `latest`\n2. **Run as non-root user**\n   ```dockerfile\n   RUN addgroup -g 1001 -S appgroup && \\\n       adduser -"
  },
  {
    "id": "browser-automation",
    "name": "browser-automation",
    "description": "æµè§ˆå™¨è‡ªåŠ¨åŒ–ä¸“å®¶ã€‚\nä½¿ç”¨ Playwright å’Œ Puppeteer è¿›è¡Œç½‘é¡µè‡ªåŠ¨åŒ–ã€‚\n",
    "category": "lab-automation",
    "source": "community",
    "triggers": [
      "browser",
      "automation",
      "playwright",
      "puppeteer",
      "browser-automation"
    ],
    "path": "/Users/marovole/GitHub/fastskills/awesome-claude-skills/browser-automation",
    "fullDescription": "\n# Browser Automation\n\næµè§ˆå™¨è‡ªåŠ¨åŒ–å’Œç½‘é¡µæŠ“å–è§£å†³æ–¹æ¡ˆã€‚\n\n## Tools Overview\n\n### Playwright (Recommended)\n\n```bash\nnpm install playwright\nnpx playwright install chromium\n```\n\n### Puppeteer\n\n```bash\nnpm install puppeteer\n```\n\n## Playwright Basics\n\n### Launch Browser\n```typescript\nimport { chromium } from 'playwright';\n\nconst browser = await chromium.launch({ headless: true });\nconst context = await browser.newContext();\nconst page = await context.newPage();\n```\n\n### Navigation\n```typescript\nawait page.goto('https://example.com');\nawait page.waitForLoadState('networkidle');\n\n// Click link\nawait page.click('a[href=\"/next\"]');\n\n// Wait for navigation\nawait page.goto('https://example.com', { waitUntil: 'networkidle' });\n```\n\n### Element Interaction\n```typescript\n// Fill input\nawait page.fill('#search-input', 'search query');\n\n// Click button\nawait page.click('button[type=\"submit\"]');\n\n// Check checkbox\nawait page.check('#agree');\n\n// Select dropdown\nawait page.selectOption('select#country', 'US');\n\n// Handle dialog\npage.on('dialog', async dialog => {\n  await dialog.accept();\n});\n```\n\n### Extraction\n```typescript\n// Get text\nconst title = await page.textContent('h1');\n\n// Get attribute\nconst link = await page.getAttribute('a', 'href');\n\n// Get multiple elements\nconst items = await page.$$('.item');\nfor (const item of items) {\n  const text = await item.textContent();\n}\n```\n\n### Screenshot\n```typescript\nawait page.screenshot({ path: 'screenshot.png' });\nawait page.screenshot({ fullPage: true, path: 'full-page.png' });\n```\n\n## Puppeteer Basics\n\n### Launch Browser\n```typescript\nimport puppeteer from 'puppeteer';\n\nconst browser = await puppeteer.launch({\n  headless: 'new',\n  args: ['--no-sandbox']\n});\nconst page = await browser.newPage();\n```\n\n### Navigation\n```typescript\nawait page.goto('https://example.com', {\n  waitUntil: 'networkidle',\n  timeout: 30000\n});\n```\n\n### Element Interaction\n```typescript\n// Click\nawait page.click('#submit');\n\n// Type\nawait page.type('#email', 'user@example.com')"
  },
  {
    "id": "writing-skills",
    "name": "writing-skills",
    "description": "Use when creating new skills, editing existing skills, or verifying skills work before deployment",
    "category": "sci-communication",
    "source": "superpowers",
    "triggers": [
      "writing",
      "editing",
      "existing",
      "verifying",
      "work",
      "deployment",
      "writing-skills"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/writing-skills",
    "fullDescription": "\n# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (`~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex)** \n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future Claude instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept | Skill Creation |\n|-------------|----------------|\n| **Test case** | Pressure scenario with subagent |\n| **Production code** | Skill document (SKILL.md) |\n| **Test fails (RED)** | Agent violates rule without skill (baseline) |\n| **Test passes (GREEN)** | Agent complies with skill present |\n| **Refactor** | Close loopholes while maintaining compliance |\n| **Write test first** | Run baseline scenario BEFORE writing skill |\n| **Watch it fail** | Document exact rationalizations agent uses |\n| **Minimal code** | Write skill addressing those specific violations |\n| **Watch it pass** | Verify agent now complies |\n| **Refactor cycle** | Find new rationa"
  },
  {
    "id": "writing-plans",
    "name": "writing-plans",
    "description": "Use when you have a spec or requirements for a multi-step task, before touching code",
    "category": "sci-communication",
    "source": "superpowers",
    "triggers": [
      "writing",
      "plans",
      "spec",
      "requirements",
      "multi-step",
      "task",
      "touching",
      "code",
      "writing-plans"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/writing-plans",
    "fullDescription": "\n# Writing Plans\n\n## Overview\n\nWrite comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.\n\nAssume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** This should be run in a dedicated worktree (created by brainstorming skill).\n\n**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n## Bite-Sized Task Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Plan Document Header\n\n**Every plan MUST start with this header:**\n\n```markdown\n# [Feature Name] Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** [One sentence describing what this builds]\n\n**Architecture:** [2-3 sentences about approach]\n\n**Tech Stack:** [Key technologies/libraries]\n\n---\n```\n\n## Task Structure\n\n```markdown\n### Task N: [Component Name]\n\n**Files:**\n- Create: `exact/path/to/file.py`\n- Modify: `exact/path/to/existing.py:123-145`\n- Test: `tests/exact/path/to/test.py`\n\n**Step 1: Write the failing test**\n\n```python\ndef test_specific_behavior():\n    result = function(input)\n    assert result == expected\n```\n\n**Step 2: Run test to verify it fails**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: FAIL with \"function not defined\"\n\n**Step 3: Write minimal implementation**\n\n```python\ndef function(input):\n    return expected\n```\n\n**Step"
  },
  {
    "id": "verification-before-completion",
    "name": "verification-before-completion",
    "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "verification",
      "completion",
      "claim",
      "work",
      "complete",
      "fixed",
      "passing",
      "committing",
      "prs",
      "requires"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/verification-before-completion",
    "fullDescription": "\n# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confiden"
  },
  {
    "id": "using-git-worktrees",
    "name": "using-git-worktrees",
    "description": "Use when starting feature work that needs isolation from current workspace or before executing implementation plans - creates isolated git worktrees with smart directory selection and safety verification",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "git",
      "worktrees",
      "starting",
      "feature",
      "work",
      "needs",
      "isolation",
      "current",
      "workspace",
      "executing"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/using-git-worktrees",
    "fullDescription": "\n# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n**Announce at start:** \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n\n## Directory Selection Process\n\nFollow this priority order:\n\n### 1. Check Existing Directories\n\n```bash\n# Check in priority order\nls -d .worktrees 2>/dev/null     # Preferred (hidden)\nls -d worktrees 2>/dev/null      # Alternative\n```\n\n**If found:** Use that directory. If both exist, `.worktrees` wins.\n\n### 2. Check CLAUDE.md\n\n```bash\ngrep -i \"worktree.*director\" CLAUDE.md 2>/dev/null\n```\n\n**If preference specified:** Use it without asking.\n\n### 3. Ask User\n\nIf no directory exists and no CLAUDE.md preference:\n\n```\nNo worktree directory found. Where should I create worktrees?\n\n1. .worktrees/ (project-local, hidden)\n2. ~/.config/superpowers/worktrees/<project-name>/ (global location)\n\nWhich would you prefer?\n```\n\n## Safety Verification\n\n### For Project-Local Directories (.worktrees or worktrees)\n\n**MUST verify directory is ignored before creating worktree:**\n\n```bash\n# Check if directory is ignored (respects local, global, and system gitignore)\ngit check-ignore -q .worktrees 2>/dev/null || git check-ignore -q worktrees 2>/dev/null\n```\n\n**If NOT ignored:**\n\nPer Jesse's rule \"Fix broken things immediately\":\n1. Add appropriate line to .gitignore\n2. Commit the change\n3. Proceed with worktree creation\n\n**Why critical:** Prevents accidentally committing worktree contents to repository.\n\n### For Global Directory (~/.config/superpowers/worktrees)\n\nNo .gitignore verification needed - outside project entirely.\n\n## Creation Steps\n\n### 1. Detect Project Name\n\n```bash\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n```\n\n### 2. Create Worktree\n\n```bash\n# Determine full path\ncase $LOCATION in\n  .worktrees|workt"
  },
  {
    "id": "test-driven-development",
    "name": "test-driven-development",
    "description": "Use when implementing any feature or bugfix, before writing implementation code",
    "category": "sci-communication",
    "source": "superpowers",
    "triggers": [
      "test",
      "driven",
      "development",
      "feature",
      "bugfix",
      "writing",
      "implementation",
      "code",
      "test-driven-development"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/test-driven-development",
    "fullDescription": "\n# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n\nImplement fresh from tests. Period.\n\n## Red-Green-Refactor\n\n```dot\ndigraph tdd_cycle {\n    rankdir=LR;\n    red [label=\"RED\\nWrite failing test\", shape=box, style=filled, fillcolor=\"#ffcccc\"];\n    verify_red [label=\"Verify fails\\ncorrectly\", shape=diamond];\n    green [label=\"GREEN\\nMinimal code\", shape=box, style=filled, fillcolor=\"#ccffcc\"];\n    verify_green [label=\"Verify passes\\nAll green\", shape=diamond];\n    refactor [label=\"REFACTOR\\nClean up\", shape=box, style=filled, fillcolor=\"#ccccff\"];\n    next [label=\"Next\", shape=ellipse];\n\n    red -> verify_red;\n    verify_red -> green [label=\"yes\"];\n    verify_red -> red [label=\"wrong\\nfailure\"];\n    green -> verify_green;\n    verify_green -> refactor [label=\"yes\"];\n    verify_green -> green [label=\"no\"];\n    refactor -> verify_green [label=\"stay\\ngreen\"];\n    verify_green -> next;\n    next -> red;\n}\n```\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n<Good>\n```typescript\ntest('retries failed operations 3 times', async () => {\n  let attempts = 0;\n  const operation = () => {\n    attempts++;\n    if (attempts < 3) throw new Error('fail');\n    return 'success';\n  };\n\n  const result = await retryOp"
  },
  {
    "id": "systematic-debugging",
    "name": "systematic-debugging",
    "description": "Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes",
    "category": "testing",
    "source": "superpowers",
    "triggers": [
      "systematic",
      "debugging",
      "encountering",
      "bug",
      "test",
      "failure",
      "unexpected",
      "behavior",
      "proposing",
      "fixes"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/systematic-debugging",
    "fullDescription": "\n# Systematic Debugging\n\n## Overview\n\nRandom fixes waste time and create new bugs. Quick patches mask underlying issues.\n\n**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.\n\n**Violating the letter of this process is violating the spirit of debugging.**\n\n## The Iron Law\n\n```\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n```\n\nIf you haven't completed Phase 1, you cannot propose fixes.\n\n## When to Use\n\nUse for ANY technical issue:\n- Test failures\n- Bugs in production\n- Unexpected behavior\n- Performance problems\n- Build failures\n- Integration issues\n\n**Use this ESPECIALLY when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- You've already tried multiple fixes\n- Previous fix didn't work\n- You don't fully understand the issue\n\n**Don't skip when:**\n- Issue seems simple (simple bugs have root causes too)\n- You're in a hurry (rushing guarantees rework)\n- Manager wants it fixed NOW (systematic is faster than thrashing)\n\n## The Four Phases\n\nYou MUST complete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**BEFORE attempting ANY fix:**\n\n1. **Read Error Messages Carefully**\n   - Don't skip past errors or warnings\n   - They often contain the exact solution\n   - Read stack traces completely\n   - Note line numbers, file paths, error codes\n\n2. **Reproduce Consistently**\n   - Can you trigger it reliably?\n   - What are the exact steps?\n   - Does it happen every time?\n   - If not reproducible â†’ gather more data, don't guess\n\n3. **Check Recent Changes**\n   - What changed that could cause this?\n   - Git diff, recent commits\n   - New dependencies, config changes\n   - Environmental differences\n\n4. **Gather Evidence in Multi-Component Systems**\n\n   **WHEN system has multiple components (CI â†’ build â†’ signing, API â†’ service â†’ database):**\n\n   **BEFORE proposing fixes, add diagnostic instrumentation:**\n   ```\n   For EACH component boundary:\n     - Log what data "
  },
  {
    "id": "subagent-driven-development",
    "name": "subagent-driven-development",
    "description": "Use when executing implementation plans with independent tasks in the current session",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "subagent",
      "driven",
      "development",
      "executing",
      "implementation",
      "plans",
      "independent",
      "tasks",
      "current",
      "session"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/subagent-driven-development",
    "fullDescription": "\n# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.\n\n**Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Have implementation plan?\" [shape=diamond];\n    \"Tasks mostly independent?\" [shape=diamond];\n    \"Stay in this session?\" [shape=diamond];\n    \"subagent-driven-development\" [shape=box];\n    \"executing-plans\" [shape=box];\n    \"Manual execution or brainstorm first\" [shape=box];\n\n    \"Have implementation plan?\" -> \"Tasks mostly independent?\" [label=\"yes\"];\n    \"Have implementation plan?\" -> \"Manual execution or brainstorm first\" [label=\"no\"];\n    \"Tasks mostly independent?\" -> \"Stay in this session?\" [label=\"yes\"];\n    \"Tasks mostly independent?\" -> \"Manual execution or brainstorm first\" [label=\"no - tightly coupled\"];\n    \"Stay in this session?\" -> \"subagent-driven-development\" [label=\"yes\"];\n    \"Stay in this session?\" -> \"executing-plans\" [label=\"no - parallel session\"];\n}\n```\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Two-stage review after each task: spec compliance first, then code quality\n- Faster iteration (no human-in-loop between tasks)\n\n## The Process\n\n```dot\ndigraph process {\n    rankdir=TB;\n\n    subgraph cluster_per_task {\n        label=\"Per Task\";\n        \"Dispatch implementer subagent (./implementer-prompt.md)\" [shape=box];\n        \"Implementer subagent asks questions?\" [shape=diamond];\n        \"Answer questions, provide context\" [shape=box];\n        \"Implementer subagent implements, tests, commits, self-reviews\" [shape=box];\n        \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [shape=box];\n        \"Spec reviewer subagent confirms code matches spec?\" [shape=diamond];\n        \"Implementer subagent fixes spec gaps\" [sha"
  },
  {
    "id": "requesting-code-review",
    "name": "requesting-code-review",
    "description": "Use when completing tasks, implementing major features, or before merging to verify work meets requirements",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "requesting",
      "code",
      "review",
      "completing",
      "tasks",
      "major",
      "merging",
      "verify",
      "work",
      "meets"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/requesting-code-review",
    "fullDescription": "\n# Requesting Code Review\n\nDispatch superpowers:code-reviewer subagent to catch issues before they cascade.\n\n**Core principle:** Review early, review often.\n\n## When to Request Review\n\n**Mandatory:**\n- After each task in subagent-driven development\n- After completing major feature\n- Before merge to main\n\n**Optional but valuable:**\n- When stuck (fresh perspective)\n- Before refactoring (baseline check)\n- After fixing complex bug\n\n## How to Request\n\n**1. Get git SHAs:**\n```bash\nBASE_SHA=$(git rev-parse HEAD~1)  # or origin/main\nHEAD_SHA=$(git rev-parse HEAD)\n```\n\n**2. Dispatch code-reviewer subagent:**\n\nUse Task tool with superpowers:code-reviewer type, fill template at `code-reviewer.md`\n\n**Placeholders:**\n- `{WHAT_WAS_IMPLEMENTED}` - What you just built\n- `{PLAN_OR_REQUIREMENTS}` - What it should do\n- `{BASE_SHA}` - Starting commit\n- `{HEAD_SHA}` - Ending commit\n- `{DESCRIPTION}` - Brief summary\n\n**3. Act on feedback:**\n- Fix Critical issues immediately\n- Fix Important issues before proceeding\n- Note Minor issues for later\n- Push back if reviewer is wrong (with reasoning)\n\n## Example\n\n```\n[Just completed Task 2: Add verification function]\n\nYou: Let me request code review before proceeding.\n\nBASE_SHA=$(git log --oneline | grep \"Task 1\" | head -1 | awk '{print $1}')\nHEAD_SHA=$(git rev-parse HEAD)\n\n[Dispatch superpowers:code-reviewer subagent]\n  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index\n  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md\n  BASE_SHA: a7981ec\n  HEAD_SHA: 3df7661\n  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types\n\n[Subagent returns]:\n  Strengths: Clean architecture, real tests\n  Issues:\n    Important: Missing progress indicators\n    Minor: Magic number (100) for reporting interval\n  Assessment: Ready to proceed\n\nYou: [Fix progress indicators]\n[Continue to Task 3]\n```\n\n## Integration with Workflows\n\n**Subagent-Driven Development:**\n- Review after EACH task\n- Catch issues before they com"
  },
  {
    "id": "using-superpowers",
    "name": "using-superpowers",
    "description": "Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions",
    "category": "tools",
    "source": "superpowers",
    "triggers": [
      "superpowers",
      "starting",
      "conversation",
      "establishes",
      "find",
      "requiring",
      "tool",
      "invocation",
      "response",
      "clarifying"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/using-superpowers",
    "fullDescription": "\n<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## How to Access Skills\n\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to youâ€”follow it directly. Never use the Read tool on skill files.\n\n**In other environments:** Check your platform's documentation for how skills are loaded.\n\n# Using Skills\n\n## The Rule\n\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\n\n```dot\ndigraph skill_flow {\n    \"User message received\" [shape=doublecircle];\n    \"Might any skill apply?\" [shape=diamond];\n    \"Invoke Skill tool\" [shape=box];\n    \"Announce: 'Using [skill] to [purpose]'\" [shape=box];\n    \"Has checklist?\" [shape=diamond];\n    \"Create TodoWrite todo per item\" [shape=box];\n    \"Follow skill exactly\" [shape=box];\n    \"Respond (including clarifications)\" [shape=doublecircle];\n\n    \"User message received\" -> \"Might any skill apply?\";\n    \"Might any skill apply?\" -> \"Invoke Skill tool\" [label=\"yes, even 1%\"];\n    \"Might any skill apply?\" -> \"Respond (including clarifications)\" [label=\"definitely not\"];\n    \"Invoke Skill tool\" -> \"Announce: 'Using [skill] to [purpose]'\";\n    \"Announce: 'Using [skill] to [purpose]'\" -> \"Has checklist?\";\n    \"Has checklist?\" -> \"Create TodoWrite todo per item\" [label=\"yes\"];\n    \"Has checklist?\" -> \"Follow skill exactly\" [label=\"no\"];\n    \"Create TodoWrite todo per item\" -> \"Follow skill exactly\";\n}\n```\n\n## Red Flags\n\nThese thoughts mean STOPâ€”you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a s"
  },
  {
    "id": "finishing-a-development-branch",
    "name": "finishing-a-development-branch",
    "description": "Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "finishing",
      "development",
      "branch",
      "work",
      "implementation",
      "complete",
      "tests",
      "pass",
      "decide",
      "integrate"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/finishing-a-development-branch",
    "fullDescription": "\n# Finishing a Development Branch\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests â†’ Present options â†’ Execute choice â†’ Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Tests\n\n**Before presenting options, verify tests pass:**\n\n```bash\n# Run project's test suite\nnpm test / cargo test / pytest / go test ./...\n```\n\n**If tests fail:**\n```\nTests failing (<N> failures). Must fix before completing:\n\n[Show failures]\n\nCannot proceed with merge/PR until tests pass.\n```\n\nStop. Don't proceed to Step 2.\n\n**If tests pass:** Continue to Step 2.\n\n### Step 2: Determine Base Branch\n\n```bash\n# Try common base branches\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\nOr ask: \"This branch split from main - is that correct?\"\n\n### Step 3: Present Options\n\nPresent exactly these 4 options:\n\n```\nImplementation complete. What would you like to do?\n\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\nWhich option?\n```\n\n**Don't add explanation** - keep options concise.\n\n### Step 4: Execute Choice\n\n#### Option 1: Merge Locally\n\n```bash\n# Switch to base branch\ngit checkout <base-branch>\n\n# Pull latest\ngit pull\n\n# Merge feature branch\ngit merge <feature-branch>\n\n# Verify tests on merged result\n<test command>\n\n# If tests pass\ngit branch -d <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 2: Push and Create PR\n\n```bash\n# Push branch\ngit push -u origin <feature-branch>\n\n# Create PR\ngh pr create --title \"<title>\" --body \"$(cat <<'EOF'\n## Summary\n<2-3 bullets of what changed>\n\n## Test Plan\n- [ ] <verification steps>\nEOF\n)\"\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 3: Keep As-Is\n\nReport: \"Keeping branch <name>. Worktree preserved at <path>.\"\n\n**Don't cleanup worktree"
  },
  {
    "id": "receiving-code-review",
    "name": "receiving-code-review",
    "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "receiving",
      "code",
      "review",
      "feedback",
      "suggestions",
      "especially",
      "seems",
      "unclear",
      "technically",
      "questionable"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/receiving-code-review",
    "fullDescription": "\n# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n```\nWHEN receiving code review feedback:\n\n1. READ: Complete feedback without reacting\n2. UNDERSTAND: Restate requirement in own words (or ask)\n3. VERIFY: Check against codebase reality\n4. EVALUATE: Technically sound for THIS codebase?\n5. RESPOND: Technical acknowledgment or reasoned pushback\n6. IMPLEMENT: One item at a time, test each\n```\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n```\nIF any item is unclear:\n  STOP - do not implement anything yet\n  ASK for clarification on unclear items\n\nWHY: Items may be related. Partial understanding = wrong implementation.\n```\n\n**Example:**\n```\nyour human partner: \"Fix 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n\nâŒ WRONG: Implement 1,2,3,6 now, ask about 4,5 later\nâœ… RIGHT: \"I understand items 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n```\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n```\nBEFORE implementing:\n  1. Check: Technically correct for THIS codebase?\n  2. Check: Breaks existing functionality?\n  3. Check: Reason for current implementation?\n  4. Check: Works on all platforms/versions?\n  5. Check: Does reviewer understand full context?\n\nIF suggestion seems wrong:\n  Push back with technical reasoning\n\nIF can't easily veri"
  },
  {
    "id": "executing-plans",
    "name": "executing-plans",
    "description": "Use when you have a written implementation plan to execute in a separate session with review checkpoints",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "executing",
      "plans",
      "written",
      "implementation",
      "plan",
      "execute",
      "separate",
      "session",
      "review",
      "checkpoints"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/executing-plans",
    "fullDescription": "\n# Executing Plans\n\n## Overview\n\nLoad plan, review critically, execute tasks in batches, report for review between batches.\n\n**Core principle:** Batch execution with checkpoints for architect review.\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed\n\n### Step 2: Execute Batch\n**Default: First 3 tasks**\n\nFor each task:\n1. Mark as in_progress\n2. Follow each step exactly (plan has bite-sized steps)\n3. Run verifications as specified\n4. Mark as completed\n\n### Step 3: Report\nWhen batch complete:\n- Show what was implemented\n- Show verification output\n- Say: \"Ready for feedback.\"\n\n### Step 4: Continue\nBased on feedback:\n- Apply changes if needed\n- Execute next batch\n- Repeat until complete\n\n### Step 5: Complete Development\n\nAfter all tasks complete and verified:\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use superpowers:finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n## When to Stop and Ask for Help\n\n**STOP executing immediately when:**\n- Hit a blocker mid-batch (missing dependency, test fails, instruction unclear)\n- Plan has critical gaps preventing starting\n- You don't understand an instruction\n- Verification fails repeatedly\n\n**Ask for clarification rather than guessing.**\n\n## When to Revisit Earlier Steps\n\n**Return to Review (Step 1) when:**\n- Partner updates the plan based on your feedback\n- Fundamental approach needs rethinking\n\n**Don't force through blockers** - stop and ask.\n\n## Remember\n- Review plan critically first\n- Follow plan steps exactly\n- Don't skip verifications\n- Reference skills when plan says to\n- Between batches: just report and wait\n- Stop whe"
  },
  {
    "id": "dispatching-parallel-agents",
    "name": "dispatching-parallel-agents",
    "description": "Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies",
    "category": "skill-dev",
    "source": "superpowers",
    "triggers": [
      "dispatching",
      "parallel",
      "agents",
      "facing",
      "independent",
      "tasks",
      "worked",
      "without",
      "shared",
      "state"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/dispatching-parallel-agents",
    "fullDescription": "\n# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Multiple failures?\" [shape=diamond];\n    \"Are they independent?\" [shape=diamond];\n    \"Single agent investigates all\" [shape=box];\n    \"One agent per problem domain\" [shape=box];\n    \"Can they work in parallel?\" [shape=diamond];\n    \"Sequential agents\" [shape=box];\n    \"Parallel dispatch\" [shape=box];\n\n    \"Multiple failures?\" -> \"Are they independent?\" [label=\"yes\"];\n    \"Are they independent?\" -> \"Single agent investigates all\" [label=\"no - related\"];\n    \"Are they independent?\" -> \"Can they work in parallel?\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Parallel dispatch\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Sequential agents\" [label=\"no - shared state\"];\n}\n```\n\n**Use when:**\n- 3+ test files failing with different root causes\n- Multiple subsystems broken independently\n- Each problem can be understood without context from others\n- No shared state between investigations\n\n**Don't use when:**\n- Failures are related (fix one might fix others)\n- Need to understand full system state\n- Agents would interfere with each other\n\n## The Pattern\n\n### 1. Identify Independent Domains\n\nGroup failures by what's broken:\n- File A tests: Tool approval flow\n- File B tests: Batch completion behavior\n- File C tests: Abort functionality\n\nEach domain is independent - fixing tool approval doesn't affect abort tests.\n\n### 2. Create Focused Agent Tasks\n\nEach agent gets:\n- **Specific scope:** One test file or subsystem\n- **Clear goal:** Make these tests pass\n- **Constraints:** Don't change other code\n- **Expected output:** Summary of what you found and fixed\n\n### 3. Dispa"
  },
  {
    "id": "brainstorming",
    "name": "brainstorming",
    "description": "You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores user intent, requirements and design before implementation.",
    "category": "frontend",
    "source": "superpowers",
    "triggers": [
      "brainstorming",
      "creative",
      "work",
      "components",
      "adding",
      "functionality",
      "modifying",
      "behavior",
      "explores",
      "user"
    ],
    "path": "/Users/marovole/GitHub/fastskills/superpowers/skills/brainstorming",
    "fullDescription": "\n# Brainstorming Ideas Into Designs\n\n## Overview\n\nHelp turn ideas into fully formed designs and specs through natural collaborative dialogue.\n\nStart by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design in small sections (200-300 words), checking after each section whether it looks right so far.\n\n## The Process\n\n**Understanding the idea:**\n- Check out the current project state first (files, docs, recent commits)\n- Ask questions one at a time to refine the idea\n- Prefer multiple choice questions when possible, but open-ended is fine too\n- Only one question per message - if a topic needs more exploration, break it into multiple questions\n- Focus on understanding: purpose, constraints, success criteria\n\n**Exploring approaches:**\n- Propose 2-3 different approaches with trade-offs\n- Present options conversationally with your recommendation and reasoning\n- Lead with your recommended option and explain why\n\n**Presenting the design:**\n- Once you believe you understand what you're building, present the design\n- Break it into sections of 200-300 words\n- Ask after each section whether it looks right so far\n- Cover: architecture, components, data flow, error handling, testing\n- Be ready to go back and clarify if something doesn't make sense\n\n## After the Design\n\n**Documentation:**\n- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`\n- Use elements-of-style:writing-clearly-and-concisely skill if available\n- Commit the design document to git\n\n**Implementation (if continuing):**\n- Ask: \"Ready to set up for implementation?\"\n- Use superpowers:using-git-worktrees to create isolated workspace\n- Use superpowers:writing-plans to create detailed implementation plan\n\n## Key Principles\n\n- **One question at a time** - Don't overwhelm with multiple questions\n- **Multiple choice preferred** - Easier to answer than open-ended when possible\n- **YAGNI ruthlessly** - Remo"
  },
  {
    "id": "obsidian-markdown",
    "name": "obsidian-markdown",
    "description": "Create and edit Obsidian Flavored Markdown with wikilinks, embeds, callouts, properties, and other Obsidian-specific syntax. Use when working with .md files in Obsidian, or when the user mentions wikilinks, callouts, frontmatter, tags, embeds, or Obsidian notes.",
    "category": "knowledge",
    "source": "obsidian",
    "triggers": [
      "obsidian",
      "markdown",
      "wikilinks",
      "embeds",
      "callouts",
      "edit",
      "flavored",
      "properties",
      "obsidian-specific",
      "syntax"
    ],
    "path": "/Users/marovole/GitHub/fastskills/obsidian-skills/skills/obsidian-markdown",
    "fullDescription": "\n# Obsidian Flavored Markdown Skill\n\nThis skill enables Claude Code to create and edit valid Obsidian Flavored Markdown, including all Obsidian-specific syntax extensions.\n\n## Overview\n\nObsidian uses a combination of Markdown flavors:\n- [CommonMark](https://commonmark.org/)\n- [GitHub Flavored Markdown](https://github.github.com/gfm/)\n- [LaTeX](https://www.latex-project.org/) for math\n- Obsidian-specific extensions (wikilinks, callouts, embeds, etc.)\n\n## Basic Formatting\n\n### Paragraphs and Line Breaks\n\n```markdown\nThis is a paragraph.\n\nThis is another paragraph (blank line between creates separate paragraphs).\n\nFor a line break within a paragraph, add two spaces at the end  \nor use Shift+Enter.\n```\n\n### Headings\n\n```markdown\n# Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n##### Heading 5\n###### Heading 6\n```\n\n### Text Formatting\n\n| Style | Syntax | Example | Output |\n|-------|--------|---------|--------|\n| Bold | `**text**` or `__text__` | `**Bold**` | **Bold** |\n| Italic | `*text*` or `_text_` | `*Italic*` | *Italic* |\n| Bold + Italic | `***text***` | `***Both***` | ***Both*** |\n| Strikethrough | `~~text~~` | `~~Striked~~` | ~~Striked~~ |\n| Highlight | `==text==` | `==Highlighted==` | ==Highlighted== |\n| Inline code | `` `code` `` | `` `code` `` | `code` |\n\n### Escaping Formatting\n\nUse backslash to escape special characters:\n```markdown\n\\*This won't be italic\\*\n\\#This won't be a heading\n1\\. This won't be a list item\n```\n\nCommon characters to escape: `\\*`, `\\_`, `\\#`, `` \\` ``, `\\|`, `\\~`\n\n## Internal Links (Wikilinks)\n\n### Basic Links\n\n```markdown\n[[Note Name]]\n[[Note Name.md]]\n[[Note Name|Display Text]]\n```\n\n### Link to Headings\n\n```markdown\n[[Note Name#Heading]]\n[[Note Name#Heading|Custom Text]]\n[[#Heading in same note]]\n[[##Search all headings in vault]]\n```\n\n### Link to Blocks\n\n```markdown\n[[Note Name#^block-id]]\n[[Note Name#^block-id|Custom Text]]\n```\n\nDefine a block ID by adding `^block-id` at the end of a paragraph:\n```markdown\nThis is a paragraph that"
  },
  {
    "id": "obsidian-bases",
    "name": "obsidian-bases",
    "description": "Create and edit Obsidian Bases (.base files) with views, filters, formulas, and summaries. Use when working with .base files, creating database-like views of notes, or when the user mentions Bases, table views, card views, filters, or formulas in Obsidian.",
    "category": "sci-databases",
    "source": "obsidian",
    "triggers": [
      "obsidian",
      "bases",
      "views",
      "base",
      "filters",
      "formulas",
      "edit",
      "summaries",
      "database-like",
      "notes"
    ],
    "path": "/Users/marovole/GitHub/fastskills/obsidian-skills/skills/obsidian-bases",
    "fullDescription": "\n# Obsidian Bases Skill\n\nThis skill enables Claude Code to create and edit valid Obsidian Bases (`.base` files) including views, filters, formulas, and all related configurations.\n\n## Overview\n\nObsidian Bases are YAML-based files that define dynamic views of notes in an Obsidian vault. A Base file can contain multiple views, global filters, formulas, property configurations, and custom summaries.\n\n## File Format\n\nBase files use the `.base` extension and contain valid YAML. They can also be embedded in Markdown code blocks.\n\n## Complete Schema\n\n```yaml\n# Global filters apply to ALL views in the base\nfilters:\n  # Can be a single filter string\n  # OR a recursive filter object with and/or/not\n  and: []\n  or: []\n  not: []\n\n# Define formula properties that can be used across all views\nformulas:\n  formula_name: 'expression'\n\n# Configure display names and settings for properties\nproperties:\n  property_name:\n    displayName: \"Display Name\"\n  formula.formula_name:\n    displayName: \"Formula Display Name\"\n  file.ext:\n    displayName: \"Extension\"\n\n# Define custom summary formulas\nsummaries:\n  custom_summary_name: 'values.mean().round(3)'\n\n# Define one or more views\nviews:\n  - type: table | cards | list | map\n    name: \"View Name\"\n    limit: 10                    # Optional: limit results\n    groupBy:                     # Optional: group results\n      property: property_name\n      direction: ASC | DESC\n    filters:                     # View-specific filters\n      and: []\n    order:                       # Properties to display in order\n      - file.name\n      - property_name\n      - formula.formula_name\n    summaries:                   # Map properties to summary formulas\n      property_name: Average\n```\n\n## Filter Syntax\n\nFilters narrow down results. They can be applied globally or per-view.\n\n### Filter Structure\n\n```yaml\n# Single filter\nfilters: 'status == \"done\"'\n\n# AND - all conditions must be true\nfilters:\n  and:\n    - 'status == \"done\"'\n    - 'priority > 3'\n\n# OR - any co"
  },
  {
    "id": "json-canvas",
    "name": "json-canvas",
    "description": "Create and edit JSON Canvas files (.canvas) with nodes, edges, groups, and connections. Use when working with .canvas files, creating visual canvases, mind maps, flowcharts, or when the user mentions Canvas files in Obsidian.",
    "category": "data-viz",
    "source": "obsidian",
    "triggers": [
      "json",
      "canvas",
      "edit",
      "nodes",
      "edges",
      "groups",
      "connections",
      "visual",
      "canvases",
      "mind"
    ],
    "path": "/Users/marovole/GitHub/fastskills/obsidian-skills/skills/json-canvas",
    "fullDescription": "\n# JSON Canvas Skill\n\nThis skill enables Claude Code to create and edit valid JSON Canvas files (`.canvas`) used in Obsidian and other applications.\n\n## Overview\n\nJSON Canvas is an open file format for infinite canvas data. Canvas files use the `.canvas` extension and contain valid JSON following the [JSON Canvas Spec 1.0](https://jsoncanvas.org/spec/1.0/).\n\n## File Structure\n\nA canvas file contains two top-level arrays:\n\n```json\n{\n  \"nodes\": [],\n  \"edges\": []\n}\n```\n\n- `nodes` (optional): Array of node objects\n- `edges` (optional): Array of edge objects connecting nodes\n\n## Nodes\n\nNodes are objects placed on the canvas. There are four node types:\n- `text` - Text content with Markdown\n- `file` - Reference to files/attachments\n- `link` - External URL\n- `group` - Visual container for other nodes\n\n### Z-Index Ordering\n\nNodes are ordered by z-index in the array:\n- First node = bottom layer (displayed below others)\n- Last node = top layer (displayed above others)\n\n### Generic Node Attributes\n\nAll nodes share these attributes:\n\n| Attribute | Required | Type | Description |\n|-----------|----------|------|-------------|\n| `id` | Yes | string | Unique identifier for the node |\n| `type` | Yes | string | Node type: `text`, `file`, `link`, or `group` |\n| `x` | Yes | integer | X position in pixels |\n| `y` | Yes | integer | Y position in pixels |\n| `width` | Yes | integer | Width in pixels |\n| `height` | Yes | integer | Height in pixels |\n| `color` | No | canvasColor | Node color (see Color section) |\n\n### Text Nodes\n\nText nodes contain Markdown content.\n\n```json\n{\n  \"id\": \"6f0ad84f44ce9c17\",\n  \"type\": \"text\",\n  \"x\": 0,\n  \"y\": 0,\n  \"width\": 400,\n  \"height\": 200,\n  \"text\": \"# Hello World\\n\\nThis is **Markdown** content.\"\n}\n```\n\n| Attribute | Required | Type | Description |\n|-----------|----------|------|-------------|\n| `text` | Yes | string | Plain text with Markdown syntax |\n\n### File Nodes\n\nFile nodes reference files or attachments (images, videos, PDFs, notes, etc.).\n\n```json\n{"
  },
  {
    "id": "zinc-database",
    "name": "zinc-database",
    "description": "Access ZINC (230M+ purchasable compounds). Search by ZINC ID/SMILES, similarity searches, 3D-ready structures for docking, analog discovery, for virtual screening and drug discovery.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "zinc",
      "discovery",
      "230m",
      "purchasable",
      "compounds",
      "smiles",
      "similarity",
      "searches",
      "3d-ready",
      "structures"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/zinc-database",
    "fullDescription": "\n# ZINC Database\n\n## Overview\n\nZINC is a freely accessible repository of 230M+ purchasable compounds maintained by UCSF. Search by ZINC ID or SMILES, perform similarity searches, download 3D-ready structures for docking, discover analogs for virtual screening and drug discovery.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **Virtual screening**: Finding compounds for molecular docking studies\n- **Lead discovery**: Identifying commercially-available compounds for drug development\n- **Structure searches**: Performing similarity or analog searches by SMILES\n- **Compound retrieval**: Looking up molecules by ZINC IDs or supplier codes\n- **Chemical space exploration**: Exploring purchasable chemical diversity\n- **Docking studies**: Accessing 3D-ready molecular structures\n- **Analog searches**: Finding similar compounds based on structural similarity\n- **Supplier queries**: Identifying compounds from specific chemical vendors\n- **Random sampling**: Obtaining random compound sets for screening\n\n## Database Versions\n\nZINC has evolved through multiple versions:\n\n- **ZINC22** (Current): Largest version with 230+ million purchasable compounds and multi-billion scale make-on-demand compounds\n- **ZINC20**: Still maintained, focused on lead-like and drug-like compounds\n- **ZINC15**: Predecessor version, legacy but still documented\n\nThis skill primarily focuses on ZINC22, the most current and comprehensive version.\n\n## Access Methods\n\n### Web Interface\n\nPrimary access point: https://zinc.docking.org/\nInteractive searching: https://cartblanche22.docking.org/\n\n### API Access\n\nAll ZINC22 searches can be performed programmatically via the CartBlanche22 API:\n\n**Base URL**: `https://cartblanche22.docking.org/`\n\nAll API endpoints return data in text or JSON format with customizable fields.\n\n## Core Capabilities\n\n### 1. Search by ZINC ID\n\nRetrieve specific compounds using their ZINC identifiers.\n\n**Web interface**: https://cartblanche22.docking.org/search/zincid\n\n**API en"
  },
  {
    "id": "zarr-python",
    "name": "zarr-python",
    "description": "Chunked N-D arrays for cloud storage. Compressed arrays, parallel I/O, S3/GCS integration, NumPy/Dask/Xarray compatible, for large-scale scientific computing pipelines.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "zarr",
      "arrays",
      "chunked",
      "n-d",
      "cloud",
      "storage",
      "compressed",
      "parallel",
      "gcs",
      "integration"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/zarr-python",
    "fullDescription": "\n# Zarr Python\n\n## Overview\n\nZarr is a Python library for storing large N-dimensional arrays with chunking and compression. Apply this skill for efficient parallel I/O, cloud-native workflows, and seamless integration with NumPy, Dask, and Xarray.\n\n## Quick Start\n\n### Installation\n\n```bash\nuv pip install zarr\n```\n\nRequires Python 3.11+. For cloud storage support, install additional packages:\n```python\nuv pip install s3fs  # For S3\nuv pip install gcsfs  # For Google Cloud Storage\n```\n\n### Basic Array Creation\n\n```python\nimport zarr\nimport numpy as np\n\n# Create a 2D array with chunking and compression\nz = zarr.create_array(\n    store=\"data/my_array.zarr\",\n    shape=(10000, 10000),\n    chunks=(1000, 1000),\n    dtype=\"f4\"\n)\n\n# Write data using NumPy-style indexing\nz[:, :] = np.random.random((10000, 10000))\n\n# Read data\ndata = z[0:100, 0:100]  # Returns NumPy array\n```\n\n## Core Operations\n\n### Creating Arrays\n\nZarr provides multiple convenience functions for array creation:\n\n```python\n# Create empty array\nz = zarr.zeros(shape=(10000, 10000), chunks=(1000, 1000), dtype='f4',\n               store='data.zarr')\n\n# Create filled arrays\nz = zarr.ones((5000, 5000), chunks=(500, 500))\nz = zarr.full((1000, 1000), fill_value=42, chunks=(100, 100))\n\n# Create from existing data\ndata = np.arange(10000).reshape(100, 100)\nz = zarr.array(data, chunks=(10, 10), store='data.zarr')\n\n# Create like another array\nz2 = zarr.zeros_like(z)  # Matches shape, chunks, dtype of z\n```\n\n### Opening Existing Arrays\n\n```python\n# Open array (read/write mode by default)\nz = zarr.open_array('data.zarr', mode='r+')\n\n# Read-only mode\nz = zarr.open_array('data.zarr', mode='r')\n\n# The open() function auto-detects arrays vs groups\nz = zarr.open('data.zarr')  # Returns Array or Group\n```\n\n### Reading and Writing Data\n\nZarr arrays support NumPy-like indexing:\n\n```python\n# Write entire array\nz[:] = 42\n\n# Write slices\nz[0, :] = np.arange(100)\nz[10:20, 50:60] = np.random.random((10, 10))\n\n# Read data (returns NumPy "
  },
  {
    "id": "uspto-database",
    "name": "uspto-database",
    "description": "Access USPTO APIs for patent/trademark searches, examination history (PEDS), assignments, citations, office actions, TSDR, for IP analysis and prior art searches.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "uspto",
      "searches",
      "apis",
      "patent",
      "trademark",
      "examination",
      "history",
      "peds",
      "assignments",
      "citations"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/uspto-database",
    "fullDescription": "\n# USPTO Database\n\n## Overview\n\nUSPTO provides specialized APIs for patent and trademark data. Search patents by keywords/inventors/assignees, retrieve examination history via PEDS, track assignments, analyze citations and office actions, access TSDR for trademarks, for IP analysis and prior art searches.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **Patent Search**: Finding patents by keywords, inventors, assignees, classifications, or dates\n- **Patent Details**: Retrieving full patent data including claims, abstracts, citations\n- **Trademark Search**: Looking up trademarks by serial or registration number\n- **Trademark Status**: Checking trademark status, ownership, and prosecution history\n- **Examination History**: Accessing patent prosecution data from PEDS (Patent Examination Data System)\n- **Office Actions**: Retrieving office action text, citations, and rejections\n- **Assignments**: Tracking patent/trademark ownership transfers\n- **Citations**: Analyzing patent citations (forward and backward)\n- **Litigation**: Accessing patent litigation records\n- **Portfolio Analysis**: Analyzing patent/trademark portfolios for companies or inventors\n\n## USPTO API Ecosystem\n\nThe USPTO provides multiple specialized APIs for different data needs:\n\n### Core APIs\n\n1. **PatentSearch API** - Modern ElasticSearch-based patent search (replaced legacy PatentsView in May 2025)\n   - Search patents by keywords, inventors, assignees, classifications, dates\n   - Access to patent data through June 30, 2025\n   - 45 requests/minute rate limit\n   - **Base URL**: `https://search.patentsview.org/api/v1/`\n\n2. **PEDS (Patent Examination Data System)** - Patent examination history\n   - Application status and transaction history from 1981-present\n   - Office action dates and examination events\n   - Use `uspto-opendata-python` Python library\n   - **Replaced**: PAIR Bulk Data (PBD) - decommissioned\n\n3. **TSDR (Trademark Status & Document Retrieval)** - Trademark data\n   - Trademar"
  },
  {
    "id": "uniprot-database",
    "name": "uniprot-database",
    "description": "Direct REST API access to UniProt. Protein searches, FASTA retrieval, ID mapping, Swiss-Prot/TrEMBL. For Python workflows with multiple databases, prefer bioservices (unified interface to 40+ services). Use this for direct HTTP/REST work or UniProt-specific control.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "uniprot",
      "direct",
      "rest",
      "protein",
      "searches",
      "fasta",
      "retrieval",
      "mapping",
      "swiss-prot",
      "trembl"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/uniprot-database",
    "fullDescription": "\n# UniProt Database\n\n## Overview\n\nUniProt is the world's leading comprehensive protein sequence and functional information resource. Search proteins by name, gene, or accession, retrieve sequences in FASTA format, perform ID mapping across databases, access Swiss-Prot/TrEMBL annotations via REST API for protein analysis.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Searching for protein entries by name, gene symbol, accession, or organism\n- Retrieving protein sequences in FASTA or other formats\n- Mapping identifiers between UniProt and external databases (Ensembl, RefSeq, PDB, etc.)\n- Accessing protein annotations including GO terms, domains, and functional descriptions\n- Batch retrieving multiple protein entries efficiently\n- Querying reviewed (Swiss-Prot) vs. unreviewed (TrEMBL) protein data\n- Streaming large protein datasets\n- Building custom queries with field-specific search syntax\n\n## Core Capabilities\n\n### 1. Searching for Proteins\n\nSearch UniProt using natural language queries or structured search syntax.\n\n**Common search patterns:**\n```python\n# Search by protein name\nquery = \"insulin AND organism_name:\\\"Homo sapiens\\\"\"\n\n# Search by gene name\nquery = \"gene:BRCA1 AND reviewed:true\"\n\n# Search by accession\nquery = \"accession:P12345\"\n\n# Search by sequence length\nquery = \"length:[100 TO 500]\"\n\n# Search by taxonomy\nquery = \"taxonomy_id:9606\"  # Human proteins\n\n# Search by GO term\nquery = \"go:0005515\"  # Protein binding\n```\n\nUse the API search endpoint: `https://rest.uniprot.org/uniprotkb/search?query={query}&format={format}`\n\n**Supported formats:** JSON, TSV, Excel, XML, FASTA, RDF, TXT\n\n### 2. Retrieving Individual Protein Entries\n\nRetrieve specific protein entries by accession number.\n\n**Accession number formats:**\n- Classic: P12345, Q1AAA9, O15530 (6 characters: letter + 5 alphanumeric)\n- Extended: A0A022YWF9 (10 characters for newer entries)\n\n**Retrieve endpoint:** `https://rest.uniprot.org/uniprotkb/{accession}.{format}`\n\nExample: `https://re"
  },
  {
    "id": "umap-learn",
    "name": "umap-learn",
    "description": "UMAP dimensionality reduction. Fast nonlinear manifold learning for 2D/3D visualization, clustering preprocessing (HDBSCAN), supervised/parametric UMAP, for high-dimensional data.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "umap",
      "learn",
      "dimensionality",
      "reduction",
      "fast",
      "nonlinear",
      "manifold",
      "visualization",
      "clustering",
      "preprocessing"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/umap-learn",
    "fullDescription": "\n# UMAP-Learn\n\n## Overview\n\nUMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique for visualization and general non-linear dimensionality reduction. Apply this skill for fast, scalable embeddings that preserve local and global structure, supervised learning, and clustering preprocessing.\n\n## Quick Start\n\n### Installation\n\n```bash\nuv pip install umap-learn\n```\n\n### Basic Usage\n\nUMAP follows scikit-learn conventions and can be used as a drop-in replacement for t-SNE or PCA.\n\n```python\nimport umap\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare data (standardization is essential)\nscaled_data = StandardScaler().fit_transform(data)\n\n# Method 1: Single step (fit and transform)\nembedding = umap.UMAP().fit_transform(scaled_data)\n\n# Method 2: Separate steps (for reusing trained model)\nreducer = umap.UMAP(random_state=42)\nreducer.fit(scaled_data)\nembedding = reducer.embedding_  # Access the trained embedding\n```\n\n**Critical preprocessing requirement:** Always standardize features to comparable scales before applying UMAP to ensure equal weighting across dimensions.\n\n### Typical Workflow\n\n```python\nimport umap\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# 1. Preprocess data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(raw_data)\n\n# 2. Create and fit UMAP\nreducer = umap.UMAP(\n    n_neighbors=15,\n    min_dist=0.1,\n    n_components=2,\n    metric='euclidean',\n    random_state=42\n)\nembedding = reducer.fit_transform(scaled_data)\n\n# 3. Visualize\nplt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='Spectral', s=5)\nplt.colorbar()\nplt.title('UMAP Embedding')\nplt.show()\n```\n\n## Parameter Tuning Guide\n\nUMAP has four primary parameters that control the embedding behavior. Understanding these is crucial for effective usage.\n\n### n_neighbors (default: 15)\n\n**Purpose:** Balances local versus global structure in the embedding.\n\n**How it works:** Controls the size of the local neighb"
  },
  {
    "id": "treatment-plans",
    "name": "treatment-plans",
    "description": "Generate concise (3-4 page), focused medical treatment plans in LaTeX/PDF format for all clinical specialties. Supports general medical treatment, rehabilitation therapy, mental health care, chronic disease management, perioperative care, and pain management. Includes SMART goal frameworks, evidence",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "treatment",
      "plans",
      "medical",
      "clinical",
      "care",
      "management",
      "generate",
      "concise",
      "3-4",
      "page"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/treatment-plans",
    "fullDescription": "\n# Treatment Plan Writing\n\n## Overview\n\nTreatment plan writing is the systematic documentation of clinical care strategies designed to address patient health conditions through evidence-based interventions, measurable goals, and structured follow-up. This skill provides comprehensive LaTeX templates and validation tools for creating **concise, focused** treatment plans (3-4 pages standard) across all medical specialties with full regulatory compliance.\n\n**Critical Principles:**\n1. **CONCISE & ACTIONABLE**: Treatment plans default to 3-4 pages maximum, focusing only on clinically essential information that impacts care decisions\n2. **Patient-Centered**: Plans must be evidence-based, measurable, and compliant with healthcare regulations (HIPAA, documentation standards)\n3. **Minimal Citations**: Use brief in-text citations only when needed to support clinical recommendations; avoid extensive bibliographies\n\nEvery treatment plan should include clear goals, specific interventions, defined timelines, monitoring parameters, and expected outcomes that align with patient preferences and current clinical guidelines - all presented as efficiently as possible.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating individualized treatment plans for patient care\n- Documenting therapeutic interventions for chronic disease management\n- Developing rehabilitation programs (physical therapy, occupational therapy, cardiac rehab)\n- Writing mental health and psychiatric treatment plans\n- Planning perioperative and surgical care pathways\n- Establishing pain management protocols\n- Setting patient-centered goals using SMART criteria\n- Coordinating multidisciplinary care across specialties\n- Ensuring regulatory compliance in treatment documentation\n- Generating professional treatment plans for medical records\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every treatment plan MUST include at least 1 AI-generated figure using the scientific-schematics skil"
  },
  {
    "id": "transformers",
    "name": "transformers",
    "description": "This skill should be used when working with pre-trained transformer models for natural language processing, computer vision, audio, or multimodal tasks. Use for text generation, classification, question answering, translation, summarization, image classification, object detection, speech recognition",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "transformers",
      "classification",
      "pre-trained",
      "transformer",
      "natural",
      "language",
      "processing",
      "computer",
      "vision",
      "audio"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/transformers",
    "fullDescription": "\n# Transformers\n\n## Overview\n\nThe Hugging Face Transformers library provides access to thousands of pre-trained models for tasks across NLP, computer vision, audio, and multimodal domains. Use this skill to load models, perform inference, and fine-tune on custom data.\n\n## Installation\n\nInstall transformers and core dependencies:\n\n```bash\nuv pip install torch transformers datasets evaluate accelerate\n```\n\nFor vision tasks, add:\n```bash\nuv pip install timm pillow\n```\n\nFor audio tasks, add:\n```bash\nuv pip install librosa soundfile\n```\n\n## Authentication\n\nMany models on the Hugging Face Hub require authentication. Set up access:\n\n```python\nfrom huggingface_hub import login\nlogin()  # Follow prompts to enter token\n```\n\nOr set environment variable:\n```bash\nexport HUGGINGFACE_TOKEN=\"your_token_here\"\n```\n\nGet tokens at: https://huggingface.co/settings/tokens\n\n## Quick Start\n\nUse the Pipeline API for fast inference without manual configuration:\n\n```python\nfrom transformers import pipeline\n\n# Text generation\ngenerator = pipeline(\"text-generation\", model=\"gpt2\")\nresult = generator(\"The future of AI is\", max_length=50)\n\n# Text classification\nclassifier = pipeline(\"text-classification\")\nresult = classifier(\"This movie was excellent!\")\n\n# Question answering\nqa = pipeline(\"question-answering\")\nresult = qa(question=\"What is AI?\", context=\"AI is artificial intelligence...\")\n```\n\n## Core Capabilities\n\n### 1. Pipelines for Quick Inference\n\nUse for simple, optimized inference across many tasks. Supports text generation, classification, NER, question answering, summarization, translation, image classification, object detection, audio classification, and more.\n\n**When to use**: Quick prototyping, simple inference tasks, no custom preprocessing needed.\n\nSee `references/pipelines.md` for comprehensive task coverage and optimization.\n\n### 2. Model Loading and Management\n\nLoad pre-trained models with fine-grained control over configuration, device placement, and precision.\n\n**When to use**: "
  },
  {
    "id": "vaex",
    "name": "vaex",
    "description": "Use this skill for processing and analyzing large tabular datasets (billions of rows) that exceed available RAM. Vaex excels at out-of-core DataFrame operations, lazy evaluation, fast aggregations, efficient visualization of big data, and machine learning on large datasets. Apply when users need to ",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "vaex",
      "large",
      "datasets",
      "fast",
      "big",
      "processing",
      "analyzing",
      "tabular",
      "billions",
      "rows"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/vaex",
    "fullDescription": "\n# Vaex\n\n## Overview\n\nVaex is a high-performance Python library designed for lazy, out-of-core DataFrames to process and visualize tabular datasets that are too large to fit into RAM. Vaex can process over a billion rows per second, enabling interactive data exploration and analysis on datasets with billions of rows.\n\n## When to Use This Skill\n\nUse Vaex when:\n- Processing tabular datasets larger than available RAM (gigabytes to terabytes)\n- Performing fast statistical aggregations on massive datasets\n- Creating visualizations and heatmaps of large datasets\n- Building machine learning pipelines on big data\n- Converting between data formats (CSV, HDF5, Arrow, Parquet)\n- Needing lazy evaluation and virtual columns to avoid memory overhead\n- Working with astronomical data, financial time series, or other large-scale scientific datasets\n\n## Core Capabilities\n\nVaex provides six primary capability areas, each documented in detail in the references directory:\n\n### 1. DataFrames and Data Loading\n\nLoad and create Vaex DataFrames from various sources including files (HDF5, CSV, Arrow, Parquet), pandas DataFrames, NumPy arrays, and dictionaries. Reference `references/core_dataframes.md` for:\n- Opening large files efficiently\n- Converting from pandas/NumPy/Arrow\n- Working with example datasets\n- Understanding DataFrame structure\n\n### 2. Data Processing and Manipulation\n\nPerform filtering, create virtual columns, use expressions, and aggregate data without loading everything into memory. Reference `references/data_processing.md` for:\n- Filtering and selections\n- Virtual columns and expressions\n- Groupby operations and aggregations\n- String operations and datetime handling\n- Working with missing data\n\n### 3. Performance and Optimization\n\nLeverage Vaex's lazy evaluation, caching strategies, and memory-efficient operations. Reference `references/performance.md` for:\n- Understanding lazy evaluation\n- Using `delay=True` for batching operations\n- Materializing columns when needed\n- Cac"
  },
  {
    "id": "torch-geometric",
    "name": "torch-geometric",
    "description": "Graph Neural Networks (PyG). Node/graph classification, link prediction, GCN, GAT, GraphSAGE, heterogeneous graphs, molecular property prediction, for geometric deep learning.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "torch",
      "geometric",
      "graph",
      "prediction",
      "neural",
      "networks",
      "pyg",
      "node",
      "classification",
      "link"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/torch_geometric",
    "fullDescription": "\n# PyTorch Geometric (PyG)\n\n## Overview\n\nPyTorch Geometric is a library built on PyTorch for developing and training Graph Neural Networks (GNNs). Apply this skill for deep learning on graphs and irregular structures, including mini-batch processing, multi-GPU training, and geometric deep learning applications.\n\n## When to Use This Skill\n\nThis skill should be used when working with:\n- **Graph-based machine learning**: Node classification, graph classification, link prediction\n- **Molecular property prediction**: Drug discovery, chemical property prediction\n- **Social network analysis**: Community detection, influence prediction\n- **Citation networks**: Paper classification, recommendation systems\n- **3D geometric data**: Point clouds, meshes, molecular structures\n- **Heterogeneous graphs**: Multi-type nodes and edges (e.g., knowledge graphs)\n- **Large-scale graph learning**: Neighbor sampling, distributed training\n\n## Quick Start\n\n### Installation\n\n```bash\nuv pip install torch_geometric\n```\n\nFor additional dependencies (sparse operations, clustering):\n```bash\nuv pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n```\n\n### Basic Graph Creation\n\n```python\nimport torch\nfrom torch_geometric.data import Data\n\n# Create a simple graph with 3 nodes\nedge_index = torch.tensor([[0, 1, 1, 2],  # source nodes\n                           [1, 0, 2, 1]], dtype=torch.long)  # target nodes\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)  # node features\n\ndata = Data(x=x, edge_index=edge_index)\nprint(f\"Nodes: {data.num_nodes}, Edges: {data.num_edges}\")\n```\n\n### Loading a Benchmark Dataset\n\n```python\nfrom torch_geometric.datasets import Planetoid\n\n# Load Cora citation network\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\ndata = dataset[0]  # Get the first (and only) graph\n\nprint(f\"Dataset: {dataset}\")\nprint(f\"Nodes: {data.num_nodes}, Edges: {data.num_edges}\")\nprint(f\"Features: {data.num_node_fe"
  },
  {
    "id": "sympy",
    "name": "sympy",
    "description": "Use this skill when working with symbolic mathematics in Python. This skill should be used for symbolic computation tasks including solving equations algebraically, performing calculus operations (derivatives, integrals, limits), manipulating algebraic expressions, working with matrices symbolically",
    "category": "physics-materials",
    "source": "scientific",
    "triggers": [
      "sympy",
      "symbolic",
      "expressions",
      "mathematical",
      "mathematics",
      "computation",
      "tasks",
      "solving",
      "equations",
      "algebraically"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/sympy",
    "fullDescription": "\n# SymPy - Symbolic Mathematics in Python\n\n## Overview\n\nSymPy is a Python library for symbolic mathematics that enables exact computation using mathematical symbols rather than numerical approximations. This skill provides comprehensive guidance for performing symbolic algebra, calculus, linear algebra, equation solving, physics calculations, and code generation using SymPy.\n\n## When to Use This Skill\n\nUse this skill when:\n- Solving equations symbolically (algebraic, differential, systems of equations)\n- Performing calculus operations (derivatives, integrals, limits, series)\n- Manipulating and simplifying algebraic expressions\n- Working with matrices and linear algebra symbolically\n- Doing physics calculations (mechanics, quantum mechanics, vector analysis)\n- Number theory computations (primes, factorization, modular arithmetic)\n- Geometric calculations (2D/3D geometry, analytic geometry)\n- Converting mathematical expressions to executable code (Python, C, Fortran)\n- Generating LaTeX or other formatted mathematical output\n- Needing exact mathematical results (e.g., `sqrt(2)` not `1.414...`)\n\n## Core Capabilities\n\n### 1. Symbolic Computation Basics\n\n**Creating symbols and expressions:**\n```python\nfrom sympy import symbols, Symbol\nx, y, z = symbols('x y z')\nexpr = x**2 + 2*x + 1\n\n# With assumptions\nx = symbols('x', real=True, positive=True)\nn = symbols('n', integer=True)\n```\n\n**Simplification and manipulation:**\n```python\nfrom sympy import simplify, expand, factor, cancel\nsimplify(sin(x)**2 + cos(x)**2)  # Returns 1\nexpand((x + 1)**3)  # x**3 + 3*x**2 + 3*x + 1\nfactor(x**2 - 1)    # (x - 1)*(x + 1)\n```\n\n**For detailed basics:** See `references/core-capabilities.md`\n\n### 2. Calculus\n\n**Derivatives:**\n```python\nfrom sympy import diff\ndiff(x**2, x)        # 2*x\ndiff(x**4, x, 3)     # 24*x (third derivative)\ndiff(x**2*y**3, x, y)  # 6*x*y**2 (partial derivatives)\n```\n\n**Integrals:**\n```python\nfrom sympy import integrate, oo\nintegrate(x**2, x)              # x**3/3 (indefi"
  },
  {
    "id": "torchdrug",
    "name": "torchdrug",
    "description": "Graph-based drug discovery toolkit. Molecular property prediction (ADMET), protein modeling, knowledge graph reasoning, molecular generation, retrosynthesis, GNNs (GIN, GAT, SchNet), 40+ datasets, for PyTorch-based ML on molecules, proteins, and biomedical graphs.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "torchdrug",
      "molecular",
      "graph-based",
      "drug",
      "discovery",
      "property",
      "prediction",
      "admet",
      "protein",
      "modeling"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/torchdrug",
    "fullDescription": "\n# TorchDrug\n\n## Overview\n\nTorchDrug is a comprehensive PyTorch-based machine learning toolbox for drug discovery and molecular science. Apply graph neural networks, pre-trained models, and task definitions to molecules, proteins, and biological knowledge graphs, including molecular property prediction, protein modeling, knowledge graph reasoning, molecular generation, retrosynthesis planning, with 40+ curated datasets and 20+ model architectures.\n\n## When to Use This Skill\n\nThis skill should be used when working with:\n\n**Data Types:**\n- SMILES strings or molecular structures\n- Protein sequences or 3D structures (PDB files)\n- Chemical reactions and retrosynthesis\n- Biomedical knowledge graphs\n- Drug discovery datasets\n\n**Tasks:**\n- Predicting molecular properties (solubility, toxicity, activity)\n- Protein function or structure prediction\n- Drug-target binding prediction\n- Generating new molecular structures\n- Planning chemical synthesis routes\n- Link prediction in biomedical knowledge bases\n- Training graph neural networks on scientific data\n\n**Libraries and Integration:**\n- TorchDrug is the primary library\n- Often used with RDKit for cheminformatics\n- Compatible with PyTorch and PyTorch Lightning\n- Integrates with AlphaFold and ESM for proteins\n\n## Getting Started\n\n### Installation\n\n```bash\nuv pip install torchdrug\n# Or with optional dependencies\nuv pip install torchdrug[full]\n```\n\n### Quick Example\n\n```python\nfrom torchdrug import datasets, models, tasks\nfrom torch.utils.data import DataLoader\n\n# Load molecular dataset\ndataset = datasets.BBBP(\"~/molecule-datasets/\")\ntrain_set, valid_set, test_set = dataset.split()\n\n# Define GNN model\nmodel = models.GIN(\n    input_dim=dataset.node_feature_dim,\n    hidden_dims=[256, 256, 256],\n    edge_input_dim=dataset.edge_feature_dim,\n    batch_norm=True,\n    readout=\"mean\"\n)\n\n# Create property prediction task\ntask = tasks.PropertyPrediction(\n    model,\n    task=dataset.tasks,\n    criterion=\"bce\",\n    metric=[\"auroc\", \"auprc\"]\n)\n"
  },
  {
    "id": "venue-templates",
    "name": "venue-templates",
    "description": "Access comprehensive LaTeX templates, formatting requirements, and submission guidelines for major scientific publication venues (Nature, Science, PLOS, IEEE, ACM), academic conferences (NeurIPS, ICML, CVPR, CHI), research posters, and grant proposals (NSF, NIH, DOE, DARPA). This skill should be use",
    "category": "sci-communication",
    "source": "scientific",
    "triggers": [
      "venue",
      "templates",
      "formatting",
      "requirements",
      "submission",
      "posters",
      "grant",
      "proposals",
      "latex",
      "guidelines"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/venue-templates",
    "fullDescription": "\n# Venue Templates\n\n## Overview\n\nAccess comprehensive LaTeX templates, formatting requirements, and submission guidelines for major scientific publication venues, academic conferences, research posters, and grant proposals. This skill provides ready-to-use templates and detailed specifications for successful academic submissions across disciplines.\n\nUse this skill when preparing manuscripts for journal submission, conference papers, research posters, or grant proposals and need venue-specific formatting requirements and templates.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Preparing a manuscript for submission to a specific journal (Nature, Science, PLOS, IEEE, etc.)\n- Writing a conference paper with specific formatting requirements (NeurIPS, ICML, CHI, etc.)\n- Creating an academic research poster for conferences\n- Drafting grant proposals for federal agencies (NSF, NIH, DOE, DARPA) or private foundations\n- Checking formatting requirements and page limits for target venues\n- Customizing templates with author information and project details\n- Verifying document compliance with venue specifications\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with p"
  },
  {
    "id": "string-database",
    "name": "string-database",
    "description": "Query STRING API for protein-protein interactions (59M proteins, 20B interactions). Network analysis, GO/KEGG enrichment, interaction discovery, 5000+ species, for systems biology.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "string",
      "interactions",
      "protein-protein",
      "59m",
      "proteins",
      "20b",
      "network",
      "kegg",
      "enrichment",
      "interaction"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/string-database",
    "fullDescription": "\n# STRING Database\n\n## Overview\n\nSTRING is a comprehensive database of known and predicted protein-protein interactions covering 59M proteins and 20B+ interactions across 5000+ organisms. Query interaction networks, perform functional enrichment, discover partners via REST API for systems biology and pathway analysis.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Retrieving protein-protein interaction networks for single or multiple proteins\n- Performing functional enrichment analysis (GO, KEGG, Pfam) on protein lists\n- Discovering interaction partners and expanding protein networks\n- Testing if proteins form significantly enriched functional modules\n- Generating network visualizations with evidence-based coloring\n- Analyzing homology and protein family relationships\n- Conducting cross-species protein interaction comparisons\n- Identifying hub proteins and network connectivity patterns\n\n## Quick Start\n\nThe skill provides:\n1. Python helper functions (`scripts/string_api.py`) for all STRING REST API operations\n2. Comprehensive reference documentation (`references/string_reference.md`) with detailed API specifications\n\nWhen users request STRING data, determine which operation is needed and use the appropriate function from `scripts/string_api.py`.\n\n## Core Operations\n\n### 1. Identifier Mapping (`string_map_ids`)\n\nConvert gene names, protein names, and external IDs to STRING identifiers.\n\n**When to use**: Starting any STRING analysis, validating protein names, finding canonical identifiers.\n\n**Usage**:\n```python\nfrom scripts.string_api import string_map_ids\n\n# Map single protein\nresult = string_map_ids('TP53', species=9606)\n\n# Map multiple proteins\nresult = string_map_ids(['TP53', 'BRCA1', 'EGFR', 'MDM2'], species=9606)\n\n# Map with multiple matches per query\nresult = string_map_ids('p53', species=9606, limit=5)\n```\n\n**Parameters**:\n- `species`: NCBI taxon ID (9606 = human, 10090 = mouse, 7227 = fly)\n- `limit`: Number of matches per identifier (default: 1)"
  },
  {
    "id": "statsmodels",
    "name": "statsmodels",
    "description": "Statistical modeling toolkit. OLS, GLM, logistic, ARIMA, time series, hypothesis tests, diagnostics, AIC/BIC, for rigorous statistical inference and econometric analysis.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "statsmodels",
      "statistical",
      "modeling",
      "ols",
      "glm",
      "logistic",
      "arima",
      "time",
      "series",
      "hypothesis"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/statsmodels",
    "fullDescription": "\n# Statsmodels: Statistical Modeling and Econometrics\n\n## Overview\n\nStatsmodels is Python's premier library for statistical modeling, providing tools for estimation, inference, and diagnostics across a wide range of statistical methods. Apply this skill for rigorous statistical analysis, from simple linear regression to complex time series models and econometric analyses.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Fitting regression models (OLS, WLS, GLS, quantile regression)\n- Performing generalized linear modeling (logistic, Poisson, Gamma, etc.)\n- Analyzing discrete outcomes (binary, multinomial, count, ordinal)\n- Conducting time series analysis (ARIMA, SARIMAX, VAR, forecasting)\n- Running statistical tests and diagnostics\n- Testing model assumptions (heteroskedasticity, autocorrelation, normality)\n- Detecting outliers and influential observations\n- Comparing models (AIC/BIC, likelihood ratio tests)\n- Estimating causal effects\n- Producing publication-ready statistical tables and inference\n\n## Quick Start Guide\n\n### Linear Regression (OLS)\n\n```python\nimport statsmodels.api as sm\nimport numpy as np\nimport pandas as pd\n\n# Prepare data - ALWAYS add constant for intercept\nX = sm.add_constant(X_data)\n\n# Fit OLS model\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n# View comprehensive results\nprint(results.summary())\n\n# Key results\nprint(f\"R-squared: {results.rsquared:.4f}\")\nprint(f\"Coefficients:\\\\n{results.params}\")\nprint(f\"P-values:\\\\n{results.pvalues}\")\n\n# Predictions with confidence intervals\npredictions = results.get_prediction(X_new)\npred_summary = predictions.summary_frame()\nprint(pred_summary)  # includes mean, CI, prediction intervals\n\n# Diagnostics\nfrom statsmodels.stats.diagnostic import het_breuschpagan\nbp_test = het_breuschpagan(results.resid, X)\nprint(f\"Breusch-Pagan p-value: {bp_test[1]:.4f}\")\n\n# Visualize residuals\nimport matplotlib.pyplot as plt\nplt.scatter(results.fittedvalues, results.resid)\nplt.axhline(y=0, color='r', linestyle='--')\n"
  },
  {
    "id": "statistical-analysis",
    "name": "statistical-analysis",
    "description": "Statistical analysis toolkit. Hypothesis tests (t-test, ANOVA, chi-square), regression, correlation, Bayesian stats, power analysis, assumption checks, APA reporting, for academic research.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "statistical",
      "hypothesis",
      "tests",
      "t-test",
      "anova",
      "chi-square",
      "regression",
      "correlation",
      "bayesian",
      "stats"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/statistical-analysis",
    "fullDescription": "\n# Statistical Analysis\n\n## Overview\n\nStatistical analysis is a systematic process for testing hypotheses and quantifying relationships. Conduct hypothesis tests (t-test, ANOVA, chi-square), regression, correlation, and Bayesian analyses with assumption checks and APA reporting. Apply this skill for academic research.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Conducting statistical hypothesis tests (t-tests, ANOVA, chi-square)\n- Performing regression or correlation analyses\n- Running Bayesian statistical analyses\n- Checking statistical assumptions and diagnostics\n- Calculating effect sizes and conducting power analyses\n- Reporting statistical results in APA format\n- Analyzing experimental or observational data for research\n\n---\n\n## Core Capabilities\n\n### 1. Test Selection and Planning\n- Choose appropriate statistical tests based on research questions and data characteristics\n- Conduct a priori power analyses to determine required sample sizes\n- Plan analysis strategies including multiple comparison corrections\n\n### 2. Assumption Checking\n- Automatically verify all relevant assumptions before running tests\n- Provide diagnostic visualizations (Q-Q plots, residual plots, box plots)\n- Recommend remedial actions when assumptions are violated\n\n### 3. Statistical Testing\n- Hypothesis testing: t-tests, ANOVA, chi-square, non-parametric alternatives\n- Regression: linear, multiple, logistic, with diagnostics\n- Correlations: Pearson, Spearman, with confidence intervals\n- Bayesian alternatives: Bayesian t-tests, ANOVA, regression with Bayes Factors\n\n### 4. Effect Sizes and Interpretation\n- Calculate and interpret appropriate effect sizes for all analyses\n- Provide confidence intervals for effect estimates\n- Distinguish statistical from practical significance\n\n### 5. Professional Reporting\n- Generate APA-style statistical reports\n- Create publication-ready figures and tables\n- Provide complete interpretation with all required statistics\n\n---\n\n## Workflow Deci"
  },
  {
    "id": "simpy",
    "name": "simpy",
    "description": "Process-based discrete-event simulation framework in Python. Use this skill when building simulations of systems with processes, queues, resources, and time-based events such as manufacturing systems, service operations, network traffic, logistics, or any system where entities interact with shared r",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "simpy",
      "systems",
      "resources",
      "process-based",
      "discrete-event",
      "simulation",
      "simulations",
      "processes",
      "queues",
      "time-based"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/simpy",
    "fullDescription": "\n# SimPy - Discrete-Event Simulation\n\n## Overview\n\nSimPy is a process-based discrete-event simulation framework based on standard Python. Use SimPy to model systems where entities (customers, vehicles, packets, etc.) interact with each other and compete for shared resources (servers, machines, bandwidth, etc.) over time.\n\n**Core capabilities:**\n- Process modeling using Python generator functions\n- Shared resource management (servers, containers, stores)\n- Event-driven scheduling and synchronization\n- Real-time simulations synchronized with wall-clock time\n- Comprehensive monitoring and data collection\n\n## When to Use This Skill\n\nUse the SimPy skill when:\n\n1. **Modeling discrete-event systems** - Systems where events occur at irregular intervals\n2. **Resource contention** - Entities compete for limited resources (servers, machines, staff)\n3. **Queue analysis** - Studying waiting lines, service times, and throughput\n4. **Process optimization** - Analyzing manufacturing, logistics, or service processes\n5. **Network simulation** - Packet routing, bandwidth allocation, latency analysis\n6. **Capacity planning** - Determining optimal resource levels for desired performance\n7. **System validation** - Testing system behavior before implementation\n\n**Not suitable for:**\n- Continuous simulations with fixed time steps (consider SciPy ODE solvers)\n- Independent processes without resource sharing\n- Pure mathematical optimization (consider SciPy optimize)\n\n## Quick Start\n\n### Basic Simulation Structure\n\n```python\nimport simpy\n\ndef process(env, name):\n    \"\"\"A simple process that waits and prints.\"\"\"\n    print(f'{name} starting at {env.now}')\n    yield env.timeout(5)\n    print(f'{name} finishing at {env.now}')\n\n# Create environment\nenv = simpy.Environment()\n\n# Start processes\nenv.process(process(env, 'Process 1'))\nenv.process(process(env, 'Process 2'))\n\n# Run simulation\nenv.run(until=10)\n```\n\n### Resource Usage Pattern\n\n```python\nimport simpy\n\ndef customer(env, name, resource):\n   "
  },
  {
    "id": "shap",
    "name": "shap",
    "description": "Model interpretability and explainability using SHAP (SHapley Additive exPlanations). Use this skill when explaining machine learning model predictions, computing feature importance, generating SHAP plots (waterfall, beeswarm, bar, scatter, force, heatmap), debugging models, analyzing model bias or ",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "shap",
      "model",
      "interpretability",
      "explainability",
      "shapley",
      "additive",
      "explanations",
      "explaining",
      "machine",
      "predictions"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/shap",
    "fullDescription": "\n# SHAP (SHapley Additive exPlanations)\n\n## Overview\n\nSHAP is a unified approach to explain machine learning model outputs using Shapley values from cooperative game theory. This skill provides comprehensive guidance for:\n\n- Computing SHAP values for any model type\n- Creating visualizations to understand feature importance\n- Debugging and validating model behavior\n- Analyzing fairness and bias\n- Implementing explainable AI in production\n\nSHAP works with all model types: tree-based models (XGBoost, LightGBM, CatBoost, Random Forest), deep learning models (TensorFlow, PyTorch, Keras), linear models, and black-box models.\n\n## When to Use This Skill\n\n**Trigger this skill when users ask about**:\n- \"Explain which features are most important in my model\"\n- \"Generate SHAP plots\" (waterfall, beeswarm, bar, scatter, force, heatmap, etc.)\n- \"Why did my model make this prediction?\"\n- \"Calculate SHAP values for my model\"\n- \"Visualize feature importance using SHAP\"\n- \"Debug my model's behavior\" or \"validate my model\"\n- \"Check my model for bias\" or \"analyze fairness\"\n- \"Compare feature importance across models\"\n- \"Implement explainable AI\" or \"add explanations to my model\"\n- \"Understand feature interactions\"\n- \"Create model interpretation dashboard\"\n\n## Quick Start Guide\n\n### Step 1: Select the Right Explainer\n\n**Decision Tree**:\n\n1. **Tree-based model?** (XGBoost, LightGBM, CatBoost, Random Forest, Gradient Boosting)\n   - Use `shap.TreeExplainer` (fast, exact)\n\n2. **Deep neural network?** (TensorFlow, PyTorch, Keras, CNNs, RNNs, Transformers)\n   - Use `shap.DeepExplainer` or `shap.GradientExplainer`\n\n3. **Linear model?** (Linear/Logistic Regression, GLMs)\n   - Use `shap.LinearExplainer` (extremely fast)\n\n4. **Any other model?** (SVMs, custom functions, black-box models)\n   - Use `shap.KernelExplainer` (model-agnostic but slower)\n\n5. **Unsure?**\n   - Use `shap.Explainer` (automatically selects best algorithm)\n\n**See `references/explainers.md` for detailed information on all explai"
  },
  {
    "id": "seaborn",
    "name": "seaborn",
    "description": "Statistical visualization. Scatter, box, violin, heatmaps, pair plots, regression, correlation matrices, KDE, faceted plots, for exploratory analysis and publication figures.",
    "category": "sci-communication",
    "source": "scientific",
    "triggers": [
      "seaborn",
      "plots",
      "statistical",
      "visualization",
      "scatter",
      "box",
      "violin",
      "heatmaps",
      "pair",
      "regression"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/seaborn",
    "fullDescription": "\n# Seaborn Statistical Visualization\n\n## Overview\n\nSeaborn is a Python visualization library for creating publication-quality statistical graphics. Use this skill for dataset-oriented plotting, multivariate analysis, automatic statistical estimation, and complex multi-panel figures with minimal code.\n\n## Design Philosophy\n\nSeaborn follows these core principles:\n\n1. **Dataset-oriented**: Work directly with DataFrames and named variables rather than abstract coordinates\n2. **Semantic mapping**: Automatically translate data values into visual properties (colors, sizes, styles)\n3. **Statistical awareness**: Built-in aggregation, error estimation, and confidence intervals\n4. **Aesthetic defaults**: Publication-ready themes and color palettes out of the box\n5. **Matplotlib integration**: Full compatibility with matplotlib customization when needed\n\n## Quick Start\n\n```python\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load example dataset\ndf = sns.load_dataset('tips')\n\n# Create a simple visualization\nsns.scatterplot(data=df, x='total_bill', y='tip', hue='day')\nplt.show()\n```\n\n## Core Plotting Interfaces\n\n### Function Interface (Traditional)\n\nThe function interface provides specialized plotting functions organized by visualization type. Each category has **axes-level** functions (plot to single axes) and **figure-level** functions (manage entire figure with faceting).\n\n**When to use:**\n- Quick exploratory analysis\n- Single-purpose visualizations\n- When you need a specific plot type\n\n### Objects Interface (Modern)\n\nThe `seaborn.objects` interface provides a declarative, composable API similar to ggplot2. Build visualizations by chaining methods to specify data mappings, marks, transformations, and scales.\n\n**When to use:**\n- Complex layered visualizations\n- When you need fine-grained control over transformations\n- Building custom plot types\n- Programmatic plot generation\n\n```python\nfrom seaborn import objects as so\n\n# Declarative syntax\n(\n   "
  },
  {
    "id": "scvi-tools",
    "name": "scvi-tools",
    "description": "This skill should be used when working with single-cell omics data analysis using scvi-tools, including scRNA-seq, scATAC-seq, CITE-seq, spatial transcriptomics, and other single-cell modalities. Use this skill for probabilistic modeling, batch correction, dimensionality reduction, differential expr",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "scvi",
      "tools",
      "single-cell",
      "scvi-tools",
      "spatial",
      "omics",
      "scrna-seq",
      "scatac-seq",
      "cite-seq",
      "transcriptomics"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scvi-tools",
    "fullDescription": "\n# scvi-tools\n\n## Overview\n\nscvi-tools is a comprehensive Python framework for probabilistic models in single-cell genomics. Built on PyTorch and PyTorch Lightning, it provides deep generative models using variational inference for analyzing diverse single-cell data modalities.\n\n## When to Use This Skill\n\nUse this skill when:\n- Analyzing single-cell RNA-seq data (dimensionality reduction, batch correction, integration)\n- Working with single-cell ATAC-seq or chromatin accessibility data\n- Integrating multimodal data (CITE-seq, multiome, paired/unpaired datasets)\n- Analyzing spatial transcriptomics data (deconvolution, spatial mapping)\n- Performing differential expression analysis on single-cell data\n- Conducting cell type annotation or transfer learning tasks\n- Working with specialized single-cell modalities (methylation, cytometry, RNA velocity)\n- Building custom probabilistic models for single-cell analysis\n\n## Core Capabilities\n\nscvi-tools provides models organized by data modality:\n\n### 1. Single-Cell RNA-seq Analysis\nCore models for expression analysis, batch correction, and integration. See `references/models-scrna-seq.md` for:\n- **scVI**: Unsupervised dimensionality reduction and batch correction\n- **scANVI**: Semi-supervised cell type annotation and integration\n- **AUTOZI**: Zero-inflation detection and modeling\n- **VeloVI**: RNA velocity analysis\n- **contrastiveVI**: Perturbation effect isolation\n\n### 2. Chromatin Accessibility (ATAC-seq)\nModels for analyzing single-cell chromatin data. See `references/models-atac-seq.md` for:\n- **PeakVI**: Peak-based ATAC-seq analysis and integration\n- **PoissonVI**: Quantitative fragment count modeling\n- **scBasset**: Deep learning approach with motif analysis\n\n### 3. Multimodal & Multi-omics Integration\nJoint analysis of multiple data types. See `references/models-multimodal.md` for:\n- **totalVI**: CITE-seq protein and RNA joint modeling\n- **MultiVI**: Paired and unpaired multi-omic integration\n- **MrVI**: Multi-resolutio"
  },
  {
    "id": "stable-baselines3",
    "name": "stable-baselines3",
    "description": "Use this skill for reinforcement learning tasks including training RL agents (PPO, SAC, DQN, TD3, DDPG, A2C, etc.), creating custom Gym environments, implementing callbacks for monitoring and control, using vectorized environments for parallel training, and integrating with deep RL workflows. This s",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "stable",
      "baselines3",
      "training",
      "environments",
      "reinforcement",
      "tasks",
      "agents",
      "ppo",
      "sac",
      "dqn"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/stable-baselines3",
    "fullDescription": "\n# Stable Baselines3\n\n## Overview\n\nStable Baselines3 (SB3) is a PyTorch-based library providing reliable implementations of reinforcement learning algorithms. This skill provides comprehensive guidance for training RL agents, creating custom environments, implementing callbacks, and optimizing training workflows using SB3's unified API.\n\n## Core Capabilities\n\n### 1. Training RL Agents\n\n**Basic Training Pattern:**\n\n```python\nimport gymnasium as gym\nfrom stable_baselines3 import PPO\n\n# Create environment\nenv = gym.make(\"CartPole-v1\")\n\n# Initialize agent\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\n\n# Train the agent\nmodel.learn(total_timesteps=10000)\n\n# Save the model\nmodel.save(\"ppo_cartpole\")\n\n# Load the model (without prior instantiation)\nmodel = PPO.load(\"ppo_cartpole\", env=env)\n```\n\n**Important Notes:**\n- `total_timesteps` is a lower bound; actual training may exceed this due to batch collection\n- Use `model.load()` as a static method, not on an existing instance\n- The replay buffer is NOT saved with the model to save space\n\n**Algorithm Selection:**\nUse `references/algorithms.md` for detailed algorithm characteristics and selection guidance. Quick reference:\n- **PPO/A2C**: General-purpose, supports all action space types, good for multiprocessing\n- **SAC/TD3**: Continuous control, off-policy, sample-efficient\n- **DQN**: Discrete actions, off-policy\n- **HER**: Goal-conditioned tasks\n\nSee `scripts/train_rl_agent.py` for a complete training template with best practices.\n\n### 2. Custom Environments\n\n**Requirements:**\nCustom environments must inherit from `gymnasium.Env` and implement:\n- `__init__()`: Define action_space and observation_space\n- `reset(seed, options)`: Return initial observation and info dict\n- `step(action)`: Return observation, reward, terminated, truncated, info\n- `render()`: Visualization (optional)\n- `close()`: Cleanup resources\n\n**Key Constraints:**\n- Image observations must be `np.uint8` in range [0, 255]\n- Use channel-first format when possible (ch"
  },
  {
    "id": "scikit-survival",
    "name": "scikit-survival",
    "description": "Comprehensive toolkit for survival analysis and time-to-event modeling in Python using scikit-survival. Use this skill when working with censored survival data, performing time-to-event analysis, fitting Cox models, Random Survival Forests, Gradient Boosting models, or Survival SVMs, evaluating surv",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "scikit",
      "survival",
      "scikit-survival",
      "time-to-event",
      "modeling",
      "censored",
      "performing",
      "fitting",
      "cox",
      "random"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scikit-survival",
    "fullDescription": "\n# scikit-survival: Survival Analysis in Python\n\n## Overview\n\nscikit-survival is a Python library for survival analysis built on top of scikit-learn. It provides specialized tools for time-to-event analysis, handling the unique challenge of censored data where some observations are only partially known.\n\nSurvival analysis aims to establish connections between covariates and the time of an event, accounting for censored records (particularly right-censored data from studies where participants don't experience events during observation periods).\n\n## When to Use This Skill\n\nUse this skill when:\n- Performing survival analysis or time-to-event modeling\n- Working with censored data (right-censored, left-censored, or interval-censored)\n- Fitting Cox proportional hazards models (standard or penalized)\n- Building ensemble survival models (Random Survival Forests, Gradient Boosting)\n- Training Survival Support Vector Machines\n- Evaluating survival model performance (concordance index, Brier score, time-dependent AUC)\n- Estimating Kaplan-Meier or Nelson-Aalen curves\n- Analyzing competing risks\n- Preprocessing survival data or handling missing values in survival datasets\n- Conducting any analysis using the scikit-survival library\n\n## Core Capabilities\n\n### 1. Model Types and Selection\n\nscikit-survival provides multiple model families, each suited for different scenarios:\n\n#### Cox Proportional Hazards Models\n**Use for**: Standard survival analysis with interpretable coefficients\n- `CoxPHSurvivalAnalysis`: Basic Cox model\n- `CoxnetSurvivalAnalysis`: Penalized Cox with elastic net for high-dimensional data\n- `IPCRidge`: Ridge regression for accelerated failure time models\n\n**See**: `references/cox-models.md` for detailed guidance on Cox models, regularization, and interpretation\n\n#### Ensemble Methods\n**Use for**: High predictive performance with complex non-linear relationships\n- `RandomSurvivalForest`: Robust, non-parametric ensemble method\n- `GradientBoostingSurvivalAnalysis`:"
  },
  {
    "id": "scikit-learn",
    "name": "scikit-learn",
    "description": "Machine learning in Python with scikit-learn. Use when working with supervised learning (classification, regression), unsupervised learning (clustering, dimensionality reduction), model evaluation, hyperparameter tuning, preprocessing, or building ML pipelines. Provides comprehensive reference docum",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "scikit",
      "learn",
      "scikit-learn",
      "preprocessing",
      "pipelines",
      "machine",
      "supervised",
      "classification",
      "regression",
      "unsupervised"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scikit-learn",
    "fullDescription": "\n# Scikit-learn\n\n## Overview\n\nThis skill provides comprehensive guidance for machine learning tasks using scikit-learn, the industry-standard Python library for classical machine learning. Use this skill for classification, regression, clustering, dimensionality reduction, preprocessing, model evaluation, and building production-ready ML pipelines.\n\n## Installation\n\n```bash\n# Install scikit-learn using uv\nuv uv pip install scikit-learn\n\n# Optional: Install visualization dependencies\nuv uv pip install matplotlib seaborn\n\n# Commonly used with\nuv uv pip install pandas numpy\n```\n\n## When to Use This Skill\n\nUse the scikit-learn skill when:\n\n- Building classification or regression models\n- Performing clustering or dimensionality reduction\n- Preprocessing and transforming data for machine learning\n- Evaluating model performance with cross-validation\n- Tuning hyperparameters with grid or random search\n- Creating ML pipelines for production workflows\n- Comparing different algorithms for a task\n- Working with both structured (tabular) and text data\n- Need interpretable, classical machine learning approaches\n\n## Quick Start\n\n### Classification Example\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# Preprocess\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# Evaluate\ny_pred = model.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred))\n```\n\n### Complete Pipeline with Mixed Data\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing "
  },
  {
    "id": "scikit-bio",
    "name": "scikit-bio",
    "description": "Biological data toolkit. Sequence analysis, alignments, phylogenetic trees, diversity metrics (alpha/beta, UniFrac), ordination (PCoA), PERMANOVA, FASTA/Newick I/O, for microbiome analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "scikit",
      "bio",
      "biological",
      "sequence",
      "alignments",
      "phylogenetic",
      "trees",
      "diversity",
      "metrics",
      "alpha"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scikit-bio",
    "fullDescription": "\n# scikit-bio\n\n## Overview\n\nscikit-bio is a comprehensive Python library for working with biological data. Apply this skill for bioinformatics analyses spanning sequence manipulation, alignment, phylogenetics, microbial ecology, and multivariate statistics.\n\n## When to Use This Skill\n\nThis skill should be used when the user:\n- Works with biological sequences (DNA, RNA, protein)\n- Needs to read/write biological file formats (FASTA, FASTQ, GenBank, Newick, BIOM, etc.)\n- Performs sequence alignments or searches for motifs\n- Constructs or analyzes phylogenetic trees\n- Calculates diversity metrics (alpha/beta diversity, UniFrac distances)\n- Performs ordination analysis (PCoA, CCA, RDA)\n- Runs statistical tests on biological/ecological data (PERMANOVA, ANOSIM, Mantel)\n- Analyzes microbiome or community ecology data\n- Works with protein embeddings from language models\n- Needs to manipulate biological data tables\n\n## Core Capabilities\n\n### 1. Sequence Manipulation\n\nWork with biological sequences using specialized classes for DNA, RNA, and protein data.\n\n**Key operations:**\n- Read/write sequences from FASTA, FASTQ, GenBank, EMBL formats\n- Sequence slicing, concatenation, and searching\n- Reverse complement, transcription (DNAâ†’RNA), and translation (RNAâ†’protein)\n- Find motifs and patterns using regex\n- Calculate distances (Hamming, k-mer based)\n- Handle sequence quality scores and metadata\n\n**Common patterns:**\n```python\nimport skbio\n\n# Read sequences from file\nseq = skbio.DNA.read('input.fasta')\n\n# Sequence operations\nrc = seq.reverse_complement()\nrna = seq.transcribe()\nprotein = rna.translate()\n\n# Find motifs\nmotif_positions = seq.find_with_regex('ATG[ACGT]{3}')\n\n# Check for properties\nhas_degens = seq.has_degenerates()\nseq_no_gaps = seq.degap()\n```\n\n**Important notes:**\n- Use `DNA`, `RNA`, `Protein` classes for grammared sequences with validation\n- Use `Sequence` class for generic sequences without alphabet restrictions\n- Quality scores automatically loaded from FASTQ files"
  },
  {
    "id": "scientific-writing",
    "name": "scientific-writing",
    "description": "Core skill for the deep research and writing tool. Write scientific manuscripts in full paragraphs (never bullet points). Use two-stage process: (1) create section outlines with key points using research-lookup, (2) convert to flowing prose. IMRAD structure, citations (APA/AMA/Vancouver), figures/ta",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "scientific",
      "writing",
      "points",
      "core",
      "deep",
      "tool",
      "write",
      "manuscripts",
      "full",
      "paragraphs"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-writing",
    "fullDescription": "\n# Scientific Writing\n\n## Overview\n\n**This is the core skill for the deep research and writing tool**â€”combining AI-driven deep research with well-formatted written outputs. Every document produced is backed by comprehensive literature search and verified citations through the research-lookup skill.\n\nScientific writing is a process for communicating research with precision and clarity. Write manuscripts using IMRAD structure, citations (APA/AMA/Vancouver), figures/tables, and reporting guidelines (CONSORT/STROBE/PRISMA). Apply this skill for research papers and journal submissions.\n\n**Critical Principle: Always write in full paragraphs with flowing prose. Never submit bullet points in the final manuscript.** Use a two-stage process: first create section outlines with key points using research-lookup, then convert those outlines into complete paragraphs.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Writing or revising any section of a scientific manuscript (abstract, introduction, methods, results, discussion)\n- Structuring a research paper using IMRAD or other standard formats\n- Formatting citations and references in specific styles (APA, AMA, Vancouver, Chicago, IEEE)\n- Creating, formatting, or improving figures, tables, and data visualizations\n- Applying study-specific reporting guidelines (CONSORT for trials, STROBE for observational studies, PRISMA for reviews)\n- Drafting abstracts that meet journal requirements (structured or unstructured)\n- Preparing manuscripts for submission to specific journals\n- Improving writing clarity, conciseness, and precision\n- Ensuring proper use of field-specific terminology and nomenclature\n- Addressing reviewer comments and revising manuscripts\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every scientific paper MUST include at least 1-2 AI-generated figures using the scientific-schematics skill.**\n\nThis is not optional. Scientific papers without visual elements are incomplete. Before finalizi"
  },
  {
    "id": "scientific-visualization",
    "name": "scientific-visualization",
    "description": "Create publication figures with matplotlib/seaborn/plotly. Multi-panel layouts, error bars, significance markers, colorblind-safe, export PDF/EPS/TIFF, for journal-ready scientific plots.",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "scientific",
      "visualization",
      "publication",
      "figures",
      "matplotlib",
      "seaborn",
      "plotly",
      "multi-panel",
      "layouts",
      "error"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-visualization",
    "fullDescription": "\n# Scientific Visualization\n\n## Overview\n\nScientific visualization transforms data into clear, accurate figures for publication. Create journal-ready plots with multi-panel layouts, error bars, significance markers, and colorblind-safe palettes. Export as PDF/EPS/TIFF using matplotlib, seaborn, and plotly for manuscripts.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating plots or visualizations for scientific manuscripts\n- Preparing figures for journal submission (Nature, Science, Cell, PLOS, etc.)\n- Ensuring figures are colorblind-friendly and accessible\n- Making multi-panel figures with consistent styling\n- Exporting figures at correct resolution and format\n- Following specific publication guidelines\n- Improving existing figures to meet publication standards\n- Creating figures that need to work in both color and grayscale\n\n## Quick Start Guide\n\n### Basic Publication-Quality Figure\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Apply publication style (from scripts/style_presets.py)\nfrom style_presets import apply_publication_style\napply_publication_style('default')\n\n# Create figure with appropriate size (single column = 3.5 inches)\nfig, ax = plt.subplots(figsize=(3.5, 2.5))\n\n# Plot data\nx = np.linspace(0, 10, 100)\nax.plot(x, np.sin(x), label='sin(x)')\nax.plot(x, np.cos(x), label='cos(x)')\n\n# Proper labeling with units\nax.set_xlabel('Time (seconds)')\nax.set_ylabel('Amplitude (mV)')\nax.legend(frameon=False)\n\n# Remove unnecessary spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Save in publication formats (from scripts/figure_export.py)\nfrom figure_export import save_publication_figure\nsave_publication_figure(fig, 'figure1', formats=['pdf', 'png'], dpi=300)\n```\n\n### Using Pre-configured Styles\n\nApply journal-specific styles using the matplotlib style files in `assets/`:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Option 1: Use style file directly\nplt.style.use('assets/nature.mplstyle')\n\n# Opt"
  },
  {
    "id": "scientific-slides",
    "name": "scientific-slides",
    "description": "Build slide decks and presentations for research talks. Use this for making PowerPoint slides, conference presentations, seminar talks, research presentations, thesis defense slides, or any scientific talk. Provides slide structure, design templates, timing guidance, and visual validation. Works wit",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "scientific",
      "slides",
      "presentations",
      "slide",
      "talks",
      "powerpoint",
      "decks",
      "making",
      "conference",
      "seminar"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-slides",
    "fullDescription": "\n# Scientific Slides\n\n## Overview\n\nScientific presentations are a critical medium for communicating research, sharing findings, and engaging with academic and professional audiences. This skill provides comprehensive guidance for creating effective scientific presentations, from structure and content development to visual design and delivery preparation.\n\n**Key Focus**: Oral presentations for conferences, seminars, defenses, and professional talks.\n\n**CRITICAL DESIGN PHILOSOPHY**: Scientific presentations should be VISUALLY ENGAGING and RESEARCH-BACKED. Avoid dry, text-heavy slides at all costs. Great scientific presentations combine:\n- **Compelling visuals**: High-quality figures, images, diagrams (not just bullet points)\n- **Research context**: Proper citations from research-lookup establishing credibility\n- **Minimal text**: Bullet points as prompts, YOU provide the explanation verbally\n- **Professional design**: Modern color schemes, strong visual hierarchy, generous white space\n- **Story-driven**: Clear narrative arc, not just data dumps\n\n**Remember**: Boring presentations = forgotten science. Make your slides visually memorable while maintaining scientific rigor through proper citations.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Preparing conference presentations (5-20 minutes)\n- Developing academic seminars (45-60 minutes)\n- Creating thesis or dissertation defense presentations\n- Designing grant pitch presentations\n- Preparing journal club presentations\n- Giving research talks at institutions or companies\n- Teaching or tutorial presentations on scientific topics\n\n## Slide Generation with Nano Banana Pro\n\n**This skill uses Nano Banana Pro AI to generate stunning presentation slides automatically.**\n\nThere are two workflows depending on output format:\n\n### Default Workflow: PDF Slides (Recommended)\n\nGenerate each slide as a complete image using Nano Banana Pro, then combine into a PDF. This produces the most visually stunning results.\n\n**How"
  },
  {
    "id": "scientific-critical-thinking",
    "name": "scientific-critical-thinking",
    "description": "Evaluate research rigor. Assess methodology, experimental design, statistical validity, biases, confounding, evidence quality (GRADE, Cochrane ROB), for critical analysis of scientific claims.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "scientific",
      "critical",
      "thinking",
      "evaluate",
      "rigor",
      "assess",
      "methodology",
      "experimental",
      "design",
      "statistical"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-critical-thinking",
    "fullDescription": "\n# Scientific Critical Thinking\n\n## Overview\n\nCritical thinking is a systematic process for evaluating scientific rigor. Assess methodology, experimental design, statistical validity, biases, confounding, and evidence quality using GRADE and Cochrane ROB frameworks. Apply this skill for critical analysis of scientific claims.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Evaluating research methodology and experimental design\n- Assessing statistical validity and evidence quality\n- Identifying biases and confounding in studies\n- Reviewing scientific claims and conclusions\n- Conducting systematic reviews or meta-analyses\n- Applying GRADE or Cochrane risk of bias assessments\n- Providing critical analysis of research papers\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper formatting\n- Review and refine through multiple iterations\n- Ensure accessibility (colorblind-friendly, high contrast)\n- Save outputs in the figures/ directory\n\n**When to add schematics:**\n- Critical thinking framework diagrams\n- Bias identification decision trees\n- Evidence quality assessment flowcharts\n- GRADE assessment methodology diagrams\n- Risk of bias evaluation framework"
  },
  {
    "id": "scientific-brainstorming",
    "name": "scientific-brainstorming",
    "description": "Research ideation partner. Generate hypotheses, explore interdisciplinary connections, challenge assumptions, develop methodologies, identify research gaps, for creative scientific problem-solving.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "scientific",
      "brainstorming",
      "ideation",
      "partner",
      "generate",
      "hypotheses",
      "explore",
      "interdisciplinary",
      "connections",
      "challenge"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-brainstorming",
    "fullDescription": "\n# Scientific Brainstorming\n\n## Overview\n\nScientific brainstorming is a conversational process for generating novel research ideas. Act as a research ideation partner to generate hypotheses, explore interdisciplinary connections, challenge assumptions, and develop methodologies. Apply this skill for creative scientific problem-solving.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Generating novel research ideas or directions\n- Exploring interdisciplinary connections and analogies\n- Challenging assumptions in existing research frameworks\n- Developing new methodological approaches\n- Identifying research gaps or opportunities\n- Overcoming creative blocks in problem-solving\n- Brainstorming experimental designs or study plans\n\n## Core Principles\n\nWhen engaging in scientific brainstorming:\n\n1. **Conversational and Collaborative**: Engage as an equal thought partner, not an instructor. Ask questions, build on ideas together, and maintain a natural dialogue.\n\n2. **Intellectually Curious**: Show genuine interest in the scientist's work. Ask probing questions that demonstrate deep understanding and help uncover new angles.\n\n3. **Creatively Challenging**: Push beyond obvious ideas. Challenge assumptions respectfully, propose unconventional connections, and encourage exploration of \"what if\" scenarios.\n\n4. **Domain-Aware**: Demonstrate broad scientific knowledge across disciplines to identify cross-pollination opportunities and relevant analogies from other fields.\n\n5. **Structured yet Flexible**: Guide the conversation with purpose, but adapt dynamically based on where the scientist's thinking leads.\n\n## Brainstorming Workflow\n\n### Phase 1: Understanding the Context\n\nBegin by deeply understanding what the scientist is working on. This phase establishes the foundation for productive ideation.\n\n**Approach:**\n- Ask open-ended questions about their current research, interests, or challenge\n- Understand their field, methodology, and constraints\n- Identify what they"
  },
  {
    "id": "scholar-evaluation",
    "name": "scholar-evaluation",
    "description": "Systematically evaluate scholarly work using the ScholarEval framework, providing structured assessment across research quality dimensions including problem formulation, methodology, analysis, and writing with quantitative scoring and actionable feedback.",
    "category": "sci-communication",
    "source": "scientific",
    "triggers": [
      "scholar",
      "evaluation",
      "systematically",
      "evaluate",
      "scholarly",
      "work",
      "scholareval",
      "providing",
      "structured",
      "assessment"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scholar-evaluation",
    "fullDescription": "\n# Scholar Evaluation\n\n## Overview\n\nApply the ScholarEval framework to systematically evaluate scholarly and research work. This skill provides structured evaluation methodology based on peer-reviewed research assessment criteria, enabling comprehensive analysis of academic papers, research proposals, literature reviews, and scholarly writing across multiple quality dimensions.\n\n## When to Use This Skill\n\nUse this skill when:\n- Evaluating research papers for quality and rigor\n- Assessing literature review comprehensiveness and quality\n- Reviewing research methodology design\n- Scoring data analysis approaches\n- Evaluating scholarly writing and presentation\n- Providing structured feedback on academic work\n- Benchmarking research quality against established criteria\n- Assessing publication readiness for target venues\n- Providing quantitative evaluation to complement qualitative peer review\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper formatting\n- Review and refine through multiple iterations\n- Ensure accessibility (colorblind-friendly, high contrast)\n- Save outputs in the figures/ directory\n\n**When to add schematics:**\n- Evaluation framework diagrams\n- Qual"
  },
  {
    "id": "scanpy",
    "name": "scanpy",
    "description": "Single-cell RNA-seq analysis. Load .h5ad/10X data, QC, normalization, PCA/UMAP/t-SNE, Leiden clustering, marker genes, cell type annotation, trajectory, for scRNA-seq analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "scanpy",
      "single-cell",
      "rna-seq",
      "load",
      "h5ad",
      "10x",
      "normalization",
      "pca",
      "umap",
      "t-sne"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scanpy",
    "fullDescription": "\n# Scanpy: Single-Cell Analysis\n\n## Overview\n\nScanpy is a scalable Python toolkit for analyzing single-cell RNA-seq data, built on AnnData. Apply this skill for complete single-cell workflows including quality control, normalization, dimensionality reduction, clustering, marker gene identification, visualization, and trajectory analysis.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Analyzing single-cell RNA-seq data (.h5ad, 10X, CSV formats)\n- Performing quality control on scRNA-seq datasets\n- Creating UMAP, t-SNE, or PCA visualizations\n- Identifying cell clusters and finding marker genes\n- Annotating cell types based on gene expression\n- Conducting trajectory inference or pseudotime analysis\n- Generating publication-quality single-cell plots\n\n## Quick Start\n\n### Basic Import and Setup\n\n```python\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\n\n# Configure settings\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80, facecolor='white')\nsc.settings.figdir = './figures/'\n```\n\n### Loading Data\n\n```python\n# From 10X Genomics\nadata = sc.read_10x_mtx('path/to/data/')\nadata = sc.read_10x_h5('path/to/data.h5')\n\n# From h5ad (AnnData format)\nadata = sc.read_h5ad('path/to/data.h5ad')\n\n# From CSV\nadata = sc.read_csv('path/to/data.csv')\n```\n\n### Understanding AnnData Structure\n\nThe AnnData object is the core data structure in scanpy:\n\n```python\nadata.X          # Expression matrix (cells Ã— genes)\nadata.obs        # Cell metadata (DataFrame)\nadata.var        # Gene metadata (DataFrame)\nadata.uns        # Unstructured annotations (dict)\nadata.obsm       # Multi-dimensional cell data (PCA, UMAP)\nadata.raw        # Raw data backup\n\n# Access cell and gene names\nadata.obs_names  # Cell barcodes\nadata.var_names  # Gene names\n```\n\n## Standard Analysis Workflow\n\n### 1. Quality Control\n\nIdentify and filter low-quality cells and genes:\n\n```python\n# Identify mitochondrial genes\nadata.var['mt'] = adata.var_names.str.startswith('MT-')\n\n# Calculate QC met"
  },
  {
    "id": "research-lookup",
    "name": "research-lookup",
    "description": "Look up current research information using Perplexity's Sonar Pro Search or Sonar Reasoning Pro models through OpenRouter. Automatically selects the best model based on query complexity. Search academic papers, recent studies, technical documentation, and general research information with citations.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "lookup",
      "information",
      "sonar",
      "pro",
      "look",
      "current",
      "perplexity",
      "reasoning",
      "openrouter",
      "automatically"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/research-lookup",
    "fullDescription": "\n# Research Information Lookup\n\n## Overview\n\nThis skill enables real-time research information lookup using Perplexity's Sonar models through OpenRouter. It intelligently selects between **Sonar Pro Search** (fast, efficient lookup) and **Sonar Reasoning Pro** (deep analytical reasoning) based on query complexity. The skill provides access to current academic literature, recent studies, technical documentation, and general research information with proper citations and source attribution.\n\n## When to Use This Skill\n\nUse this skill when you need:\n\n- **Current Research Information**: Latest studies, papers, and findings in a specific field\n- **Literature Verification**: Check facts, statistics, or claims against current research\n- **Background Research**: Gather context and supporting evidence for scientific writing\n- **Citation Sources**: Find relevant papers and studies to cite in manuscripts\n- **Technical Documentation**: Look up specifications, protocols, or methodologies\n- **Recent Developments**: Stay current with emerging trends and breakthroughs\n- **Statistical Data**: Find recent statistics, survey results, or research findings\n- **Expert Opinions**: Access insights from recent interviews, reviews, or commentary\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram des"
  },
  {
    "id": "research-grants",
    "name": "research-grants",
    "description": "Write competitive research proposals for NSF, NIH, DOE, and DARPA. Agency-specific formatting, review criteria, budget preparation, broader impacts, significance statements, innovation narratives, and compliance with submission requirements.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "grants",
      "write",
      "competitive",
      "proposals",
      "nsf",
      "nih",
      "doe",
      "darpa",
      "agency-specific",
      "formatting"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/research-grants",
    "fullDescription": "\n# Research Grant Writing\n\n## Overview\n\nResearch grant writing is the process of developing competitive funding proposals for federal agencies and foundations. Master agency-specific requirements, review criteria, narrative structure, budget preparation, and compliance for NSF (National Science Foundation), NIH (National Institutes of Health), DOE (Department of Energy), and DARPA (Defense Advanced Research Projects Agency) submissions.\n\n**Critical Principle: Grants are persuasive documents that must simultaneously demonstrate scientific rigor, innovation, feasibility, and broader impact.** Each agency has distinct priorities, review criteria, formatting requirements, and strategic goals that must be addressed.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Writing research proposals for NSF, NIH, DOE, or DARPA programs\n- Preparing project descriptions, specific aims, or technical narratives\n- Developing broader impacts or significance statements\n- Creating research timelines and milestone plans\n- Preparing budget justifications and personnel allocation plans\n- Responding to program solicitations or funding announcements\n- Addressing reviewer comments in resubmissions\n- Planning multi-institutional collaborative proposals\n- Writing preliminary data or feasibility sections\n- Preparing biosketches, CVs, or facilities descriptions\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every research grant proposal MUST include at least 1-2 AI-generated figures using the scientific-schematics skill.**\n\nThis is not optional. Grant proposals without visual elements are incomplete and less competitive. Before finalizing any document:\n1. Generate at minimum ONE schematic or diagram (e.g., project timeline, methodology flowchart, or conceptual framework)\n2. Prefer 2-3 figures for comprehensive proposals (research workflow, Gantt chart, preliminary data visualization)\n\n**How to generate figures:**\n- Use the **scientific-schematics** skill to generat"
  },
  {
    "id": "reactome-database",
    "name": "reactome-database",
    "description": "Query Reactome REST API for pathway analysis, enrichment, gene-pathway mapping, disease pathways, molecular interactions, expression analysis, for systems biology studies.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "reactome",
      "rest",
      "pathway",
      "enrichment",
      "gene-pathway",
      "mapping",
      "disease",
      "pathways",
      "molecular",
      "interactions"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/reactome-database",
    "fullDescription": "\n# Reactome Database\n\n## Overview\n\nReactome is a free, open-source, curated pathway database with 2,825+ human pathways. Query biological pathways, perform overrepresentation and expression analysis, map genes to pathways, explore molecular interactions via REST API and Python client for systems biology research.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Performing pathway enrichment analysis on gene or protein lists\n- Analyzing gene expression data to identify relevant biological pathways\n- Querying specific pathway information, reactions, or molecular interactions\n- Mapping genes or proteins to biological pathways and processes\n- Exploring disease-related pathways and mechanisms\n- Visualizing analysis results in the Reactome Pathway Browser\n- Conducting comparative pathway analysis across species\n\n## Core Capabilities\n\nReactome provides two main API services and a Python client library:\n\n### 1. Content Service - Data Retrieval\n\nQuery and retrieve biological pathway data, molecular interactions, and entity information.\n\n**Common operations:**\n- Retrieve pathway information and hierarchies\n- Query specific entities (proteins, reactions, complexes)\n- Get participating molecules in pathways\n- Access database version and metadata\n- Explore pathway compartments and locations\n\n**API Base URL:** `https://reactome.org/ContentService`\n\n### 2. Analysis Service - Pathway Analysis\n\nPerform computational analysis on gene lists and expression data.\n\n**Analysis types:**\n- **Overrepresentation Analysis**: Identify statistically significant pathways from gene/protein lists\n- **Expression Data Analysis**: Analyze gene expression datasets to find relevant pathways\n- **Species Comparison**: Compare pathway data across different organisms\n\n**API Base URL:** `https://reactome.org/AnalysisService`\n\n### 3. reactome2py Python Package\n\nPython client library that wraps Reactome API calls for easier programmatic access.\n\n**Installation:**\n```bash\nuv pip install reactome2py"
  },
  {
    "id": "qutip",
    "name": "qutip",
    "description": "Quantum mechanics simulations and analysis using QuTiP (Quantum Toolbox in Python). Use when working with quantum systems including: (1) quantum states (kets, bras, density matrices), (2) quantum operators and gates, (3) time evolution and dynamics (SchrÃ¶dinger, master equations, Monte Carlo), (4) o",
    "category": "physics-materials",
    "source": "scientific",
    "triggers": [
      "qutip",
      "quantum",
      "systems",
      "states",
      "open",
      "functions",
      "mechanics",
      "simulations",
      "toolbox",
      "kets"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/qutip",
    "fullDescription": "\n# QuTiP: Quantum Toolbox in Python\n\n## Overview\n\nQuTiP provides comprehensive tools for simulating and analyzing quantum mechanical systems. It handles both closed (unitary) and open (dissipative) quantum systems with multiple solvers optimized for different scenarios.\n\n## Installation\n\n```bash\nuv pip install qutip\n```\n\nOptional packages for additional functionality:\n\n```bash\n# Quantum information processing (circuits, gates)\nuv pip install qutip-qip\n\n# Quantum trajectory viewer\nuv pip install qutip-qtrl\n```\n\n## Quick Start\n\n```python\nfrom qutip import *\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create quantum state\npsi = basis(2, 0)  # |0âŸ© state\n\n# Create operator\nH = sigmaz()  # Hamiltonian\n\n# Time evolution\ntlist = np.linspace(0, 10, 100)\nresult = sesolve(H, psi, tlist, e_ops=[sigmaz()])\n\n# Plot results\nplt.plot(tlist, result.expect[0])\nplt.xlabel('Time')\nplt.ylabel('âŸ¨ÏƒzâŸ©')\nplt.show()\n```\n\n## Core Capabilities\n\n### 1. Quantum Objects and States\n\nCreate and manipulate quantum states and operators:\n\n```python\n# States\npsi = basis(N, n)  # Fock state |nâŸ©\npsi = coherent(N, alpha)  # Coherent state |Î±âŸ©\nrho = thermal_dm(N, n_avg)  # Thermal density matrix\n\n# Operators\na = destroy(N)  # Annihilation operator\nH = num(N)  # Number operator\nsx, sy, sz = sigmax(), sigmay(), sigmaz()  # Pauli matrices\n\n# Composite systems\npsi_AB = tensor(psi_A, psi_B)  # Tensor product\n```\n\n**See** `references/core_concepts.md` for comprehensive coverage of quantum objects, states, operators, and tensor products.\n\n### 2. Time Evolution and Dynamics\n\nMultiple solvers for different scenarios:\n\n```python\n# Closed systems (unitary evolution)\nresult = sesolve(H, psi0, tlist, e_ops=[num(N)])\n\n# Open systems (dissipation)\nc_ops = [np.sqrt(0.1) * destroy(N)]  # Collapse operators\nresult = mesolve(H, psi0, tlist, c_ops, e_ops=[num(N)])\n\n# Quantum trajectories (Monte Carlo)\nresult = mcsolve(H, psi0, tlist, c_ops, ntraj=500, e_ops=[num(N)])\n```\n\n**Solver selection guide:**\n- `sesolve`: Pur"
  },
  {
    "id": "rdkit",
    "name": "rdkit",
    "description": "Cheminformatics toolkit for fine-grained molecular control. SMILES/SDF parsing, descriptors (MW, LogP, TPSA), fingerprints, substructure search, 2D/3D generation, similarity, reactions. For standard workflows with simpler interface, use datamol (wrapper around RDKit). Use rdkit for advanced control,",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "rdkit",
      "control",
      "cheminformatics",
      "fine-grained",
      "molecular",
      "smiles",
      "sdf",
      "parsing",
      "descriptors",
      "logp"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/rdkit",
    "fullDescription": "\n# RDKit Cheminformatics Toolkit\n\n## Overview\n\nRDKit is a comprehensive cheminformatics library providing Python APIs for molecular analysis and manipulation. This skill provides guidance for reading/writing molecular structures, calculating descriptors, fingerprinting, substructure searching, chemical reactions, 2D/3D coordinate generation, and molecular visualization. Use this skill for drug discovery, computational chemistry, and cheminformatics research tasks.\n\n## Core Capabilities\n\n### 1. Molecular I/O and Creation\n\n**Reading Molecules:**\n\nRead molecular structures from various formats:\n\n```python\nfrom rdkit import Chem\n\n# From SMILES strings\nmol = Chem.MolFromSmiles('Cc1ccccc1')  # Returns Mol object or None\n\n# From MOL files\nmol = Chem.MolFromMolFile('path/to/file.mol')\n\n# From MOL blocks (string data)\nmol = Chem.MolFromMolBlock(mol_block_string)\n\n# From InChI\nmol = Chem.MolFromInchi('InChI=1S/C6H6/c1-2-4-6-5-3-1/h1-6H')\n```\n\n**Writing Molecules:**\n\nConvert molecules to text representations:\n\n```python\n# To canonical SMILES\nsmiles = Chem.MolToSmiles(mol)\n\n# To MOL block\nmol_block = Chem.MolToMolBlock(mol)\n\n# To InChI\ninchi = Chem.MolToInchi(mol)\n```\n\n**Batch Processing:**\n\nFor processing multiple molecules, use Supplier/Writer objects:\n\n```python\n# Read SDF files\nsuppl = Chem.SDMolSupplier('molecules.sdf')\nfor mol in suppl:\n    if mol is not None:  # Check for parsing errors\n        # Process molecule\n        pass\n\n# Read SMILES files\nsuppl = Chem.SmilesMolSupplier('molecules.smi', titleLine=False)\n\n# For large files or compressed data\nwith gzip.open('molecules.sdf.gz') as f:\n    suppl = Chem.ForwardSDMolSupplier(f)\n    for mol in suppl:\n        # Process molecule\n        pass\n\n# Multithreaded processing for large datasets\nsuppl = Chem.MultithreadedSDMolSupplier('molecules.sdf')\n\n# Write molecules to SDF\nwriter = Chem.SDWriter('output.sdf')\nfor mol in molecules:\n    writer.write(mol)\nwriter.close()\n```\n\n**Important Notes:**\n- All `MolFrom*` functions return `"
  },
  {
    "id": "qiskit",
    "name": "qiskit",
    "description": "Comprehensive quantum computing toolkit for building, optimizing, and executing quantum circuits. Use when working with quantum algorithms, simulations, or quantum hardware including (1) Building quantum circuits with gates and measurements, (2) Running quantum algorithms (VQE, QAOA, Grover), (3) Tr",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "qiskit",
      "quantum",
      "circuits",
      "computing",
      "optimizing",
      "executing",
      "algorithms",
      "hardware",
      "simulations",
      "gates"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/qiskit",
    "fullDescription": "\n# Qiskit\n\n## Overview\n\nQiskit is the world's most popular open-source quantum computing framework with 13M+ downloads. Build quantum circuits, optimize for hardware, execute on simulators or real quantum computers, and analyze results. Supports IBM Quantum (100+ qubit systems), IonQ, Amazon Braket, and other providers.\n\n**Key Features:**\n- 83x faster transpilation than competitors\n- 29% fewer two-qubit gates in optimized circuits\n- Backend-agnostic execution (local simulators or cloud hardware)\n- Comprehensive algorithm libraries for optimization, chemistry, and ML\n\n## Quick Start\n\n### Installation\n\n```bash\nuv pip install qiskit\nuv pip install \"qiskit[visualization]\" matplotlib\n```\n\n### First Circuit\n\n```python\nfrom qiskit import QuantumCircuit\nfrom qiskit.primitives import StatevectorSampler\n\n# Create Bell state (entangled qubits)\nqc = QuantumCircuit(2)\nqc.h(0)           # Hadamard on qubit 0\nqc.cx(0, 1)       # CNOT from qubit 0 to 1\nqc.measure_all()  # Measure both qubits\n\n# Run locally\nsampler = StatevectorSampler()\nresult = sampler.run([qc], shots=1024).result()\ncounts = result[0].data.meas.get_counts()\nprint(counts)  # {'00': ~512, '11': ~512}\n```\n\n### Visualization\n\n```python\nfrom qiskit.visualization import plot_histogram\n\nqc.draw('mpl')           # Circuit diagram\nplot_histogram(counts)   # Results histogram\n```\n\n## Core Capabilities\n\n### 1. Setup and Installation\nFor detailed installation, authentication, and IBM Quantum account setup:\n- **See `references/setup.md`**\n\nTopics covered:\n- Installation with uv\n- Python environment setup\n- IBM Quantum account and API token configuration\n- Local vs. cloud execution\n\n### 2. Building Quantum Circuits\nFor constructing quantum circuits with gates, measurements, and composition:\n- **See `references/circuits.md`**\n\nTopics covered:\n- Creating circuits with QuantumCircuit\n- Single-qubit gates (H, X, Y, Z, rotations, phase gates)\n- Multi-qubit gates (CNOT, SWAP, Toffoli)\n- Measurements and barriers\n- Circuit composition"
  },
  {
    "id": "pytorch-lightning",
    "name": "pytorch-lightning",
    "description": "Deep learning framework (PyTorch Lightning). Organize PyTorch code into LightningModules, configure Trainers for multi-GPU/TPU, implement data pipelines, callbacks, logging (W&B, TensorBoard), distributed training (DDP, FSDP, DeepSpeed), for scalable neural network training.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "pytorch",
      "lightning",
      "training",
      "deep",
      "organize",
      "code",
      "lightningmodules",
      "configure",
      "trainers",
      "multi-gpu"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pytorch-lightning",
    "fullDescription": "\n# PyTorch Lightning\n\n## Overview\n\nPyTorch Lightning is a deep learning framework that organizes PyTorch code to eliminate boilerplate while maintaining full flexibility. Automate training workflows, multi-device orchestration, and implement best practices for neural network training and scaling across multiple GPUs/TPUs.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Building, training, or deploying neural networks using PyTorch Lightning\n- Organizing PyTorch code into LightningModules\n- Configuring Trainers for multi-GPU/TPU training\n- Implementing data pipelines with LightningDataModules\n- Working with callbacks, logging, and distributed training strategies (DDP, FSDP, DeepSpeed)\n- Structuring deep learning projects professionally\n\n## Core Capabilities\n\n### 1. LightningModule - Model Definition\n\nOrganize PyTorch models into six logical sections:\n\n1. **Initialization** - `__init__()` and `setup()`\n2. **Training Loop** - `training_step(batch, batch_idx)`\n3. **Validation Loop** - `validation_step(batch, batch_idx)`\n4. **Test Loop** - `test_step(batch, batch_idx)`\n5. **Prediction** - `predict_step(batch, batch_idx)`\n6. **Optimizer Configuration** - `configure_optimizers()`\n\n**Quick template reference:** See `scripts/template_lightning_module.py` for a complete boilerplate.\n\n**Detailed documentation:** Read `references/lightning_module.md` for comprehensive method documentation, hooks, properties, and best practices.\n\n### 2. Trainer - Training Automation\n\nThe Trainer automates the training loop, device management, gradient operations, and callbacks. Key features:\n\n- Multi-GPU/TPU support with strategy selection (DDP, FSDP, DeepSpeed)\n- Automatic mixed precision training\n- Gradient accumulation and clipping\n- Checkpointing and early stopping\n- Progress bars and logging\n\n**Quick setup reference:** See `scripts/quick_trainer_setup.py` for common Trainer configurations.\n\n**Detailed documentation:** Read `references/trainer.md` for all parameters, methods, a"
  },
  {
    "id": "pysam",
    "name": "pysam",
    "description": "Genomic file toolkit. Read/write SAM/BAM/CRAM alignments, VCF/BCF variants, FASTA/FASTQ sequences, extract regions, calculate coverage, for NGS data processing pipelines.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "pysam",
      "genomic",
      "file",
      "read",
      "write",
      "sam",
      "bam",
      "cram",
      "alignments",
      "vcf"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pysam",
    "fullDescription": "\n# Pysam\n\n## Overview\n\nPysam is a Python module for reading, manipulating, and writing genomic datasets. Read/write SAM/BAM/CRAM alignment files, VCF/BCF variant files, and FASTA/FASTQ sequences with a Pythonic interface to htslib. Query tabix-indexed files, perform pileup analysis for coverage, and execute samtools/bcftools commands.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with sequencing alignment files (BAM/CRAM)\n- Analyzing genetic variants (VCF/BCF)\n- Extracting reference sequences or gene regions\n- Processing raw sequencing data (FASTQ)\n- Calculating coverage or read depth\n- Implementing bioinformatics analysis pipelines\n- Quality control of sequencing data\n- Variant calling and annotation workflows\n\n## Quick Start\n\n### Installation\n```bash\nuv pip install pysam\n```\n\n### Basic Examples\n\n**Read alignment file:**\n```python\nimport pysam\n\n# Open BAM file and fetch reads in region\nsamfile = pysam.AlignmentFile(\"example.bam\", \"rb\")\nfor read in samfile.fetch(\"chr1\", 1000, 2000):\n    print(f\"{read.query_name}: {read.reference_start}\")\nsamfile.close()\n```\n\n**Read variant file:**\n```python\n# Open VCF file and iterate variants\nvcf = pysam.VariantFile(\"variants.vcf\")\nfor variant in vcf:\n    print(f\"{variant.chrom}:{variant.pos} {variant.ref}>{variant.alts}\")\nvcf.close()\n```\n\n**Query reference sequence:**\n```python\n# Open FASTA and extract sequence\nfasta = pysam.FastaFile(\"reference.fasta\")\nsequence = fasta.fetch(\"chr1\", 1000, 2000)\nprint(sequence)\nfasta.close()\n```\n\n## Core Capabilities\n\n### 1. Alignment File Operations (SAM/BAM/CRAM)\n\nUse the `AlignmentFile` class to work with aligned sequencing reads. This is appropriate for analyzing mapping results, calculating coverage, extracting reads, or quality control.\n\n**Common operations:**\n- Open and read BAM/SAM/CRAM files\n- Fetch reads from specific genomic regions\n- Filter reads by mapping quality, flags, or other criteria\n- Write filtered or modified alignments\n- Calculate coverage statistics\n"
  },
  {
    "id": "pytdc",
    "name": "pytdc",
    "description": "Therapeutics Data Commons. AI-ready drug discovery datasets (ADME, toxicity, DTI), benchmarks, scaffold splits, molecular oracles, for therapeutic ML and pharmacological prediction.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "pytdc",
      "therapeutics",
      "commons",
      "ai-ready",
      "drug",
      "discovery",
      "datasets",
      "adme",
      "toxicity",
      "dti"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pytdc",
    "fullDescription": "\n# PyTDC (Therapeutics Data Commons)\n\n## Overview\n\nPyTDC is an open-science platform providing AI-ready datasets and benchmarks for drug discovery and development. Access curated datasets spanning the entire therapeutics pipeline with standardized evaluation metrics and meaningful data splits, organized into three categories: single-instance prediction (molecular/protein properties), multi-instance prediction (drug-target interactions, DDI), and generation (molecule generation, retrosynthesis).\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with drug discovery or therapeutic ML datasets\n- Benchmarking machine learning models on standardized pharmaceutical tasks\n- Predicting molecular properties (ADME, toxicity, bioactivity)\n- Predicting drug-target or drug-drug interactions\n- Generating novel molecules with desired properties\n- Accessing curated datasets with proper train/test splits (scaffold, cold-split)\n- Using molecular oracles for property optimization\n\n## Installation & Setup\n\nInstall PyTDC using pip:\n\n```bash\nuv pip install PyTDC\n```\n\nTo upgrade to the latest version:\n\n```bash\nuv pip install PyTDC --upgrade\n```\n\nCore dependencies (automatically installed):\n- numpy, pandas, tqdm, seaborn, scikit_learn, fuzzywuzzy\n\nAdditional packages are installed automatically as needed for specific features.\n\n## Quick Start\n\nThe basic pattern for accessing any TDC dataset follows this structure:\n\n```python\nfrom tdc.<problem> import <Task>\ndata = <Task>(name='<Dataset>')\nsplit = data.get_split(method='scaffold', seed=1, frac=[0.7, 0.1, 0.2])\ndf = data.get_data(format='df')\n```\n\nWhere:\n- `<problem>`: One of `single_pred`, `multi_pred`, or `generation`\n- `<Task>`: Specific task category (e.g., ADME, DTI, MolGen)\n- `<Dataset>`: Dataset name within that task\n\n**Example - Loading ADME data:**\n\n```python\nfrom tdc.single_pred import ADME\ndata = ADME(name='Caco2_Wang')\nsplit = data.get_split(method='scaffold')\n# Returns dict with 'train', 'valid', 'test' DataFr"
  },
  {
    "id": "pyopenms",
    "name": "pyopenms",
    "description": "Python interface to OpenMS for mass spectrometry data analysis. Use for LC-MS/MS proteomics and metabolomics workflows including file handling (mzML, mzXML, mzTab, FASTA, pepXML, protXML, mzIdentML), signal processing, feature detection, peptide identification, and quantitative analysis. Apply when ",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "pyopenms",
      "mass",
      "spectrometry",
      "proteomics",
      "metabolomics",
      "processing",
      "interface",
      "openms",
      "lc-ms",
      "workflows"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pyopenms",
    "fullDescription": "\n# PyOpenMS\n\n## Overview\n\nPyOpenMS provides Python bindings to the OpenMS library for computational mass spectrometry, enabling analysis of proteomics and metabolomics data. Use for handling mass spectrometry file formats, processing spectral data, detecting features, identifying peptides/proteins, and performing quantitative analysis.\n\n## Installation\n\nInstall using uv:\n\n```bash\nuv uv pip install pyopenms\n```\n\nVerify installation:\n\n```python\nimport pyopenms\nprint(pyopenms.__version__)\n```\n\n## Core Capabilities\n\nPyOpenMS organizes functionality into these domains:\n\n### 1. File I/O and Data Formats\n\nHandle mass spectrometry file formats and convert between representations.\n\n**Supported formats**: mzML, mzXML, TraML, mzTab, FASTA, pepXML, protXML, mzIdentML, featureXML, consensusXML, idXML\n\nBasic file reading:\n\n```python\nimport pyopenms as ms\n\n# Read mzML file\nexp = ms.MSExperiment()\nms.MzMLFile().load(\"data.mzML\", exp)\n\n# Access spectra\nfor spectrum in exp:\n    mz, intensity = spectrum.get_peaks()\n    print(f\"Spectrum: {len(mz)} peaks\")\n```\n\n**For detailed file handling**: See `references/file_io.md`\n\n### 2. Signal Processing\n\nProcess raw spectral data with smoothing, filtering, centroiding, and normalization.\n\nBasic spectrum processing:\n\n```python\n# Smooth spectrum with Gaussian filter\ngaussian = ms.GaussFilter()\nparams = gaussian.getParameters()\nparams.setValue(\"gaussian_width\", 0.1)\ngaussian.setParameters(params)\ngaussian.filterExperiment(exp)\n```\n\n**For algorithm details**: See `references/signal_processing.md`\n\n### 3. Feature Detection\n\nDetect and link features across spectra and samples for quantitative analysis.\n\n```python\n# Detect features\nff = ms.FeatureFinder()\nff.run(\"centroided\", exp, features, params, ms.FeatureMap())\n```\n\n**For complete workflows**: See `references/feature_detection.md`\n\n### 4. Peptide and Protein Identification\n\nIntegrate with search engines and process identification results.\n\n**Supported engines**: Comet, Mascot, MSGFPlus, XTandem, O"
  },
  {
    "id": "pymc-bayesian-modeling",
    "name": "pymc-bayesian-modeling",
    "description": "Bayesian modeling with PyMC. Build hierarchical models, MCMC (NUTS), variational inference, LOO/WAIC comparison, posterior checks, for probabilistic programming and inference.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "pymc",
      "bayesian",
      "modeling",
      "inference",
      "hierarchical",
      "mcmc",
      "nuts",
      "variational",
      "loo",
      "waic"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pymc",
    "fullDescription": "\n# PyMC Bayesian Modeling\n\n## Overview\n\nPyMC is a Python library for Bayesian modeling and probabilistic programming. Build, fit, validate, and compare Bayesian models using PyMC's modern API (version 5.x+), including hierarchical models, MCMC sampling (NUTS), variational inference, and model comparison (LOO, WAIC).\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Building Bayesian models (linear/logistic regression, hierarchical models, time series, etc.)\n- Performing MCMC sampling or variational inference\n- Conducting prior/posterior predictive checks\n- Diagnosing sampling issues (divergences, convergence, ESS)\n- Comparing multiple models using information criteria (LOO, WAIC)\n- Implementing uncertainty quantification through Bayesian methods\n- Working with hierarchical/multilevel data structures\n- Handling missing data or measurement error in a principled way\n\n## Standard Bayesian Workflow\n\nFollow this workflow for building and validating Bayesian models:\n\n### 1. Data Preparation\n\n```python\nimport pymc as pm\nimport arviz as az\nimport numpy as np\n\n# Load and prepare data\nX = ...  # Predictors\ny = ...  # Outcomes\n\n# Standardize predictors for better sampling\nX_mean = X.mean(axis=0)\nX_std = X.std(axis=0)\nX_scaled = (X - X_mean) / X_std\n```\n\n**Key practices:**\n- Standardize continuous predictors (improves sampling efficiency)\n- Center outcomes when possible\n- Handle missing data explicitly (treat as parameters)\n- Use named dimensions with `coords` for clarity\n\n### 2. Model Building\n\n```python\ncoords = {\n    'predictors': ['var1', 'var2', 'var3'],\n    'obs_id': np.arange(len(y))\n}\n\nwith pm.Model(coords=coords) as model:\n    # Priors\n    alpha = pm.Normal('alpha', mu=0, sigma=1)\n    beta = pm.Normal('beta', mu=0, sigma=1, dims='predictors')\n    sigma = pm.HalfNormal('sigma', sigma=1)\n\n    # Linear predictor\n    mu = alpha + pm.math.dot(X_scaled, beta)\n\n    # Likelihood\n    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y, dims='obs_id')\n```\n\n**Key"
  },
  {
    "id": "pymoo",
    "name": "pymoo",
    "description": "Multi-objective optimization framework. NSGA-II, NSGA-III, MOEA/D, Pareto fronts, constraint handling, benchmarks (ZDT, DTLZ), for engineering design and optimization problems.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "pymoo",
      "optimization",
      "multi-objective",
      "nsga-ii",
      "nsga-iii",
      "moea",
      "pareto",
      "fronts",
      "constraint",
      "handling"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pymoo",
    "fullDescription": "\n# Pymoo - Multi-Objective Optimization in Python\n\n## Overview\n\nPymoo is a comprehensive Python framework for optimization with emphasis on multi-objective problems. Solve single and multi-objective optimization using state-of-the-art algorithms (NSGA-II/III, MOEA/D), benchmark problems (ZDT, DTLZ), customizable genetic operators, and multi-criteria decision making methods. Excels at finding trade-off solutions (Pareto fronts) for problems with conflicting objectives.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Solving optimization problems with one or multiple objectives\n- Finding Pareto-optimal solutions and analyzing trade-offs\n- Implementing evolutionary algorithms (GA, DE, PSO, NSGA-II/III)\n- Working with constrained optimization problems\n- Benchmarking algorithms on standard test problems (ZDT, DTLZ, WFG)\n- Customizing genetic operators (crossover, mutation, selection)\n- Visualizing high-dimensional optimization results\n- Making decisions from multiple competing solutions\n- Handling binary, discrete, continuous, or mixed-variable problems\n\n## Core Concepts\n\n### The Unified Interface\n\nPymoo uses a consistent `minimize()` function for all optimization tasks:\n\n```python\nfrom pymoo.optimize import minimize\n\nresult = minimize(\n    problem,        # What to optimize\n    algorithm,      # How to optimize\n    termination,    # When to stop\n    seed=1,\n    verbose=True\n)\n```\n\n**Result object contains:**\n- `result.X`: Decision variables of optimal solution(s)\n- `result.F`: Objective values of optimal solution(s)\n- `result.G`: Constraint violations (if constrained)\n- `result.algorithm`: Algorithm object with history\n\n### Problem Types\n\n**Single-objective:** One objective to minimize/maximize\n**Multi-objective:** 2-3 conflicting objectives â†’ Pareto front\n**Many-objective:** 4+ objectives â†’ High-dimensional Pareto front\n**Constrained:** Objectives + inequality/equality constraints\n**Dynamic:** Time-varying objectives or constraints\n\n## Quick Start Workflo"
  },
  {
    "id": "pymatgen",
    "name": "pymatgen",
    "description": "Materials science toolkit. Crystal structures (CIF, POSCAR), phase diagrams, band structure, DOS, Materials Project integration, format conversion, for computational materials science.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "pymatgen",
      "materials",
      "science",
      "crystal",
      "structures",
      "cif",
      "poscar",
      "phase",
      "diagrams",
      "band"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pymatgen",
    "fullDescription": "\n# Pymatgen - Python Materials Genomics\n\n## Overview\n\nPymatgen is a comprehensive Python library for materials analysis that powers the Materials Project. Create, analyze, and manipulate crystal structures and molecules, compute phase diagrams and thermodynamic properties, analyze electronic structure (band structures, DOS), generate surfaces and interfaces, and access Materials Project's database of computed materials. Supports 100+ file formats from various computational codes.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with crystal structures or molecular systems in materials science\n- Converting between structure file formats (CIF, POSCAR, XYZ, etc.)\n- Analyzing symmetry, space groups, or coordination environments\n- Computing phase diagrams or assessing thermodynamic stability\n- Analyzing electronic structure data (band gaps, DOS, band structures)\n- Generating surfaces, slabs, or studying interfaces\n- Accessing the Materials Project database programmatically\n- Setting up high-throughput computational workflows\n- Analyzing diffusion, magnetism, or mechanical properties\n- Working with VASP, Gaussian, Quantum ESPRESSO, or other computational codes\n\n## Quick Start Guide\n\n### Installation\n\n```bash\n# Core pymatgen\nuv pip install pymatgen\n\n# With Materials Project API access\nuv pip install pymatgen mp-api\n\n# Optional dependencies for extended functionality\nuv pip install pymatgen[analysis]  # Additional analysis tools\nuv pip install pymatgen[vis]       # Visualization tools\n```\n\n### Basic Structure Operations\n\n```python\nfrom pymatgen.core import Structure, Lattice\n\n# Read structure from file (automatic format detection)\nstruct = Structure.from_file(\"POSCAR\")\n\n# Create structure from scratch\nlattice = Lattice.cubic(3.84)\nstruct = Structure(lattice, [\"Si\", \"Si\"], [[0,0,0], [0.25,0.25,0.25]])\n\n# Write to different format\nstruct.to(filename=\"structure.cif\")\n\n# Basic properties\nprint(f\"Formula: {struct.composition.reduced_formula}\")\nprint(f\"Space "
  },
  {
    "id": "pylabrobot",
    "name": "pylabrobot",
    "description": "Laboratory automation toolkit for controlling liquid handlers, plate readers, pumps, heater shakers, incubators, centrifuges, and analytical equipment. Use this skill when automating laboratory workflows, programming liquid handling robots (Hamilton STAR, Opentrons OT-2, Tecan EVO), integrating lab ",
    "category": "lab-automation",
    "source": "scientific",
    "triggers": [
      "pylabrobot",
      "laboratory",
      "liquid",
      "equipment",
      "plates",
      "protocols",
      "automation",
      "controlling",
      "handlers",
      "plate"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pylabrobot",
    "fullDescription": "\n# PyLabRobot\n\n## Overview\n\nPyLabRobot is a hardware-agnostic, pure Python Software Development Kit for automated and autonomous laboratories. Use this skill to control liquid handling robots, plate readers, pumps, heater shakers, incubators, centrifuges, and other laboratory automation equipment through a unified Python interface that works across platforms (Windows, macOS, Linux).\n\n## When to Use This Skill\n\nUse this skill when:\n- Programming liquid handling robots (Hamilton STAR/STARlet, Opentrons OT-2, Tecan EVO)\n- Automating laboratory workflows involving pipetting, sample preparation, or analytical measurements\n- Managing deck layouts and laboratory resources (plates, tips, containers, troughs)\n- Integrating multiple lab devices (liquid handlers, plate readers, heater shakers, pumps)\n- Creating reproducible laboratory protocols with state management\n- Simulating protocols before running on physical hardware\n- Reading plates using BMG CLARIOstar or other supported plate readers\n- Controlling temperature, shaking, centrifugation, or other material handling operations\n- Working with laboratory automation in Python\n\n## Core Capabilities\n\nPyLabRobot provides comprehensive laboratory automation through six main capability areas, each detailed in the references/ directory:\n\n### 1. Liquid Handling (`references/liquid-handling.md`)\n\nControl liquid handling robots for aspirating, dispensing, and transferring liquids. Key operations include:\n- **Basic Operations**: Aspirate, dispense, transfer liquids between wells\n- **Tip Management**: Pick up, drop, and track pipette tips automatically\n- **Advanced Techniques**: Multi-channel pipetting, serial dilutions, plate replication\n- **Volume Tracking**: Automatic tracking of liquid volumes in wells\n- **Hardware Support**: Hamilton STAR/STARlet, Opentrons OT-2, Tecan EVO, and others\n\n### 2. Resource Management (`references/resources.md`)\n\nManage laboratory resources in a hierarchical system:\n- **Resource Types**: Plates, tip rac"
  },
  {
    "id": "pyhealth",
    "name": "pyhealth",
    "description": "Comprehensive healthcare AI toolkit for developing, testing, and deploying machine learning models with clinical data. This skill should be used when working with electronic health records (EHR), clinical prediction tasks (mortality, readmission, drug recommendation), medical coding systems (ICD, ND",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "pyhealth",
      "healthcare",
      "clinical",
      "testing",
      "deploying",
      "machine",
      "electronic",
      "health",
      "records",
      "ehr"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pyhealth",
    "fullDescription": "\n# PyHealth: Healthcare AI Toolkit\n\n## Overview\n\nPyHealth is a comprehensive Python library for healthcare AI that provides specialized tools, models, and datasets for clinical machine learning. Use this skill when developing healthcare prediction models, processing clinical data, working with medical coding systems, or deploying AI solutions in healthcare settings.\n\n## When to Use This Skill\n\nInvoke this skill when:\n\n- **Working with healthcare datasets**: MIMIC-III, MIMIC-IV, eICU, OMOP, sleep EEG data, medical images\n- **Clinical prediction tasks**: Mortality prediction, hospital readmission, length of stay, drug recommendation\n- **Medical coding**: Translating between ICD-9/10, NDC, RxNorm, ATC coding systems\n- **Processing clinical data**: Sequential events, physiological signals, clinical text, medical images\n- **Implementing healthcare models**: RETAIN, SafeDrug, GAMENet, StageNet, Transformer for EHR\n- **Evaluating clinical models**: Fairness metrics, calibration, interpretability, uncertainty quantification\n\n## Core Capabilities\n\nPyHealth operates through a modular 5-stage pipeline optimized for healthcare AI:\n\n1. **Data Loading**: Access 10+ healthcare datasets with standardized interfaces\n2. **Task Definition**: Apply 20+ predefined clinical prediction tasks or create custom tasks\n3. **Model Selection**: Choose from 33+ models (baselines, deep learning, healthcare-specific)\n4. **Training**: Train with automatic checkpointing, monitoring, and evaluation\n5. **Deployment**: Calibrate, interpret, and validate for clinical use\n\n**Performance**: 3x faster than pandas for healthcare data processing\n\n## Quick Start Workflow\n\n```python\nfrom pyhealth.datasets import MIMIC4Dataset\nfrom pyhealth.tasks import mortality_prediction_mimic4_fn\nfrom pyhealth.datasets import split_by_patient, get_dataloader\nfrom pyhealth.models import Transformer\nfrom pyhealth.trainer import Trainer\n\n# 1. Load dataset and set task\ndataset = MIMIC4Dataset(root=\"/path/to/data\")\nsample_dataset"
  },
  {
    "id": "pydeseq2",
    "name": "pydeseq2",
    "description": "Differential gene expression analysis (Python DESeq2). Identify DE genes from bulk RNA-seq counts, Wald tests, FDR correction, volcano/MA plots, for RNA-seq analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "pydeseq2",
      "rna-seq",
      "differential",
      "gene",
      "expression",
      "deseq2",
      "identify",
      "genes",
      "bulk",
      "counts"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pydeseq2",
    "fullDescription": "\n# PyDESeq2\n\n## Overview\n\nPyDESeq2 is a Python implementation of DESeq2 for differential expression analysis with bulk RNA-seq data. Design and execute complete workflows from data loading through result interpretation, including single-factor and multi-factor designs, Wald tests with multiple testing correction, optional apeGLM shrinkage, and integration with pandas and AnnData.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Analyzing bulk RNA-seq count data for differential expression\n- Comparing gene expression between experimental conditions (e.g., treated vs control)\n- Performing multi-factor designs accounting for batch effects or covariates\n- Converting R-based DESeq2 workflows to Python\n- Integrating differential expression analysis into Python-based pipelines\n- Users mention \"DESeq2\", \"differential expression\", \"RNA-seq analysis\", or \"PyDESeq2\"\n\n## Quick Start Workflow\n\nFor users who want to perform a standard differential expression analysis:\n\n```python\nimport pandas as pd\nfrom pydeseq2.dds import DeseqDataSet\nfrom pydeseq2.ds import DeseqStats\n\n# 1. Load data\ncounts_df = pd.read_csv(\"counts.csv\", index_col=0).T  # Transpose to samples Ã— genes\nmetadata = pd.read_csv(\"metadata.csv\", index_col=0)\n\n# 2. Filter low-count genes\ngenes_to_keep = counts_df.columns[counts_df.sum(axis=0) >= 10]\ncounts_df = counts_df[genes_to_keep]\n\n# 3. Initialize and fit DESeq2\ndds = DeseqDataSet(\n    counts=counts_df,\n    metadata=metadata,\n    design=\"~condition\",\n    refit_cooks=True\n)\ndds.deseq2()\n\n# 4. Perform statistical testing\nds = DeseqStats(dds, contrast=[\"condition\", \"treated\", \"control\"])\nds.summary()\n\n# 5. Access results\nresults = ds.results_df\nsignificant = results[results.padj < 0.05]\nprint(f\"Found {len(significant)} significant genes\")\n```\n\n## Core Workflow Steps\n\n### Step 1: Data Preparation\n\n**Input requirements:**\n- **Count matrix:** Samples Ã— genes DataFrame with non-negative integer read counts\n- **Metadata:** Samples Ã— variables DataFrame with e"
  },
  {
    "id": "pydicom",
    "name": "pydicom",
    "description": "Python library for working with DICOM (Digital Imaging and Communications in Medicine) files. Use this skill when reading, writing, or modifying medical imaging data in DICOM format, extracting pixel data from medical images (CT, MRI, X-ray, ultrasound), anonymizing DICOM files, working with DICOM m",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "pydicom",
      "dicom",
      "imaging",
      "medical",
      "images",
      "library",
      "digital",
      "communications",
      "medicine",
      "reading"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pydicom",
    "fullDescription": "\n# Pydicom\n\n## Overview\n\nPydicom is a pure Python package for working with DICOM files, the standard format for medical imaging data. This skill provides guidance on reading, writing, and manipulating DICOM files, including working with pixel data, metadata, and various compression formats.\n\n## When to Use This Skill\n\nUse this skill when working with:\n- Medical imaging files (CT, MRI, X-ray, ultrasound, PET, etc.)\n- DICOM datasets requiring metadata extraction or modification\n- Pixel data extraction and image processing from medical scans\n- DICOM anonymization for research or data sharing\n- Converting DICOM files to standard image formats\n- Compressed DICOM data requiring decompression\n- DICOM sequences and structured reports\n- Multi-slice volume reconstruction\n- PACS (Picture Archiving and Communication System) integration\n\n## Installation\n\nInstall pydicom and common dependencies:\n\n```bash\nuv pip install pydicom\nuv pip install pillow  # For image format conversion\nuv pip install numpy   # For pixel array manipulation\nuv pip install matplotlib  # For visualization\n```\n\nFor handling compressed DICOM files, additional packages may be needed:\n\n```bash\nuv pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg  # JPEG compression\nuv pip install python-gdcm  # Alternative compression handler\n```\n\n## Core Workflows\n\n### Reading DICOM Files\n\nRead a DICOM file using `pydicom.dcmread()`:\n\n```python\nimport pydicom\n\n# Read a DICOM file\nds = pydicom.dcmread('path/to/file.dcm')\n\n# Access metadata\nprint(f\"Patient Name: {ds.PatientName}\")\nprint(f\"Study Date: {ds.StudyDate}\")\nprint(f\"Modality: {ds.Modality}\")\n\n# Display all elements\nprint(ds)\n```\n\n**Key points:**\n- `dcmread()` returns a `Dataset` object\n- Access data elements using attribute notation (e.g., `ds.PatientName`) or tag notation (e.g., `ds[0x0010, 0x0010]`)\n- Use `ds.file_meta` to access file metadata like Transfer Syntax UID\n- Handle missing attributes with `getattr(ds, 'AttributeName', default_value)` or `hasattr(d"
  },
  {
    "id": "pufferlib",
    "name": "pufferlib",
    "description": "This skill should be used when working with reinforcement learning tasks including high-performance RL training, custom environment development, vectorized parallel simulation, multi-agent systems, or integration with existing RL environments (Gymnasium, PettingZoo, Atari, Procgen, etc.). Use this s",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "pufferlib",
      "training",
      "environments",
      "reinforcement",
      "tasks",
      "high-performance",
      "custom",
      "environment",
      "development",
      "vectorized"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pufferlib",
    "fullDescription": "\n# PufferLib - High-Performance Reinforcement Learning\n\n## Overview\n\nPufferLib is a high-performance reinforcement learning library designed for fast parallel environment simulation and training. It achieves training at millions of steps per second through optimized vectorization, native multi-agent support, and efficient PPO implementation (PuffeRL). The library provides the Ocean suite of 20+ environments and seamless integration with Gymnasium, PettingZoo, and specialized RL frameworks.\n\n## When to Use This Skill\n\nUse this skill when:\n- **Training RL agents** with PPO on any environment (single or multi-agent)\n- **Creating custom environments** using the PufferEnv API\n- **Optimizing performance** for parallel environment simulation (vectorization)\n- **Integrating existing environments** from Gymnasium, PettingZoo, Atari, Procgen, etc.\n- **Developing policies** with CNN, LSTM, or custom architectures\n- **Scaling RL** to millions of steps per second for faster experimentation\n- **Multi-agent RL** with native multi-agent environment support\n\n## Core Capabilities\n\n### 1. High-Performance Training (PuffeRL)\n\nPuffeRL is PufferLib's optimized PPO+LSTM training algorithm achieving 1M-4M steps/second.\n\n**Quick start training:**\n```bash\n# CLI training\npuffer train procgen-coinrun --train.device cuda --train.learning-rate 3e-4\n\n# Distributed training\ntorchrun --nproc_per_node=4 train.py\n```\n\n**Python training loop:**\n```python\nimport pufferlib\nfrom pufferlib import PuffeRL\n\n# Create vectorized environment\nenv = pufferlib.make('procgen-coinrun', num_envs=256)\n\n# Create trainer\ntrainer = PuffeRL(\n    env=env,\n    policy=my_policy,\n    device='cuda',\n    learning_rate=3e-4,\n    batch_size=32768\n)\n\n# Training loop\nfor iteration in range(num_iterations):\n    trainer.evaluate()  # Collect rollouts\n    trainer.train()     # Train on batch\n    trainer.mean_and_log()  # Log results\n```\n\n**For comprehensive training guidance**, read `references/training.md` for:\n- Complete training w"
  },
  {
    "id": "pubmed-database",
    "name": "pubmed-database",
    "description": "Direct REST API access to PubMed. Advanced Boolean/MeSH queries, E-utilities API, batch processing, citation management. For Python workflows, prefer biopython (Bio.Entrez). Use this for direct HTTP/REST work or custom API implementations.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "pubmed",
      "direct",
      "rest",
      "advanced",
      "boolean",
      "mesh",
      "queries",
      "e-utilities",
      "batch",
      "processing"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pubmed-database",
    "fullDescription": "\n# PubMed Database\n\n## Overview\n\nPubMed is the U.S. National Library of Medicine's comprehensive database providing free access to MEDLINE and life sciences literature. Construct advanced queries with Boolean operators, MeSH terms, and field tags, access data programmatically via E-utilities API for systematic reviews and literature analysis.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Searching for biomedical or life sciences research articles\n- Constructing complex search queries with Boolean operators, field tags, or MeSH terms\n- Conducting systematic literature reviews or meta-analyses\n- Accessing PubMed data programmatically via the E-utilities API\n- Finding articles by specific criteria (author, journal, publication date, article type)\n- Retrieving citation information, abstracts, or full-text articles\n- Working with PMIDs (PubMed IDs) or DOIs\n- Creating automated workflows for literature monitoring or data extraction\n\n## Core Capabilities\n\n### 1. Advanced Search Query Construction\n\nConstruct sophisticated PubMed queries using Boolean operators, field tags, and specialized syntax.\n\n**Basic Search Strategies**:\n- Combine concepts with Boolean operators (AND, OR, NOT)\n- Use field tags to limit searches to specific record parts\n- Employ phrase searching with double quotes for exact matches\n- Apply wildcards for term variations\n- Use proximity searching for terms within specified distances\n\n**Example Queries**:\n```\n# Recent systematic reviews on diabetes treatment\ndiabetes mellitus[mh] AND treatment[tiab] AND systematic review[pt] AND 2023:2024[dp]\n\n# Clinical trials comparing two drugs\n(metformin[nm] OR insulin[nm]) AND diabetes mellitus, type 2[mh] AND randomized controlled trial[pt]\n\n# Author-specific research\nsmith ja[au] AND cancer[tiab] AND 2023[dp] AND english[la]\n```\n\n**When to consult search_syntax.md**:\n- Need comprehensive list of available field tags\n- Require detailed explanation of search operators\n- Constructing complex proximity s"
  },
  {
    "id": "pubchem-database",
    "name": "pubchem-database",
    "description": "Query PubChem via PUG-REST API/PubChemPy (110M+ compounds). Search by name/CID/SMILES, retrieve properties, similarity/substructure searches, bioactivity, for cheminformatics.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "pubchem",
      "via",
      "pug-rest",
      "pubchempy",
      "110m",
      "compounds",
      "name",
      "cid",
      "smiles",
      "retrieve"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pubchem-database",
    "fullDescription": "\n# PubChem Database\n\n## Overview\n\nPubChem is the world's largest freely available chemical database with 110M+ compounds and 270M+ bioactivities. Query chemical structures by name, CID, or SMILES, retrieve molecular properties, perform similarity and substructure searches, access bioactivity data using PUG-REST API and PubChemPy.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Searching for chemical compounds by name, structure (SMILES/InChI), or molecular formula\n- Retrieving molecular properties (MW, LogP, TPSA, hydrogen bonding descriptors)\n- Performing similarity searches to find structurally related compounds\n- Conducting substructure searches for specific chemical motifs\n- Accessing bioactivity data from screening assays\n- Converting between chemical identifier formats (CID, SMILES, InChI)\n- Batch processing multiple compounds for drug-likeness screening or property analysis\n\n## Core Capabilities\n\n### 1. Chemical Structure Search\n\nSearch for compounds using multiple identifier types:\n\n**By Chemical Name**:\n```python\nimport pubchempy as pcp\ncompounds = pcp.get_compounds('aspirin', 'name')\ncompound = compounds[0]\n```\n\n**By CID (Compound ID)**:\n```python\ncompound = pcp.Compound.from_cid(2244)  # Aspirin\n```\n\n**By SMILES**:\n```python\ncompound = pcp.get_compounds('CC(=O)OC1=CC=CC=C1C(=O)O', 'smiles')[0]\n```\n\n**By InChI**:\n```python\ncompound = pcp.get_compounds('InChI=1S/C9H8O4/...', 'inchi')[0]\n```\n\n**By Molecular Formula**:\n```python\ncompounds = pcp.get_compounds('C9H8O4', 'formula')\n# Returns all compounds matching this formula\n```\n\n### 2. Property Retrieval\n\nRetrieve molecular properties for compounds using either high-level or low-level approaches:\n\n**Using PubChemPy (Recommended)**:\n```python\nimport pubchempy as pcp\n\n# Get compound object with all properties\ncompound = pcp.get_compounds('caffeine', 'name')[0]\n\n# Access individual properties\nmolecular_formula = compound.molecular_formula\nmolecular_weight = compound.molecular_weight\niupac_name = co"
  },
  {
    "id": "protocolsio-integration",
    "name": "protocolsio-integration",
    "description": "Integration with protocols.io API for managing scientific protocols. This skill should be used when working with protocols.io to search, create, update, or publish protocols; manage protocol steps and materials; handle discussions and comments; organize workspaces; upload and manage files; or integr",
    "category": "lab-automation",
    "source": "scientific",
    "triggers": [
      "protocolsio",
      "integration",
      "protocols",
      "protocol",
      "scientific",
      "manage",
      "managing",
      "update",
      "publish",
      "steps"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/protocolsio-integration",
    "fullDescription": "\n# Protocols.io Integration\n\n## Overview\n\nProtocols.io is a comprehensive platform for developing, sharing, and managing scientific protocols. This skill provides complete integration with the protocols.io API v3, enabling programmatic access to protocols, workspaces, discussions, file management, and collaboration features.\n\n## When to Use This Skill\n\nUse this skill when working with protocols.io in any of the following scenarios:\n\n- **Protocol Discovery**: Searching for existing protocols by keywords, DOI, or category\n- **Protocol Management**: Creating, updating, or publishing scientific protocols\n- **Step Management**: Adding, editing, or organizing protocol steps and procedures\n- **Collaborative Development**: Working with team members on shared protocols\n- **Workspace Organization**: Managing lab or institutional protocol repositories\n- **Discussion & Feedback**: Adding or responding to protocol comments\n- **File Management**: Uploading data files, images, or documents to protocols\n- **Experiment Tracking**: Documenting protocol executions and results\n- **Data Export**: Backing up or migrating protocol collections\n- **Integration Projects**: Building tools that interact with protocols.io\n\n## Core Capabilities\n\nThis skill provides comprehensive guidance across five major capability areas:\n\n### 1. Authentication & Access\n\nManage API authentication using access tokens and OAuth flows. Includes both client access tokens (for personal content) and OAuth tokens (for multi-user applications).\n\n**Key operations:**\n- Generate authorization links for OAuth flow\n- Exchange authorization codes for access tokens\n- Refresh expired tokens\n- Manage rate limits and permissions\n\n**Reference:** Read `references/authentication.md` for detailed authentication procedures, OAuth implementation, and security best practices.\n\n### 2. Protocol Operations\n\nComplete protocol lifecycle management from creation to publication.\n\n**Key operations:**\n- Search and discover protocols by keywords"
  },
  {
    "id": "latex-posters",
    "name": "latex-posters",
    "description": "Create professional research posters in LaTeX using beamerposter, tikzposter, or baposter. Support for conference presentations, academic posters, and scientific communication. Includes layout design, color schemes, multi-column formats, figure integration, and poster-specific best practices for vis",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "latex",
      "posters",
      "communication",
      "professional",
      "beamerposter",
      "tikzposter",
      "baposter",
      "conference",
      "presentations",
      "academic"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pptx-posters",
    "fullDescription": "\n# LaTeX Research Posters\n\n## Overview\n\nResearch posters are a critical medium for scientific communication at conferences, symposia, and academic events. This skill provides comprehensive guidance for creating professional, visually appealing research posters using LaTeX packages. Generate publication-quality posters with proper layout, typography, color schemes, and visual hierarchy.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating research posters for conferences, symposia, or poster sessions\n- Designing academic posters for university events or thesis defenses\n- Preparing visual summaries of research for public engagement\n- Converting scientific papers into poster format\n- Creating template posters for research groups or departments\n- Designing posters that comply with specific conference size requirements (A0, A1, 36Ã—48\", etc.)\n- Building posters with complex multi-column layouts\n- Integrating figures, tables, equations, and citations in poster format\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every research poster MUST include at least 2-3 AI-generated figures using the scientific-schematics skill.**\n\nThis is not optional. Posters are primarily visual media - text-heavy posters fail to communicate effectively. Before finalizing any poster:\n1. Generate at minimum TWO schematics or diagrams\n2. Target 3-4 figures for comprehensive posters (methodology flowchart, key results visualization, conceptual framework)\n3. Figures should occupy 40-50% of poster area\n\n**How to generate figures:**\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper "
  },
  {
    "id": "polars",
    "name": "polars",
    "description": "Fast DataFrame library (Apache Arrow). Select, filter, group_by, joins, lazy evaluation, CSV/Parquet I/O, expression API, for high-performance data analysis workflows.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "polars",
      "fast",
      "dataframe",
      "library",
      "apache",
      "arrow",
      "select",
      "filter",
      "group_by",
      "joins"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/polars",
    "fullDescription": "\n# Polars\n\n## Overview\n\nPolars is a lightning-fast DataFrame library for Python and Rust built on Apache Arrow. Work with Polars' expression-based API, lazy evaluation framework, and high-performance data manipulation capabilities for efficient data processing, pandas migration, and data pipeline optimization.\n\n## Quick Start\n\n### Installation and Basic Usage\n\nInstall Polars:\n```python\nuv pip install polars\n```\n\nBasic DataFrame creation and operations:\n```python\nimport polars as pl\n\n# Create DataFrame\ndf = pl.DataFrame({\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"city\": [\"NY\", \"LA\", \"SF\"]\n})\n\n# Select columns\ndf.select(\"name\", \"age\")\n\n# Filter rows\ndf.filter(pl.col(\"age\") > 25)\n\n# Add computed columns\ndf.with_columns(\n    age_plus_10=pl.col(\"age\") + 10\n)\n```\n\n## Core Concepts\n\n### Expressions\n\nExpressions are the fundamental building blocks of Polars operations. They describe transformations on data and can be composed, reused, and optimized.\n\n**Key principles:**\n- Use `pl.col(\"column_name\")` to reference columns\n- Chain methods to build complex transformations\n- Expressions are lazy and only execute within contexts (select, with_columns, filter, group_by)\n\n**Example:**\n```python\n# Expression-based computation\ndf.select(\n    pl.col(\"name\"),\n    (pl.col(\"age\") * 12).alias(\"age_in_months\")\n)\n```\n\n### Lazy vs Eager Evaluation\n\n**Eager (DataFrame):** Operations execute immediately\n```python\ndf = pl.read_csv(\"file.csv\")  # Reads immediately\nresult = df.filter(pl.col(\"age\") > 25)  # Executes immediately\n```\n\n**Lazy (LazyFrame):** Operations build a query plan, optimized before execution\n```python\nlf = pl.scan_csv(\"file.csv\")  # Doesn't read yet\nresult = lf.filter(pl.col(\"age\") > 25).select(\"name\", \"age\")\ndf = result.collect()  # Now executes optimized query\n```\n\n**When to use lazy:**\n- Working with large datasets\n- Complex query pipelines\n- When only some columns/rows are needed\n- Performance is critical\n\n**Benefits of lazy evaluation:**\n- Auto"
  },
  {
    "id": "plotly",
    "name": "plotly",
    "description": "Interactive scientific and statistical data visualization library for Python. Use when creating charts, plots, or visualizations including scatter plots, line charts, bar charts, heatmaps, 3D plots, geographic maps, statistical distributions, financial charts, and dashboards. Supports both quick vis",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "plotly",
      "charts",
      "plots",
      "interactive",
      "statistical",
      "visualizations",
      "scientific",
      "visualization",
      "library",
      "scatter"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/plotly",
    "fullDescription": "\n# Plotly\n\nPython graphing library for creating interactive, publication-quality visualizations with 40+ chart types.\n\n## Quick Start\n\nInstall Plotly:\n```bash\nuv pip install plotly\n```\n\nBasic usage with Plotly Express (high-level API):\n```python\nimport plotly.express as px\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'x': [1, 2, 3, 4],\n    'y': [10, 11, 12, 13]\n})\n\nfig = px.scatter(df, x='x', y='y', title='My First Plot')\nfig.show()\n```\n\n## Choosing Between APIs\n\n### Use Plotly Express (px)\nFor quick, standard visualizations with sensible defaults:\n- Working with pandas DataFrames\n- Creating common chart types (scatter, line, bar, histogram, etc.)\n- Need automatic color encoding and legends\n- Want minimal code (1-5 lines)\n\nSee [reference/plotly-express.md](reference/plotly-express.md) for complete guide.\n\n### Use Graph Objects (go)\nFor fine-grained control and custom visualizations:\n- Chart types not in Plotly Express (3D mesh, isosurface, complex financial charts)\n- Building complex multi-trace figures from scratch\n- Need precise control over individual components\n- Creating specialized visualizations with custom shapes and annotations\n\nSee [reference/graph-objects.md](reference/graph-objects.md) for complete guide.\n\n**Note:** Plotly Express returns graph objects Figure, so you can combine approaches:\n```python\nfig = px.scatter(df, x='x', y='y')\nfig.update_layout(title='Custom Title')  # Use go methods on px figure\nfig.add_hline(y=10)                     # Add shapes\n```\n\n## Core Capabilities\n\n### 1. Chart Types\n\nPlotly supports 40+ chart types organized into categories:\n\n**Basic Charts:** scatter, line, bar, pie, area, bubble\n\n**Statistical Charts:** histogram, box plot, violin, distribution, error bars\n\n**Scientific Charts:** heatmap, contour, ternary, image display\n\n**Financial Charts:** candlestick, OHLC, waterfall, funnel, time series\n\n**Maps:** scatter maps, choropleth, density maps (geographic visualization)\n\n**3D Charts:** scatter3d, surface, mesh, cone, vo"
  },
  {
    "id": "pennylane",
    "name": "pennylane",
    "description": "Cross-platform Python library for quantum computing, quantum machine learning, and quantum chemistry. Enables building and training quantum circuits with automatic differentiation, seamless integration with PyTorch/JAX/TensorFlow, and device-independent execution across simulators and quantum hardwa",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "pennylane",
      "quantum",
      "computing",
      "machine",
      "chemistry",
      "circuits",
      "cross-platform",
      "library",
      "training",
      "automatic"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pennylane",
    "fullDescription": "\n# PennyLane\n\n## Overview\n\nPennyLane is a quantum computing library that enables training quantum computers like neural networks. It provides automatic differentiation of quantum circuits, device-independent programming, and seamless integration with classical machine learning frameworks.\n\n## Installation\n\nInstall using uv:\n\n```bash\nuv pip install pennylane\n```\n\nFor quantum hardware access, install device plugins:\n\n```bash\n# IBM Quantum\nuv pip install pennylane-qiskit\n\n# Amazon Braket\nuv pip install amazon-braket-pennylane-plugin\n\n# Google Cirq\nuv pip install pennylane-cirq\n\n# Rigetti Forest\nuv pip install pennylane-rigetti\n\n# IonQ\nuv pip install pennylane-ionq\n```\n\n## Quick Start\n\nBuild a quantum circuit and optimize its parameters:\n\n```python\nimport pennylane as qml\nfrom pennylane import numpy as np\n\n# Create device\ndev = qml.device('default.qubit', wires=2)\n\n# Define quantum circuit\n@qml.qnode(dev)\ndef circuit(params):\n    qml.RX(params[0], wires=0)\n    qml.RY(params[1], wires=1)\n    qml.CNOT(wires=[0, 1])\n    return qml.expval(qml.PauliZ(0))\n\n# Optimize parameters\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\nparams = np.array([0.1, 0.2], requires_grad=True)\n\nfor i in range(100):\n    params = opt.step(circuit, params)\n```\n\n## Core Capabilities\n\n### 1. Quantum Circuit Construction\n\nBuild circuits with gates, measurements, and state preparation. See `references/quantum_circuits.md` for:\n- Single and multi-qubit gates\n- Controlled operations and conditional logic\n- Mid-circuit measurements and adaptive circuits\n- Various measurement types (expectation, probability, samples)\n- Circuit inspection and debugging\n\n### 2. Quantum Machine Learning\n\nCreate hybrid quantum-classical models. See `references/quantum_ml.md` for:\n- Integration with PyTorch, JAX, TensorFlow\n- Quantum neural networks and variational classifiers\n- Data encoding strategies (angle, amplitude, basis, IQP)\n- Training hybrid models with backpropagation\n- Transfer learning with quantum circuits\n\n### 3"
  },
  {
    "id": "peer-review",
    "name": "peer-review",
    "description": "Systematic peer review toolkit. Evaluate methodology, statistics, design, reproducibility, ethics, figure integrity, reporting standards, for manuscript and grant review across disciplines.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "peer",
      "review",
      "systematic",
      "evaluate",
      "methodology",
      "statistics",
      "design",
      "reproducibility",
      "ethics",
      "figure"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/peer-review",
    "fullDescription": "\n# Scientific Critical Evaluation and Peer Review\n\n## Overview\n\nPeer review is a systematic process for evaluating scientific manuscripts. Assess methodology, statistics, design, reproducibility, ethics, and reporting standards. Apply this skill for manuscript and grant review across disciplines with constructive, rigorous evaluation.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Conducting peer review of scientific manuscripts for journals\n- Evaluating grant proposals and research applications\n- Assessing methodology and experimental design rigor\n- Reviewing statistical analyses and reporting standards\n- Evaluating reproducibility and data availability\n- Checking compliance with reporting guidelines (CONSORT, STROBE, PRISMA)\n- Providing constructive feedback on scientific writing\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper formatting\n- Review and refine through multiple iterations\n- Ensure accessibility (colorblind-friendly, high contrast)\n- Save outputs in the figures/ directory\n\n**When to add schematics:**\n- Peer review workflow diagrams\n- Evaluation criteria decision trees\n- Review process flowcharts\n- Methodology assessment framewor"
  },
  {
    "id": "perplexity-search",
    "name": "perplexity-search",
    "description": "Perform AI-powered web searches with real-time information using Perplexity models via LiteLLM and OpenRouter. This skill should be used when conducting web searches for current information, finding recent scientific literature, getting grounded answers with source citations, or accessing informatio",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "perplexity",
      "information",
      "sonar",
      "pro",
      "web",
      "searches",
      "openrouter",
      "perform",
      "ai-powered",
      "real-time"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/perplexity-search",
    "fullDescription": "\n# Perplexity Search\n\n## Overview\n\nPerform AI-powered web searches using Perplexity models through LiteLLM and OpenRouter. Perplexity provides real-time, web-grounded answers with source citations, making it ideal for finding current information, recent scientific literature, and facts beyond the model's training data cutoff.\n\nThis skill provides access to all Perplexity models through OpenRouter, requiring only a single API key (no separate Perplexity account needed).\n\n## When to Use This Skill\n\nUse this skill when:\n- Searching for current information or recent developments (2024 and beyond)\n- Finding latest scientific publications and research\n- Getting real-time answers grounded in web sources\n- Verifying facts with source citations\n- Conducting literature searches across multiple domains\n- Accessing information beyond the model's knowledge cutoff\n- Performing domain-specific research (biomedical, technical, clinical)\n- Comparing current approaches or technologies\n\n**Do not use** for:\n- Simple calculations or logic problems (use directly)\n- Tasks requiring code execution (use standard tools)\n- Questions well within the model's training data (unless verification needed)\n\n## Quick Start\n\n### Setup (One-time)\n\n1. **Get OpenRouter API key**:\n   - Visit https://openrouter.ai/keys\n   - Create account and generate API key\n   - Add credits to account (minimum $5 recommended)\n\n2. **Configure environment**:\n   ```bash\n   # Set API key\n   export OPENROUTER_API_KEY='sk-or-v1-your-key-here'\n\n   # Or use setup script\n   python scripts/setup_env.py --api-key sk-or-v1-your-key-here\n   ```\n\n3. **Install dependencies**:\n   ```bash\n   uv pip install litellm\n   ```\n\n4. **Verify setup**:\n   ```bash\n   python scripts/perplexity_search.py --check-setup\n   ```\n\nSee `references/openrouter_setup.md` for detailed setup instructions, troubleshooting, and security best practices.\n\n### Basic Usage\n\n**Simple search:**\n```bash\npython scripts/perplexity_search.py \"What are the latest development"
  },
  {
    "id": "pdb-database",
    "name": "pdb-database",
    "description": "Access RCSB PDB for 3D protein/nucleic acid structures. Search by text/sequence/structure, download coordinates (PDB/mmCIF), retrieve metadata, for structural biology and drug discovery.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "pdb",
      "rcsb",
      "protein",
      "nucleic",
      "acid",
      "structures",
      "text",
      "sequence",
      "structure",
      "download"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pdb-database",
    "fullDescription": "\n# PDB Database\n\n## Overview\n\nRCSB PDB is the worldwide repository for 3D structural data of biological macromolecules. Search for structures, retrieve coordinates and metadata, perform sequence and structure similarity searches across 200,000+ experimentally determined structures and computed models.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Searching for protein or nucleic acid 3D structures by text, sequence, or structural similarity\n- Downloading coordinate files in PDB, mmCIF, or BinaryCIF formats\n- Retrieving structural metadata, experimental methods, or quality metrics\n- Performing batch operations across multiple structures\n- Integrating PDB data into computational workflows for drug discovery, protein engineering, or structural biology research\n\n## Core Capabilities\n\n### 1. Searching for Structures\n\nFind PDB entries using various search criteria:\n\n**Text Search:** Search by protein name, keywords, or descriptions\n```python\nfrom rcsbapi.search import TextQuery\nquery = TextQuery(\"hemoglobin\")\nresults = list(query())\nprint(f\"Found {len(results)} structures\")\n```\n\n**Attribute Search:** Query specific properties (organism, resolution, method, etc.)\n```python\nfrom rcsbapi.search import AttributeQuery\nfrom rcsbapi.search.attrs import rcsb_entity_source_organism\n\n# Find human protein structures\nquery = AttributeQuery(\n    attribute=rcsb_entity_source_organism.scientific_name,\n    operator=\"exact_match\",\n    value=\"Homo sapiens\"\n)\nresults = list(query())\n```\n\n**Sequence Similarity:** Find structures similar to a given sequence\n```python\nfrom rcsbapi.search import SequenceQuery\n\nquery = SequenceQuery(\n    value=\"MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHHYREQIKRVKDSEDVPMVLVGNKCDLPSRTVDTKQAQDLARSYGIPFIETSAKTRQGVDDAFYTLVREIRKHKEKMSKDGKKKKKKSKTKCVIM\",\n    evalue_cutoff=0.1,\n    identity_cutoff=0.9\n)\nresults = list(query())\n```\n\n**Structure Similarity:** Find structures with similar 3D geometry\n```py"
  },
  {
    "id": "pathml",
    "name": "pathml",
    "description": "Computational pathology toolkit for analyzing whole-slide images (WSI) and multiparametric imaging data. Use this skill when working with histopathology slides, H&E stained images, multiplex immunofluorescence (CODEX, Vectra), spatial proteomics, nucleus detection/segmentation, tissue graph construc",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "pathml",
      "pathology",
      "images",
      "computational",
      "analyzing",
      "whole-slide",
      "wsi",
      "multiparametric",
      "imaging",
      "histopathology"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/pathml",
    "fullDescription": "\n# PathML\n\n## Overview\n\nPathML is a comprehensive Python toolkit for computational pathology workflows, designed to facilitate machine learning and image analysis for whole-slide pathology images. The framework provides modular, composable tools for loading diverse slide formats, preprocessing images, constructing spatial graphs, training deep learning models, and analyzing multiparametric imaging data from technologies like CODEX and multiplex immunofluorescence.\n\n## When to Use This Skill\n\nApply this skill for:\n- Loading and processing whole-slide images (WSI) in various proprietary formats\n- Preprocessing H&E stained tissue images with stain normalization\n- Nucleus detection, segmentation, and classification workflows\n- Building cell and tissue graphs for spatial analysis\n- Training or deploying machine learning models (HoVer-Net, HACTNet) on pathology data\n- Analyzing multiparametric imaging (CODEX, Vectra, MERFISH) for spatial proteomics\n- Quantifying marker expression from multiplex immunofluorescence\n- Managing large-scale pathology datasets with HDF5 storage\n- Tile-based analysis and stitching operations\n\n## Core Capabilities\n\nPathML provides six major capability areas documented in detail within reference files:\n\n### 1. Image Loading & Formats\n\nLoad whole-slide images from 160+ proprietary formats including Aperio SVS, Hamamatsu NDPI, Leica SCN, Zeiss ZVI, DICOM, and OME-TIFF. PathML automatically handles vendor-specific formats and provides unified interfaces for accessing image pyramids, metadata, and regions of interest.\n\n**See:** `references/image_loading.md` for supported formats, loading strategies, and working with different slide types.\n\n### 2. Preprocessing Pipelines\n\nBuild modular preprocessing pipelines by composing transforms for image manipulation, quality control, stain normalization, tissue detection, and mask operations. PathML's Pipeline architecture enables reproducible, scalable preprocessing across large datasets.\n\n**Key transforms:**\n- "
  },
  {
    "id": "paper-2-web",
    "name": "paper-2-web",
    "description": "This skill should be used when converting academic papers into promotional and presentation formats including interactive websites (Paper2Web), presentation videos (Paper2Video), and conference posters (Paper2Poster). Use this skill for tasks involving paper dissemination, conference preparation, cr",
    "category": "sci-communication",
    "source": "scientific",
    "triggers": [
      "paper",
      "web",
      "academic",
      "presentation",
      "conference",
      "posters",
      "converting",
      "papers",
      "promotional",
      "formats"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/paper-2-web",
    "fullDescription": "\n# Paper2All: Academic Paper Transformation Pipeline\n\n## Overview\n\nThis skill enables the transformation of academic papers into multiple promotional and presentation formats using the Paper2All autonomous pipeline. The system converts research papers (LaTeX or PDF) into three primary outputs:\n\n1. **Paper2Web**: Interactive, explorable academic homepages with layout-aware design\n2. **Paper2Video**: Professional presentation videos with narration, slides, and optional talking-head\n3. **Paper2Poster**: Print-ready conference posters with professional layouts\n\nThe pipeline uses LLM-powered content extraction, design generation, and iterative refinement to create high-quality outputs suitable for conferences, journals, preprint repositories, and academic promotion.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- **Creating conference materials**: Posters, presentation videos, and companion websites for academic conferences\n- **Promoting research**: Converting published papers or preprints into accessible, engaging web formats\n- **Preparing presentations**: Generating video abstracts or full presentation videos from paper content\n- **Disseminating findings**: Creating promotional materials for social media, lab websites, or institutional showcases\n- **Enhancing preprints**: Adding interactive homepages to bioRxiv, arXiv, or other preprint submissions\n- **Batch processing**: Generating promotional materials for multiple papers simultaneously\n\n**Trigger phrases**:\n- \"Convert this paper to a website\"\n- \"Generate a conference poster from my LaTeX paper\"\n- \"Create a video presentation from this research\"\n- \"Make an interactive homepage for my paper\"\n- \"Transform my paper into promotional materials\"\n- \"Generate a poster and video for my conference talk\"\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already c"
  },
  {
    "id": "opentargets-database",
    "name": "opentargets-database",
    "description": "Query Open Targets Platform for target-disease associations, drug target discovery, tractability/safety data, genetics/omics evidence, known drugs, for therapeutic target identification.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "opentargets",
      "target",
      "open",
      "targets",
      "target-disease",
      "associations",
      "drug",
      "discovery",
      "tractability",
      "safety"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/opentargets-database",
    "fullDescription": "\n# Open Targets Database\n\n## Overview\n\nThe Open Targets Platform is a comprehensive resource for systematic identification and prioritization of potential therapeutic drug targets. It integrates publicly available datasets including human genetics, omics, literature, and chemical data to build and score target-disease associations.\n\n**Key capabilities:**\n- Query target (gene) annotations including tractability, safety, expression\n- Search for disease-target associations with evidence scores\n- Retrieve evidence from multiple data types (genetics, pathways, literature, etc.)\n- Find known drugs for diseases and their mechanisms\n- Access drug information including clinical trial phases and adverse events\n- Evaluate target druggability and therapeutic potential\n\n**Data access:** The platform provides a GraphQL API, web interface, data downloads, and Google BigQuery access. This skill focuses on the GraphQL API for programmatic access.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **Target discovery:** Finding potential therapeutic targets for a disease\n- **Target assessment:** Evaluating tractability, safety, and druggability of genes\n- **Evidence gathering:** Retrieving supporting evidence for target-disease associations\n- **Drug repurposing:** Identifying existing drugs that could be repurposed for new indications\n- **Competitive intelligence:** Understanding clinical precedence and drug development landscape\n- **Target prioritization:** Ranking targets based on genetic evidence and other data types\n- **Mechanism research:** Investigating biological pathways and gene functions\n- **Biomarker discovery:** Finding genes differentially expressed in disease\n- **Safety assessment:** Identifying potential toxicity concerns for drug targets\n\n## Core Workflow\n\n### 1. Search for Entities\n\nStart by finding the identifiers for targets, diseases, or drugs of interest.\n\n**For targets (genes):**\n```python\nfrom scripts.query_opentargets import search_entities\n\n# Searc"
  },
  {
    "id": "openalex-database",
    "name": "openalex-database",
    "description": "Query and analyze scholarly literature using the OpenAlex database. This skill should be used when searching for academic papers, analyzing research trends, finding works by authors or institutions, tracking citations, discovering open access publications, or conducting bibliometric analysis across ",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "openalex",
      "scholarly",
      "literature",
      "academic",
      "works",
      "analyze",
      "searching",
      "papers",
      "analyzing",
      "trends"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/openalex-database",
    "fullDescription": "\n# OpenAlex Database\n\n## Overview\n\nOpenAlex is a comprehensive open catalog of 240M+ scholarly works, authors, institutions, topics, sources, publishers, and funders. This skill provides tools and workflows for querying the OpenAlex API to search literature, analyze research output, track citations, and conduct bibliometric studies.\n\n## Quick Start\n\n### Basic Setup\n\nAlways initialize the client with an email address to access the polite pool (10x rate limit boost):\n\n```python\nfrom scripts.openalex_client import OpenAlexClient\n\nclient = OpenAlexClient(email=\"your-email@example.edu\")\n```\n\n### Installation Requirements\n\nInstall required package using uv:\n\n```bash\nuv pip install requests\n```\n\nNo API key required - OpenAlex is completely open.\n\n## Core Capabilities\n\n### 1. Search for Papers\n\n**Use for**: Finding papers by title, abstract, or topic\n\n```python\n# Simple search\nresults = client.search_works(\n    search=\"machine learning\",\n    per_page=100\n)\n\n# Search with filters\nresults = client.search_works(\n    search=\"CRISPR gene editing\",\n    filter_params={\n        \"publication_year\": \">2020\",\n        \"is_oa\": \"true\"\n    },\n    sort=\"cited_by_count:desc\"\n)\n```\n\n### 2. Find Works by Author\n\n**Use for**: Getting all publications by a specific researcher\n\nUse the two-step pattern (entity name â†’ ID â†’ works):\n\n```python\nfrom scripts.query_helpers import find_author_works\n\nworks = find_author_works(\n    author_name=\"Jennifer Doudna\",\n    client=client,\n    limit=100\n)\n```\n\n**Manual two-step approach**:\n```python\n# Step 1: Get author ID\nauthor_response = client._make_request(\n    '/authors',\n    params={'search': 'Jennifer Doudna', 'per-page': 1}\n)\nauthor_id = author_response['results'][0]['id'].split('/')[-1]\n\n# Step 2: Get works\nworks = client.search_works(\n    filter_params={\"authorships.author.id\": author_id}\n)\n```\n\n### 3. Find Works from Institution\n\n**Use for**: Analyzing research output from universities or organizations\n\n```python\nfrom scripts.query_helpers import fin"
  },
  {
    "id": "omero-integration",
    "name": "omero-integration",
    "description": "Microscopy data management platform. Access images via Python, retrieve datasets, analyze pixels, manage ROIs/annotations, batch processing, for high-content screening and microscopy workflows.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "omero",
      "integration",
      "microscopy",
      "management",
      "images",
      "via",
      "retrieve",
      "datasets",
      "analyze",
      "pixels"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/omero-integration",
    "fullDescription": "\n# OMERO Integration\n\n## Overview\n\nOMERO is an open-source platform for managing, visualizing, and analyzing microscopy images and metadata. Access images via Python API, retrieve datasets, analyze pixels, manage ROIs and annotations, for high-content screening and microscopy workflows.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with OMERO Python API (omero-py) to access microscopy data\n- Retrieving images, datasets, projects, or screening data programmatically\n- Analyzing pixel data and creating derived images\n- Creating or managing ROIs (regions of interest) on microscopy images\n- Adding annotations, tags, or metadata to OMERO objects\n- Storing measurement results in OMERO tables\n- Creating server-side scripts for batch processing\n- Performing high-content screening analysis\n\n## Core Capabilities\n\nThis skill covers eight major capability areas. Each is documented in detail in the references/ directory:\n\n### 1. Connection & Session Management\n**File**: `references/connection.md`\n\nEstablish secure connections to OMERO servers, manage sessions, handle authentication, and work with group contexts. Use this for initial setup and connection patterns.\n\n**Common scenarios:**\n- Connect to OMERO server with credentials\n- Use existing session IDs\n- Switch between group contexts\n- Manage connection lifecycle with context managers\n\n### 2. Data Access & Retrieval\n**File**: `references/data_access.md`\n\nNavigate OMERO's hierarchical data structure (Projects â†’ Datasets â†’ Images) and screening data (Screens â†’ Plates â†’ Wells). Retrieve objects, query by attributes, and access metadata.\n\n**Common scenarios:**\n- List all projects and datasets for a user\n- Retrieve images by ID or dataset\n- Access screening plate data\n- Query objects with filters\n\n### 3. Metadata & Annotations\n**File**: `references/metadata.md`\n\nCreate and manage annotations including tags, key-value pairs, file attachments, and comments. Link annotations to images, datasets, or other objects"
  },
  {
    "id": "neuropixels-analysis",
    "name": "neuropixels-analysis",
    "description": "Neuropixels neural recording analysis. Load SpikeGLX/OpenEphys data, preprocess, motion correction, Kilosort4 spike sorting, quality metrics, Allen/IBL curation, AI-assisted visual analysis, for Neuropixels 1.0/2.0 extracellular electrophysiology. Use when working with neural recordings, spike sorti",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "neuropixels",
      "neural",
      "spikeglx",
      "spike",
      "sorting",
      "quality",
      "metrics",
      "curation",
      "extracellular",
      "electrophysiology"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/neuropixels-analysis",
    "fullDescription": "\n# Neuropixels Data Analysis\n\n## Overview\n\nComprehensive toolkit for analyzing Neuropixels high-density neural recordings using current best practices from SpikeInterface, Allen Institute, and International Brain Laboratory (IBL). Supports the full workflow from raw data to publication-ready curated units.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with Neuropixels recordings (.ap.bin, .lf.bin, .meta files)\n- Loading data from SpikeGLX, Open Ephys, or NWB formats\n- Preprocessing neural recordings (filtering, CAR, bad channel detection)\n- Detecting and correcting motion/drift in recordings\n- Running spike sorting (Kilosort4, SpykingCircus2, Mountainsort5)\n- Computing quality metrics (SNR, ISI violations, presence ratio)\n- Curating units using Allen/IBL criteria\n- Creating visualizations of neural data\n- Exporting results to Phy or NWB\n\n## Supported Hardware & Formats\n\n| Probe | Electrodes | Channels | Notes |\n|-------|-----------|----------|-------|\n| Neuropixels 1.0 | 960 | 384 | Requires phase_shift correction |\n| Neuropixels 2.0 (single) | 1280 | 384 | Denser geometry |\n| Neuropixels 2.0 (4-shank) | 5120 | 384 | Multi-region recording |\n\n| Format | Extension | Reader |\n|--------|-----------|--------|\n| SpikeGLX | `.ap.bin`, `.lf.bin`, `.meta` | `si.read_spikeglx()` |\n| Open Ephys | `.continuous`, `.oebin` | `si.read_openephys()` |\n| NWB | `.nwb` | `si.read_nwb()` |\n\n## Quick Start\n\n### Basic Import and Setup\n\n```python\nimport spikeinterface.full as si\nimport neuropixels_analysis as npa\n\n# Configure parallel processing\njob_kwargs = dict(n_jobs=-1, chunk_duration='1s', progress_bar=True)\n```\n\n### Loading Data\n\n```python\n# SpikeGLX (most common)\nrecording = si.read_spikeglx('/path/to/data', stream_id='imec0.ap')\n\n# Open Ephys (common for many labs)\nrecording = si.read_openephys('/path/to/Record_Node_101/')\n\n# Check available streams\nstreams, ids = si.get_neo_streams('spikeglx', '/path/to/data')\nprint(streams)  # ['imec0.ap', 'imec0.lf', 'ni"
  },
  {
    "id": "neurokit2",
    "name": "neurokit2",
    "description": "Comprehensive biosignal processing toolkit for analyzing physiological data including ECG, EEG, EDA, RSP, PPG, EMG, and EOG signals. Use this skill when processing cardiovascular signals, brain activity, electrodermal responses, respiratory patterns, muscle activity, or eye movements. Applicable for",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "neurokit2",
      "processing",
      "physiological",
      "signals",
      "activity",
      "biosignal",
      "analyzing",
      "ecg",
      "eeg",
      "eda"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/neurokit2",
    "fullDescription": "\n# NeuroKit2\n\n## Overview\n\nNeuroKit2 is a comprehensive Python toolkit for processing and analyzing physiological signals (biosignals). Use this skill to process cardiovascular, neural, autonomic, respiratory, and muscular signals for psychophysiology research, clinical applications, and human-computer interaction studies.\n\n## When to Use This Skill\n\nApply this skill when working with:\n- **Cardiac signals**: ECG, PPG, heart rate variability (HRV), pulse analysis\n- **Brain signals**: EEG frequency bands, microstates, complexity, source localization\n- **Autonomic signals**: Electrodermal activity (EDA/GSR), skin conductance responses (SCR)\n- **Respiratory signals**: Breathing rate, respiratory variability (RRV), volume per time\n- **Muscular signals**: EMG amplitude, muscle activation detection\n- **Eye tracking**: EOG, blink detection and analysis\n- **Multi-modal integration**: Processing multiple physiological signals simultaneously\n- **Complexity analysis**: Entropy measures, fractal dimensions, nonlinear dynamics\n\n## Core Capabilities\n\n### 1. Cardiac Signal Processing (ECG/PPG)\n\nProcess electrocardiogram and photoplethysmography signals for cardiovascular analysis. See `references/ecg_cardiac.md` for detailed workflows.\n\n**Primary workflows:**\n- ECG processing pipeline: cleaning â†’ R-peak detection â†’ delineation â†’ quality assessment\n- HRV analysis across time, frequency, and nonlinear domains\n- PPG pulse analysis and quality assessment\n- ECG-derived respiration extraction\n\n**Key functions:**\n```python\nimport neurokit2 as nk\n\n# Complete ECG processing pipeline\nsignals, info = nk.ecg_process(ecg_signal, sampling_rate=1000)\n\n# Analyze ECG data (event-related or interval-related)\nanalysis = nk.ecg_analyze(signals, sampling_rate=1000)\n\n# Comprehensive HRV analysis\nhrv = nk.hrv(peaks, sampling_rate=1000)  # Time, frequency, nonlinear domains\n```\n\n### 2. Heart Rate Variability Analysis\n\nCompute comprehensive HRV metrics from cardiac signals. See `references/hrv.md` for all "
  },
  {
    "id": "networkx",
    "name": "networkx",
    "description": "Comprehensive toolkit for creating, analyzing, and visualizing complex networks and graphs in Python. Use when working with network/graph data structures, analyzing relationships between entities, computing graph algorithms (shortest paths, centrality, clustering), detecting communities, generating ",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "networkx",
      "networks",
      "analyzing",
      "visualizing",
      "network",
      "graph",
      "relationships",
      "complex",
      "graphs",
      "structures"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/networkx",
    "fullDescription": "\n# NetworkX\n\n## Overview\n\nNetworkX is a Python package for creating, manipulating, and analyzing complex networks and graphs. Use this skill when working with network or graph data structures, including social networks, biological networks, transportation systems, citation networks, knowledge graphs, or any system involving relationships between entities.\n\n## When to Use This Skill\n\nInvoke this skill when tasks involve:\n\n- **Creating graphs**: Building network structures from data, adding nodes and edges with attributes\n- **Graph analysis**: Computing centrality measures, finding shortest paths, detecting communities, measuring clustering\n- **Graph algorithms**: Running standard algorithms like Dijkstra's, PageRank, minimum spanning trees, maximum flow\n- **Network generation**: Creating synthetic networks (random, scale-free, small-world models) for testing or simulation\n- **Graph I/O**: Reading from or writing to various formats (edge lists, GraphML, JSON, CSV, adjacency matrices)\n- **Visualization**: Drawing and customizing network visualizations with matplotlib or interactive libraries\n- **Network comparison**: Checking isomorphism, computing graph metrics, analyzing structural properties\n\n## Core Capabilities\n\n### 1. Graph Creation and Manipulation\n\nNetworkX supports four main graph types:\n- **Graph**: Undirected graphs with single edges\n- **DiGraph**: Directed graphs with one-way connections\n- **MultiGraph**: Undirected graphs allowing multiple edges between nodes\n- **MultiDiGraph**: Directed graphs with multiple edges\n\nCreate graphs by:\n```python\nimport networkx as nx\n\n# Create empty graph\nG = nx.Graph()\n\n# Add nodes (can be any hashable type)\nG.add_node(1)\nG.add_nodes_from([2, 3, 4])\nG.add_node(\"protein_A\", type='enzyme', weight=1.5)\n\n# Add edges\nG.add_edge(1, 2)\nG.add_edges_from([(1, 3), (2, 4)])\nG.add_edge(1, 4, weight=0.8, relation='interacts')\n```\n\n**Reference**: See `references/graph-basics.md` for comprehensive guidance on creating, modifying, examining"
  },
  {
    "id": "molfeat",
    "name": "molfeat",
    "description": "Molecular featurization for ML (100+ featurizers). ECFP, MACCS, descriptors, pretrained models (ChemBERTa), convert SMILES to features, for QSAR and molecular ML.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "molfeat",
      "molecular",
      "featurization",
      "100",
      "featurizers",
      "ecfp",
      "maccs",
      "descriptors",
      "pretrained",
      "chemberta"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/molfeat",
    "fullDescription": "\n# Molfeat - Molecular Featurization Hub\n\n## Overview\n\nMolfeat is a comprehensive Python library for molecular featurization that unifies 100+ pre-trained embeddings and hand-crafted featurizers. Convert chemical structures (SMILES strings or RDKit molecules) into numerical representations for machine learning tasks including QSAR modeling, virtual screening, similarity searching, and deep learning applications. Features fast parallel processing, scikit-learn compatible transformers, and built-in caching.\n\n## When to Use This Skill\n\nThis skill should be used when working with:\n- **Molecular machine learning**: Building QSAR/QSPR models, property prediction\n- **Virtual screening**: Ranking compound libraries for biological activity\n- **Similarity searching**: Finding structurally similar molecules\n- **Chemical space analysis**: Clustering, visualization, dimensionality reduction\n- **Deep learning**: Training neural networks on molecular data\n- **Featurization pipelines**: Converting SMILES to ML-ready representations\n- **Cheminformatics**: Any task requiring molecular feature extraction\n\n## Installation\n\n```bash\nuv pip install molfeat\n\n# With all optional dependencies\nuv pip install \"molfeat[all]\"\n```\n\n**Optional dependencies for specific featurizers:**\n- `molfeat[dgl]` - GNN models (GIN variants)\n- `molfeat[graphormer]` - Graphormer models\n- `molfeat[transformer]` - ChemBERTa, ChemGPT, MolT5\n- `molfeat[fcd]` - FCD descriptors\n- `molfeat[map4]` - MAP4 fingerprints\n\n## Core Concepts\n\nMolfeat organizes featurization into three hierarchical classes:\n\n### 1. Calculators (`molfeat.calc`)\n\nCallable objects that convert individual molecules into feature vectors. Accept RDKit `Chem.Mol` objects or SMILES strings.\n\n**Use calculators for:**\n- Single molecule featurization\n- Custom processing loops\n- Direct feature computation\n\n**Example:**\n```python\nfrom molfeat.calc import FPCalculator\n\ncalc = FPCalculator(\"ecfp\", radius=3, fpSize=2048)\nfeatures = calc(\"CCO\")  # Returns numpy"
  },
  {
    "id": "modal",
    "name": "modal",
    "description": "Run Python code in the cloud with serverless containers, GPUs, and autoscaling. Use when deploying ML models, running batch processing jobs, scheduling compute-intensive tasks, or serving APIs that require GPU acceleration or dynamic scaling.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "modal",
      "run",
      "code",
      "cloud",
      "serverless",
      "containers",
      "gpus",
      "autoscaling",
      "deploying",
      "running"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/modal",
    "fullDescription": "\n# Modal\n\n## Overview\n\nModal is a serverless platform for running Python code in the cloud with minimal configuration. Execute functions on powerful GPUs, scale automatically to thousands of containers, and pay only for compute used.\n\nModal is particularly suited for AI/ML workloads, high-performance batch processing, scheduled jobs, GPU inference, and serverless APIs. Sign up for free at https://modal.com and receive $30/month in credits.\n\n## When to Use This Skill\n\nUse Modal for:\n- Deploying and serving ML models (LLMs, image generation, embedding models)\n- Running GPU-accelerated computation (training, inference, rendering)\n- Batch processing large datasets in parallel\n- Scheduling compute-intensive jobs (daily data processing, model training)\n- Building serverless APIs that need automatic scaling\n- Scientific computing requiring distributed compute or specialized hardware\n\n## Authentication and Setup\n\nModal requires authentication via API token.\n\n### Initial Setup\n\n```bash\n# Install Modal\nuv uv pip install modal\n\n# Authenticate (opens browser for login)\nmodal token new\n```\n\nThis creates a token stored in `~/.modal.toml`. The token authenticates all Modal operations.\n\n### Verify Setup\n\n```python\nimport modal\n\napp = modal.App(\"test-app\")\n\n@app.function()\ndef hello():\n    print(\"Modal is working!\")\n```\n\nRun with: `modal run script.py`\n\n## Core Capabilities\n\nModal provides serverless Python execution through Functions that run in containers. Define compute requirements, dependencies, and scaling behavior declaratively.\n\n### 1. Define Container Images\n\nSpecify dependencies and environment for functions using Modal Images.\n\n```python\nimport modal\n\n# Basic image with Python packages\nimage = (\n    modal.Image.debian_slim(python_version=\"3.12\")\n    .uv_pip_install(\"torch\", \"transformers\", \"numpy\")\n)\n\napp = modal.App(\"ml-app\", image=image)\n```\n\n**Common patterns:**\n- Install Python packages: `.uv_pip_install(\"pandas\", \"scikit-learn\")`\n- Install system packages: `.apt_inst"
  },
  {
    "id": "metabolomics-workbench-database",
    "name": "metabolomics-workbench-database",
    "description": "Access NIH Metabolomics Workbench via REST API (4,200+ studies). Query metabolites, RefMet nomenclature, MS/NMR data, m/z searches, study metadata, for metabolomics and biomarker discovery.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "metabolomics",
      "workbench",
      "nih",
      "via",
      "rest",
      "200",
      "studies",
      "metabolites",
      "refmet",
      "nomenclature"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/metabolomics-workbench-database",
    "fullDescription": "\n# Metabolomics Workbench Database\n\n## Overview\n\nThe Metabolomics Workbench is a comprehensive NIH Common Fund-sponsored platform hosted at UCSD that serves as the primary repository for metabolomics research data. It provides programmatic access to over 4,200 processed studies (3,790+ publicly available), standardized metabolite nomenclature through RefMet, and powerful search capabilities across multiple analytical platforms (GC-MS, LC-MS, NMR).\n\n## When to Use This Skill\n\nThis skill should be used when querying metabolite structures, accessing study data, standardizing nomenclature, performing mass spectrometry searches, or retrieving gene/protein-metabolite associations through the Metabolomics Workbench REST API.\n\n## Core Capabilities\n\n### 1. Querying Metabolite Structures and Data\n\nAccess comprehensive metabolite information including structures, identifiers, and cross-references to external databases.\n\n**Key operations:**\n- Retrieve compound data by various identifiers (PubChem CID, InChI Key, KEGG ID, HMDB ID, etc.)\n- Download molecular structures as MOL files or PNG images\n- Access standardized compound classifications\n- Cross-reference between different metabolite databases\n\n**Example queries:**\n```python\nimport requests\n\n# Get compound information by PubChem CID\nresponse = requests.get('https://www.metabolomicsworkbench.org/rest/compound/pubchem_cid/5281365/all/json')\n\n# Download molecular structure as PNG\nresponse = requests.get('https://www.metabolomicsworkbench.org/rest/compound/regno/11/png')\n\n# Get compound name by registry number\nresponse = requests.get('https://www.metabolomicsworkbench.org/rest/compound/regno/11/name/json')\n```\n\n### 2. Accessing Study Metadata and Experimental Results\n\nQuery metabolomics studies by various criteria and retrieve complete experimental datasets.\n\n**Key operations:**\n- Search studies by metabolite, institute, investigator, or title\n- Access study summaries, experimental factors, and analysis details\n- Retrieve complet"
  },
  {
    "id": "medchem",
    "name": "medchem",
    "description": "Medicinal chemistry filters. Apply drug-likeness rules (Lipinski, Veber), PAINS filters, structural alerts, complexity metrics, for compound prioritization and library filtering.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "medchem",
      "filters",
      "medicinal",
      "chemistry",
      "apply",
      "drug-likeness",
      "rules",
      "lipinski",
      "veber",
      "pains"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/medchem",
    "fullDescription": "\n# Medchem\n\n## Overview\n\nMedchem is a Python library for molecular filtering and prioritization in drug discovery workflows. Apply hundreds of well-established and novel molecular filters, structural alerts, and medicinal chemistry rules to efficiently triage and prioritize compound libraries at scale. Rules and filters are context-specificâ€”use as guidelines combined with domain expertise.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Applying drug-likeness rules (Lipinski, Veber, etc.) to compound libraries\n- Filtering molecules by structural alerts or PAINS patterns\n- Prioritizing compounds for lead optimization\n- Assessing compound quality and medicinal chemistry properties\n- Detecting reactive or problematic functional groups\n- Calculating molecular complexity metrics\n\n## Installation\n\n```bash\nuv pip install medchem\n```\n\n## Core Capabilities\n\n### 1. Medicinal Chemistry Rules\n\nApply established drug-likeness rules to molecules using the `medchem.rules` module.\n\n**Available Rules:**\n- Rule of Five (Lipinski)\n- Rule of Oprea\n- Rule of CNS\n- Rule of leadlike (soft and strict)\n- Rule of three\n- Rule of Reos\n- Rule of drug\n- Rule of Veber\n- Golden triangle\n- PAINS filters\n\n**Single Rule Application:**\n\n```python\nimport medchem as mc\n\n# Apply Rule of Five to a SMILES string\nsmiles = \"CC(=O)OC1=CC=CC=C1C(=O)O\"  # Aspirin\npasses = mc.rules.basic_rules.rule_of_five(smiles)\n# Returns: True\n\n# Check specific rules\npasses_oprea = mc.rules.basic_rules.rule_of_oprea(smiles)\npasses_cns = mc.rules.basic_rules.rule_of_cns(smiles)\n```\n\n**Multiple Rules with RuleFilters:**\n\n```python\nimport datamol as dm\nimport medchem as mc\n\n# Load molecules\nmols = [dm.to_mol(smiles) for smiles in smiles_list]\n\n# Create filter with multiple rules\nrfilter = mc.rules.RuleFilters(\n    rule_list=[\n        \"rule_of_five\",\n        \"rule_of_oprea\",\n        \"rule_of_cns\",\n        \"rule_of_leadlike_soft\"\n    ]\n)\n\n# Apply filters with parallelization\nresults = rfilter(\n    mols=mols,\n    n_j"
  },
  {
    "id": "matplotlib",
    "name": "matplotlib",
    "description": "Foundational plotting library. Create line plots, scatter, bar, histograms, heatmaps, 3D, subplots, export PNG/PDF/SVG, for scientific visualization and publication figures.",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "matplotlib",
      "foundational",
      "plotting",
      "library",
      "line",
      "plots",
      "scatter",
      "bar",
      "histograms",
      "heatmaps"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/matplotlib",
    "fullDescription": "\n# Matplotlib\n\n## Overview\n\nMatplotlib is Python's foundational visualization library for creating static, animated, and interactive plots. This skill provides guidance on using matplotlib effectively, covering both the pyplot interface (MATLAB-style) and the object-oriented API (Figure/Axes), along with best practices for creating publication-quality visualizations.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating any type of plot or chart (line, scatter, bar, histogram, heatmap, contour, etc.)\n- Generating scientific or statistical visualizations\n- Customizing plot appearance (colors, styles, labels, legends)\n- Creating multi-panel figures with subplots\n- Exporting visualizations to various formats (PNG, PDF, SVG, etc.)\n- Building interactive plots or animations\n- Working with 3D visualizations\n- Integrating plots into Jupyter notebooks or GUI applications\n\n## Core Concepts\n\n### The Matplotlib Hierarchy\n\nMatplotlib uses a hierarchical structure of objects:\n\n1. **Figure** - The top-level container for all plot elements\n2. **Axes** - The actual plotting area where data is displayed (one Figure can contain multiple Axes)\n3. **Artist** - Everything visible on the figure (lines, text, ticks, etc.)\n4. **Axis** - The number line objects (x-axis, y-axis) that handle ticks and labels\n\n### Two Interfaces\n\n**1. pyplot Interface (Implicit, MATLAB-style)**\n```python\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.show()\n```\n- Convenient for quick, simple plots\n- Maintains state automatically\n- Good for interactive work and simple scripts\n\n**2. Object-Oriented Interface (Explicit)**\n```python\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4])\nax.set_ylabel('some numbers')\nplt.show()\n```\n- **Recommended for most use cases**\n- More explicit control over figure and axes\n- Better for complex figures with multiple subplots\n- Easier to maintain and debug\n\n## Common Workflows\n\n### 1. Basic Plot C"
  },
  {
    "id": "matchms",
    "name": "matchms",
    "description": "Mass spectrometry analysis. Process mzML/MGF/MSP, spectral similarity (cosine, modified cosine), metadata harmonization, compound ID, for metabolomics and MS data processing.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "matchms",
      "cosine",
      "mass",
      "spectrometry",
      "process",
      "mzml",
      "mgf",
      "msp",
      "spectral",
      "similarity"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/matchms",
    "fullDescription": "\n# Matchms\n\n## Overview\n\nMatchms is an open-source Python library for mass spectrometry data processing and analysis. Import spectra from various formats, standardize metadata, filter peaks, calculate spectral similarities, and build reproducible analytical workflows.\n\n## Core Capabilities\n\n### 1. Importing and Exporting Mass Spectrometry Data\n\nLoad spectra from multiple file formats and export processed data:\n\n```python\nfrom matchms.importing import load_from_mgf, load_from_mzml, load_from_msp, load_from_json\nfrom matchms.exporting import save_as_mgf, save_as_msp, save_as_json\n\n# Import spectra\nspectra = list(load_from_mgf(\"spectra.mgf\"))\nspectra = list(load_from_mzml(\"data.mzML\"))\nspectra = list(load_from_msp(\"library.msp\"))\n\n# Export processed spectra\nsave_as_mgf(spectra, \"output.mgf\")\nsave_as_json(spectra, \"output.json\")\n```\n\n**Supported formats:**\n- mzML and mzXML (raw mass spectrometry formats)\n- MGF (Mascot Generic Format)\n- MSP (spectral library format)\n- JSON (GNPS-compatible)\n- metabolomics-USI references\n- Pickle (Python serialization)\n\nFor detailed importing/exporting documentation, consult `references/importing_exporting.md`.\n\n### 2. Spectrum Filtering and Processing\n\nApply comprehensive filters to standardize metadata and refine peak data:\n\n```python\nfrom matchms.filtering import default_filters, normalize_intensities\nfrom matchms.filtering import select_by_relative_intensity, require_minimum_number_of_peaks\n\n# Apply default metadata harmonization filters\nspectrum = default_filters(spectrum)\n\n# Normalize peak intensities\nspectrum = normalize_intensities(spectrum)\n\n# Filter peaks by relative intensity\nspectrum = select_by_relative_intensity(spectrum, intensity_from=0.01, intensity_to=1.0)\n\n# Require minimum peaks\nspectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n```\n\n**Filter categories:**\n- **Metadata processing**: Harmonize compound names, derive chemical structures, standardize adducts, correct charges\n- **Peak filtering**: Normalize"
  },
  {
    "id": "markitdown",
    "name": "markitdown",
    "description": "Convert files and office documents to Markdown. Supports PDF, DOCX, PPTX, XLSX, images (with OCR), audio (with transcription), HTML, CSV, JSON, XML, ZIP, YouTube URLs, EPubs and more.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "markitdown",
      "convert",
      "office",
      "documents",
      "markdown",
      "pdf",
      "docx",
      "pptx",
      "xlsx",
      "images"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/markitdown",
    "fullDescription": "\n# MarkItDown - File to Markdown Conversion\n\n## Overview\n\nMarkItDown is a Python tool developed by Microsoft for converting various file formats to Markdown. It's particularly useful for converting documents into LLM-friendly text format, as Markdown is token-efficient and well-understood by modern language models.\n\n**Key Benefits**:\n- Convert documents to clean, structured Markdown\n- Token-efficient format for LLM processing\n- Supports 15+ file formats\n- Optional AI-enhanced image descriptions\n- OCR for images and scanned documents\n- Speech transcription for audio files\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper formatting\n- Review and refine through multiple iterations\n- Ensure accessibility (colorblind-friendly, high contrast)\n- Save outputs in the figures/ directory\n\n**When to add schematics:**\n- Document conversion workflow diagrams\n- File format architecture illustrations\n- OCR processing pipeline diagrams\n- Integration workflow visualizations\n- System architecture diagrams\n- Data flow diagrams\n- Any complex concept that benefits from visualization\n\nFor detailed guidance on creating schematics, refer to the scientific-schematics skill documentati"
  },
  {
    "id": "market-research-reports",
    "name": "market-research-reports",
    "description": "Generate comprehensive market research reports (50+ pages) in the style of top consulting firms (McKinsey, BCG, Gartner). Features professional LaTeX formatting, extensive visual generation with scientific-schematics and generate-image, deep integration with research-lookup for data gathering, and m",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "market",
      "reports",
      "bcg",
      "generate",
      "pages",
      "style",
      "top",
      "consulting",
      "firms",
      "mckinsey"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/market-research-reports",
    "fullDescription": "\n# Market Research Reports\n\n## Overview\n\nMarket research reports are comprehensive strategic documents that analyze industries, markets, and competitive landscapes to inform business decisions, investment strategies, and strategic planning. This skill generates **professional-grade reports of 50+ pages** with extensive visual content, modeled after deliverables from top consulting firms like McKinsey, BCG, Bain, Gartner, and Forrester.\n\n**Key Features:**\n- **Comprehensive length**: Reports are designed to be 50+ pages with no token constraints\n- **Visual-rich content**: 5-6 key diagrams generated at start (more added as needed during writing)\n- **Data-driven analysis**: Deep integration with research-lookup for market data\n- **Multi-framework approach**: Porter's Five Forces, PESTLE, SWOT, BCG Matrix, TAM/SAM/SOM\n- **Professional formatting**: Consulting-firm quality typography, colors, and layout\n- **Actionable recommendations**: Strategic focus with implementation roadmaps\n\n**Output Format:** LaTeX with professional styling, compiled to PDF. Uses the `market_research.sty` style package for consistent, professional formatting.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating comprehensive market analysis for investment decisions\n- Developing industry reports for strategic planning\n- Analyzing competitive landscapes and market dynamics\n- Conducting market sizing exercises (TAM/SAM/SOM)\n- Evaluating market entry opportunities\n- Preparing due diligence materials for M&A activities\n- Creating thought leadership content for industry positioning\n- Developing go-to-market strategy documentation\n- Analyzing regulatory and policy impacts on markets\n- Building business cases for new product launches\n\n## Visual Enhancement Requirements\n\n**CRITICAL: Market research reports should include key visual content.**\n\nEvery report should generate **6 essential visuals** at the start, with additional visuals added as needed during writing. Start with the most crit"
  },
  {
    "id": "literature-review",
    "name": "literature-review",
    "description": "Conduct comprehensive, systematic literature reviews using multiple academic databases (PubMed, arXiv, bioRxiv, Semantic Scholar, etc.). This skill should be used when conducting systematic literature reviews, meta-analyses, research synthesis, or comprehensive literature searches across biomedical,",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "literature",
      "review",
      "systematic",
      "reviews",
      "etc",
      "conduct",
      "academic",
      "databases",
      "pubmed",
      "arxiv"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/literature-review",
    "fullDescription": "\n# Literature Review\n\n## Overview\n\nConduct systematic, comprehensive literature reviews following rigorous academic methodology. Search multiple literature databases, synthesize findings thematically, verify all citations for accuracy, and generate professional output documents in markdown and PDF formats.\n\nThis skill integrates with multiple scientific skills for database access (gget, bioservices, datacommons-client) and provides specialized tools for citation verification, result aggregation, and document generation.\n\n## When to Use This Skill\n\nUse this skill when:\n- Conducting a systematic literature review for research or publication\n- Synthesizing current knowledge on a specific topic across multiple sources\n- Performing meta-analysis or scoping reviews\n- Writing the literature review section of a research paper or thesis\n- Investigating the state of the art in a research domain\n- Identifying research gaps and future directions\n- Requiring verified citations and professional formatting\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every literature review MUST include at least 1-2 AI-generated figures using the scientific-schematics skill.**\n\nThis is not optional. Literature reviews without visual elements are incomplete. Before finalizing any document:\n1. Generate at minimum ONE schematic or diagram (e.g., PRISMA flow diagram for systematic reviews)\n2. Prefer 2-3 figures for comprehensive reviews (search strategy flowchart, thematic synthesis diagram, conceptual framework)\n\n**How to generate figures:**\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper forma"
  },
  {
    "id": "latchbio-integration",
    "name": "latchbio-integration",
    "description": "Latch platform for bioinformatics workflows. Build pipelines with Latch SDK, @workflow/@task decorators, deploy serverless workflows, LatchFile/LatchDir, Nextflow/Snakemake integration.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "latchbio",
      "integration",
      "latch",
      "workflows",
      "bioinformatics",
      "pipelines",
      "sdk",
      "workflow",
      "task",
      "decorators"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/latchbio-integration",
    "fullDescription": "\n# LatchBio Integration\n\n## Overview\n\nLatch is a Python framework for building and deploying bioinformatics workflows as serverless pipelines. Built on Flyte, create workflows with @workflow/@task decorators, manage cloud data with LatchFile/LatchDir, configure resources, and integrate Nextflow/Snakemake pipelines.\n\n## Core Capabilities\n\nThe Latch platform provides four main areas of functionality:\n\n### 1. Workflow Creation and Deployment\n- Define serverless workflows using Python decorators\n- Support for native Python, Nextflow, and Snakemake pipelines\n- Automatic containerization with Docker\n- Auto-generated no-code user interfaces\n- Version control and reproducibility\n\n### 2. Data Management\n- Cloud storage abstractions (LatchFile, LatchDir)\n- Structured data organization with Registry (Projects â†’ Tables â†’ Records)\n- Type-safe data operations with links and enums\n- Automatic file transfer between local and cloud\n- Glob pattern matching for file selection\n\n### 3. Resource Configuration\n- Pre-configured task decorators (@small_task, @large_task, @small_gpu_task, @large_gpu_task)\n- Custom resource specifications (CPU, memory, GPU, storage)\n- GPU support (K80, V100, A100)\n- Timeout and storage configuration\n- Cost optimization strategies\n\n### 4. Verified Workflows\n- Production-ready pre-built pipelines\n- Bulk RNA-seq, DESeq2, pathway analysis\n- AlphaFold and ColabFold for protein structure prediction\n- Single-cell tools (ArchR, scVelo, emptyDropsR)\n- CRISPR analysis, phylogenetics, and more\n\n## Quick Start\n\n### Installation and Setup\n\n```bash\n# Install Latch SDK\npython3 -m uv pip install latch\n\n# Login to Latch\nlatch login\n\n# Initialize a new workflow\nlatch init my-workflow\n\n# Register workflow to platform\nlatch register my-workflow\n```\n\n**Prerequisites:**\n- Docker installed and running\n- Latch account credentials\n- Python 3.8+\n\n### Basic Workflow Example\n\n```python\nfrom latch import workflow, small_task\nfrom latch.types import LatchFile\n\n@small_task\ndef process_file"
  },
  {
    "id": "labarchive-integration",
    "name": "labarchive-integration",
    "description": "Electronic lab notebook API integration. Access notebooks, manage entries/attachments, backup notebooks, integrate with Protocols.io/Jupyter/REDCap, for programmatic ELN workflows.",
    "category": "lab-automation",
    "source": "scientific",
    "triggers": [
      "labarchive",
      "integration",
      "notebooks",
      "electronic",
      "lab",
      "notebook",
      "manage",
      "entries",
      "attachments",
      "backup"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/labarchive-integration",
    "fullDescription": "\n# LabArchives Integration\n\n## Overview\n\nLabArchives is an electronic lab notebook platform for research documentation and data management. Access notebooks, manage entries and attachments, generate reports, and integrate with third-party tools programmatically via REST API.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with LabArchives REST API for notebook automation\n- Backing up notebooks programmatically\n- Creating or managing notebook entries and attachments\n- Generating site reports and analytics\n- Integrating LabArchives with third-party tools (Protocols.io, Jupyter, REDCap)\n- Automating data upload to electronic lab notebooks\n- Managing user access and permissions programmatically\n\n## Core Capabilities\n\n### 1. Authentication and Configuration\n\nSet up API access credentials and regional endpoints for LabArchives API integration.\n\n**Prerequisites:**\n- Enterprise LabArchives license with API access enabled\n- API access key ID and password from LabArchives administrator\n- User authentication credentials (email and external applications password)\n\n**Configuration setup:**\n\nUse the `scripts/setup_config.py` script to create a configuration file:\n\n```bash\npython3 scripts/setup_config.py\n```\n\nThis creates a `config.yaml` file with the following structure:\n\n```yaml\napi_url: https://api.labarchives.com/api  # or regional endpoint\naccess_key_id: YOUR_ACCESS_KEY_ID\naccess_password: YOUR_ACCESS_PASSWORD\n```\n\n**Regional API endpoints:**\n- US/International: `https://api.labarchives.com/api`\n- Australia: `https://auapi.labarchives.com/api`\n- UK: `https://ukapi.labarchives.com/api`\n\nFor detailed authentication instructions and troubleshooting, refer to `references/authentication_guide.md`.\n\n### 2. User Information Retrieval\n\nObtain user ID (UID) and access information required for subsequent API operations.\n\n**Workflow:**\n\n1. Call the `users/user_access_info` API method with login credentials\n2. Parse the XML/JSON response to extract the user ID (UID)"
  },
  {
    "id": "kegg-database",
    "name": "kegg-database",
    "description": "Direct REST API access to KEGG (academic use only). Pathway analysis, gene-pathway mapping, metabolic pathways, drug interactions, ID conversion. For Python workflows with multiple databases, prefer bioservices. Use this for direct HTTP/REST work or KEGG-specific control.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "kegg",
      "direct",
      "rest",
      "academic",
      "pathway",
      "gene-pathway",
      "mapping",
      "metabolic",
      "pathways",
      "drug"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/kegg-database",
    "fullDescription": "\n# KEGG Database\n\n## Overview\n\nKEGG (Kyoto Encyclopedia of Genes and Genomes) is a comprehensive bioinformatics resource for biological pathway analysis and molecular interaction networks.\n\n**Important**: KEGG API is made available only for academic use by academic users.\n\n## When to Use This Skill\n\nThis skill should be used when querying pathways, genes, compounds, enzymes, diseases, and drugs across multiple organisms using KEGG's REST API.\n\n## Quick Start\n\nThe skill provides:\n1. Python helper functions (`scripts/kegg_api.py`) for all KEGG REST API operations\n2. Comprehensive reference documentation (`references/kegg_reference.md`) with detailed API specifications\n\nWhen users request KEGG data, determine which operation is needed and use the appropriate function from `scripts/kegg_api.py`.\n\n## Core Operations\n\n### 1. Database Information (`kegg_info`)\n\nRetrieve metadata and statistics about KEGG databases.\n\n**When to use**: Understanding database structure, checking available data, getting release information.\n\n**Usage**:\n```python\nfrom scripts.kegg_api import kegg_info\n\n# Get pathway database info\ninfo = kegg_info('pathway')\n\n# Get organism-specific info\nhsa_info = kegg_info('hsa')  # Human genome\n```\n\n**Common databases**: `kegg`, `pathway`, `module`, `brite`, `genes`, `genome`, `compound`, `glycan`, `reaction`, `enzyme`, `disease`, `drug`\n\n### 2. Listing Entries (`kegg_list`)\n\nList entry identifiers and names from KEGG databases.\n\n**When to use**: Getting all pathways for an organism, listing genes, retrieving compound catalogs.\n\n**Usage**:\n```python\nfrom scripts.kegg_api import kegg_list\n\n# List all reference pathways\npathways = kegg_list('pathway')\n\n# List human-specific pathways\nhsa_pathways = kegg_list('pathway', 'hsa')\n\n# List specific genes (max 10)\ngenes = kegg_list('hsa:10458+hsa:10459')\n```\n\n**Common organism codes**: `hsa` (human), `mmu` (mouse), `dme` (fruit fly), `sce` (yeast), `eco` (E. coli)\n\n### 3. Searching (`kegg_find`)\n\nSearch KEGG databases b"
  },
  {
    "id": "iso-13485-certification",
    "name": "iso-13485-certification",
    "description": "Comprehensive toolkit for preparing ISO 13485 certification documentation for medical device Quality Management Systems. Use when users need help with ISO 13485 QMS documentation, including (1) conducting gap analysis of existing documentation, (2) creating Quality Manuals, (3) developing required p",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "iso",
      "13485",
      "certification",
      "documentation",
      "medical",
      "device",
      "quality",
      "preparing",
      "users",
      "qms"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/iso-13485-certification",
    "fullDescription": "\n# ISO 13485 Certification Documentation Assistant\n\n## Overview\n\nThis skill helps medical device manufacturers prepare comprehensive documentation for ISO 13485:2016 certification. It provides tools, templates, references, and guidance to create, review, and gap-analyze all required Quality Management System (QMS) documentation.\n\n**What this skill provides:**\n- Gap analysis of existing documentation\n- Templates for all mandatory documents\n- Comprehensive requirements guidance\n- Step-by-step documentation creation\n- Identification of missing documentation\n- Compliance checklists\n\n**When to use this skill:**\n- Starting ISO 13485 certification process\n- Conducting gap analysis against ISO 13485\n- Creating or updating QMS documentation\n- Preparing for certification audit\n- Transitioning from FDA QSR to QMSR\n- Harmonizing with EU MDR requirements\n\n## Core Workflow\n\n### 1. Assess Current State (Gap Analysis)\n\n**When to start here:** User has existing documentation and needs to identify gaps\n\n**Process:**\n\n1. **Collect existing documentation:**\n   - Ask user to provide directory of current QMS documents\n   - Documents can be in any format (.txt, .md, .doc, .docx, .pdf)\n   - Include any procedures, manuals, work instructions, forms\n\n2. **Run gap analysis script:**\n   ```bash\n   python scripts/gap_analyzer.py --docs-dir <path_to_docs> --output gap-report.json\n   ```\n\n3. **Review results:**\n   - Identify which of the 31 required procedures are present\n   - Identify missing key documents (Quality Manual, MDF, etc.)\n   - Calculate compliance percentage\n   - Prioritize missing documentation\n\n4. **Present findings to user:**\n   - Summarize what exists\n   - Clearly list what's missing\n   - Provide prioritized action plan\n   - Estimate effort required\n\n**Output:** Comprehensive gap analysis report with prioritized action items\n\n### 2. Understand Requirements (Reference Consultation)\n\n**When to use:** User needs to understand specific ISO 13485 requirements\n\n**Available references:*"
  },
  {
    "id": "hypothesis-generation",
    "name": "hypothesis-generation",
    "description": "Generate testable hypotheses. Formulate from observations, design experiments, explore competing explanations, develop predictions, propose mechanisms, for scientific inquiry across domains.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "hypothesis",
      "generation",
      "generate",
      "testable",
      "hypotheses",
      "formulate",
      "observations",
      "design",
      "experiments",
      "explore"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/hypothesis-generation",
    "fullDescription": "\n# Scientific Hypothesis Generation\n\n## Overview\n\nHypothesis generation is a systematic process for developing testable explanations. Formulate evidence-based hypotheses from observations, design experiments, explore competing explanations, and develop predictions. Apply this skill for scientific inquiry across domains.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Developing hypotheses from observations or preliminary data\n- Designing experiments to test scientific questions\n- Exploring competing explanations for phenomena\n- Formulating testable predictions for research\n- Conducting literature-based hypothesis generation\n- Planning mechanistic studies across scientific domains\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every hypothesis generation report MUST include at least 1-2 AI-generated figures using the scientific-schematics skill.**\n\nThis is not optional. Hypothesis reports without visual elements are incomplete. Before finalizing any document:\n1. Generate at minimum ONE schematic or diagram (e.g., hypothesis framework showing competing explanations)\n2. Prefer 2-3 figures for comprehensive reports (mechanistic pathway, experimental design flowchart, prediction decision tree)\n\n**How to generate figures:**\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Create publication-quality images with proper formatting\n- Review and refine through multiple iterations\n- Ensure accessibility (colorblind-friendly, high contrast)\n- Save outputs in the figures/ directory\n\n**When to add schematics:**\n- Hypothesis framework diagrams showing competing explanations\n- Experimental design flowcharts\n- M"
  },
  {
    "id": "hypogenic",
    "name": "hypogenic",
    "description": "Automated hypothesis generation and testing using large language models. Use this skill when generating scientific hypotheses from datasets, combining literature insights with empirical data, testing hypotheses against observational data, or conducting systematic hypothesis exploration for research ",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "hypogenic",
      "hypothesis",
      "testing",
      "hypotheses",
      "empirical",
      "detection",
      "automated",
      "generation",
      "large",
      "language"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/hypogenic",
    "fullDescription": "\n# Hypogenic\n\n## Overview\n\nHypogenic provides automated hypothesis generation and testing using large language models to accelerate scientific discovery. The framework supports three approaches: HypoGeniC (data-driven hypothesis generation), HypoRefine (synergistic literature and data integration), and Union methods (mechanistic combination of literature and data-driven hypotheses).\n\n## Quick Start\n\nGet started with Hypogenic in minutes:\n\n```bash\n# Install the package\nuv pip install hypogenic\n\n# Clone example datasets\ngit clone https://github.com/ChicagoHAI/HypoGeniC-datasets.git ./data\n\n# Run basic hypothesis generation\nhypogenic_generation --config ./data/your_task/config.yaml --method hypogenic --num_hypotheses 20\n\n# Run inference on generated hypotheses\nhypogenic_inference --config ./data/your_task/config.yaml --hypotheses output/hypotheses.json\n```\n\n**Or use Python API:**\n\n```python\nfrom hypogenic import BaseTask\n\n# Create task with your configuration\ntask = BaseTask(config_path=\"./data/your_task/config.yaml\")\n\n# Generate hypotheses\ntask.generate_hypotheses(method=\"hypogenic\", num_hypotheses=20)\n\n# Run inference\nresults = task.inference(hypothesis_bank=\"./output/hypotheses.json\")\n```\n\n## When to Use This Skill\n\nUse this skill when working on:\n- Generating scientific hypotheses from observational datasets\n- Testing multiple competing hypotheses systematically\n- Combining literature insights with empirical patterns\n- Accelerating research discovery through automated hypothesis ideation\n- Domains requiring hypothesis-driven analysis: deception detection, AI-generated content identification, mental health indicators, predictive modeling, or other empirical research\n\n## Key Features\n\n**Automated Hypothesis Generation**\n- Generate 10-20+ testable hypotheses from data in minutes\n- Iterative refinement based on validation performance\n- Support for both API-based (OpenAI, Anthropic) and local LLMs\n\n**Literature Integration**\n- Extract insights from research papers via P"
  },
  {
    "id": "hmdb-database",
    "name": "hmdb-database",
    "description": "Access Human Metabolome Database (220K+ metabolites). Search by name/ID/structure, retrieve chemical properties, biomarker data, NMR/MS spectra, pathways, for metabolomics and identification.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "hmdb",
      "human",
      "metabolome",
      "220k",
      "metabolites",
      "name",
      "structure",
      "retrieve",
      "chemical",
      "properties"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/hmdb-database",
    "fullDescription": "\n# HMDB Database\n\n## Overview\n\nThe Human Metabolome Database (HMDB) is a comprehensive, freely available resource containing detailed information about small molecule metabolites found in the human body.\n\n## When to Use This Skill\n\nThis skill should be used when performing metabolomics research, clinical chemistry, biomarker discovery, or metabolite identification tasks.\n\n## Database Contents\n\nHMDB version 5.0 (current as of 2025) contains:\n\n- **220,945 metabolite entries** covering both water-soluble and lipid-soluble compounds\n- **8,610 protein sequences** for enzymes and transporters involved in metabolism\n- **130+ data fields per metabolite** including:\n  - Chemical properties (structure, formula, molecular weight, InChI, SMILES)\n  - Clinical data (biomarker associations, diseases, normal/abnormal concentrations)\n  - Biological information (pathways, reactions, locations)\n  - Spectroscopic data (NMR, MS, MS-MS spectra)\n  - External database links (KEGG, PubChem, MetaCyc, ChEBI, PDB, UniProt, GenBank)\n\n## Core Capabilities\n\n### 1. Web-Based Metabolite Searches\n\nAccess HMDB through the web interface at https://www.hmdb.ca/ for:\n\n**Text Searches:**\n- Search by metabolite name, synonym, or identifier (HMDB ID)\n- Example HMDB IDs: HMDB0000001, HMDB0001234\n- Search by disease associations or pathway involvement\n- Query by biological specimen type (urine, serum, CSF, saliva, feces, sweat)\n\n**Structure-Based Searches:**\n- Use ChemQuery for structure and substructure searches\n- Search by molecular weight or molecular weight range\n- Use SMILES or InChI strings to find compounds\n\n**Spectral Searches:**\n- LC-MS spectral matching\n- GC-MS spectral matching\n- NMR spectral searches for metabolite identification\n\n**Advanced Searches:**\n- Combine multiple criteria (name, properties, concentration ranges)\n- Filter by biological locations or specimen types\n- Search by protein/enzyme associations\n\n### 2. Accessing Metabolite Information\n\nWhen retrieving metabolite data, HMDB provide"
  },
  {
    "id": "histolab",
    "name": "histolab",
    "description": "Digital pathology image processing toolkit for whole slide images (WSI). Use this skill when working with histopathology slides, processing H&E or IHC stained tissue images, extracting tiles from gigapixel pathology images, detecting tissue regions, segmenting tissue masks, or preparing datasets for",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "histolab",
      "pathology",
      "images",
      "tissue",
      "image",
      "processing",
      "wsi",
      "digital",
      "whole",
      "slide"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/histolab",
    "fullDescription": "\n# Histolab\n\n## Overview\n\nHistolab is a Python library for processing whole slide images (WSI) in digital pathology. It automates tissue detection, extracts informative tiles from gigapixel images, and prepares datasets for deep learning pipelines. The library handles multiple WSI formats, implements sophisticated tissue segmentation, and provides flexible tile extraction strategies.\n\n## Installation\n\n```bash\nuv pip install histolab\n```\n\n## Quick Start\n\nBasic workflow for extracting tiles from a whole slide image:\n\n```python\nfrom histolab.slide import Slide\nfrom histolab.tiler import RandomTiler\n\n# Load slide\nslide = Slide(\"slide.svs\", processed_path=\"output/\")\n\n# Configure tiler\ntiler = RandomTiler(\n    tile_size=(512, 512),\n    n_tiles=100,\n    level=0,\n    seed=42\n)\n\n# Preview tile locations\ntiler.locate_tiles(slide, n_tiles=20)\n\n# Extract tiles\ntiler.extract(slide)\n```\n\n## Core Capabilities\n\n### 1. Slide Management\n\nLoad, inspect, and work with whole slide images in various formats.\n\n**Common operations:**\n- Loading WSI files (SVS, TIFF, NDPI, etc.)\n- Accessing slide metadata (dimensions, magnification, properties)\n- Generating thumbnails for visualization\n- Working with pyramidal image structures\n- Extracting regions at specific coordinates\n\n**Key classes:** `Slide`\n\n**Reference:** `references/slide_management.md` contains comprehensive documentation on:\n- Slide initialization and configuration\n- Built-in sample datasets (prostate, ovarian, breast, heart, kidney tissues)\n- Accessing slide properties and metadata\n- Thumbnail generation and visualization\n- Working with pyramid levels\n- Multi-slide processing workflows\n\n**Example workflow:**\n```python\nfrom histolab.slide import Slide\nfrom histolab.data import prostate_tissue\n\n# Load sample data\nprostate_svs, prostate_path = prostate_tissue()\n\n# Initialize slide\nslide = Slide(prostate_path, processed_path=\"output/\")\n\n# Inspect properties\nprint(f\"Dimensions: {slide.dimensions}\")\nprint(f\"Levels: {slide.levels}\")\nprin"
  },
  {
    "id": "gwas-database",
    "name": "gwas-database",
    "description": "Query NHGRI-EBI GWAS Catalog for SNP-trait associations. Search variants by rs ID, disease/trait, gene, retrieve p-values and summary statistics, for genetic epidemiology and polygenic risk scores.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "gwas",
      "nhgri-ebi",
      "catalog",
      "snp-trait",
      "associations",
      "variants",
      "disease",
      "trait",
      "gene",
      "retrieve"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/gwas-database",
    "fullDescription": "\n# GWAS Catalog Database\n\n## Overview\n\nThe GWAS Catalog is a comprehensive repository of published genome-wide association studies maintained by the National Human Genome Research Institute (NHGRI) and the European Bioinformatics Institute (EBI). The catalog contains curated SNP-trait associations from thousands of GWAS publications, including genetic variants, associated traits and diseases, p-values, effect sizes, and full summary statistics for many studies.\n\n## When to Use This Skill\n\nThis skill should be used when queries involve:\n\n- **Genetic variant associations**: Finding SNPs associated with diseases or traits\n- **SNP lookups**: Retrieving information about specific genetic variants (rs IDs)\n- **Trait/disease searches**: Discovering genetic associations for phenotypes\n- **Gene associations**: Finding variants in or near specific genes\n- **GWAS summary statistics**: Accessing complete genome-wide association data\n- **Study metadata**: Retrieving publication and cohort information\n- **Population genetics**: Exploring ancestry-specific associations\n- **Polygenic risk scores**: Identifying variants for risk prediction models\n- **Functional genomics**: Understanding variant effects and genomic context\n- **Systematic reviews**: Comprehensive literature synthesis of genetic associations\n\n## Core Capabilities\n\n### 1. Understanding GWAS Catalog Data Structure\n\nThe GWAS Catalog is organized around four core entities:\n\n- **Studies**: GWAS publications with metadata (PMID, author, cohort details)\n- **Associations**: SNP-trait associations with statistical evidence (p â‰¤ 5Ã—10â»â¸)\n- **Variants**: Genetic markers (SNPs) with genomic coordinates and alleles\n- **Traits**: Phenotypes and diseases (mapped to EFO ontology terms)\n\n**Key Identifiers:**\n- Study accessions: `GCST` IDs (e.g., GCST001234)\n- Variant IDs: `rs` numbers (e.g., rs7903146) or `variant_id` format\n- Trait IDs: EFO terms (e.g., EFO_0001360 for type 2 diabetes)\n- Gene symbols: HGNC approved names (e.g., TCF7L2)"
  },
  {
    "id": "gtars",
    "name": "gtars",
    "description": "High-performance toolkit for genomic interval analysis in Rust with Python bindings. Use when working with genomic regions, BED files, coverage tracks, overlap detection, tokenization for ML models, or fragment analysis in computational genomics and machine learning applications.",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "gtars",
      "genomic",
      "high-performance",
      "interval",
      "rust",
      "bindings",
      "regions",
      "bed",
      "coverage",
      "tracks"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/gtars",
    "fullDescription": "\n# Gtars: Genomic Tools and Algorithms in Rust\n\n## Overview\n\nGtars is a high-performance Rust toolkit for manipulating, analyzing, and processing genomic interval data. It provides specialized tools for overlap detection, coverage analysis, tokenization for machine learning, and reference sequence management.\n\nUse this skill when working with:\n- Genomic interval files (BED format)\n- Overlap detection between genomic regions\n- Coverage track generation (WIG, BigWig)\n- Genomic ML preprocessing and tokenization\n- Fragment analysis in single-cell genomics\n- Reference sequence retrieval and validation\n\n## Installation\n\n### Python Installation\n\nInstall gtars Python bindings:\n\n```bash\nuv uv pip install gtars\n```\n\n### CLI Installation\n\nInstall command-line tools (requires Rust/Cargo):\n\n```bash\n# Install with all features\ncargo install gtars-cli --features \"uniwig overlaprs igd bbcache scoring fragsplit\"\n\n# Or install specific features only\ncargo install gtars-cli --features \"uniwig overlaprs\"\n```\n\n### Rust Library\n\nAdd to Cargo.toml for Rust projects:\n\n```toml\n[dependencies]\ngtars = { version = \"0.1\", features = [\"tokenizers\", \"overlaprs\"] }\n```\n\n## Core Capabilities\n\nGtars is organized into specialized modules, each focused on specific genomic analysis tasks:\n\n### 1. Overlap Detection and IGD Indexing\n\nEfficiently detect overlaps between genomic intervals using the Integrated Genome Database (IGD) data structure.\n\n**When to use:**\n- Finding overlapping regulatory elements\n- Variant annotation\n- Comparing ChIP-seq peaks\n- Identifying shared genomic features\n\n**Quick example:**\n```python\nimport gtars\n\n# Build IGD index and query overlaps\nigd = gtars.igd.build_index(\"regions.bed\")\noverlaps = igd.query(\"chr1\", 1000, 2000)\n```\n\nSee `references/overlap.md` for comprehensive overlap detection documentation.\n\n### 2. Coverage Track Generation\n\nGenerate coverage tracks from sequencing data with the uniwig module.\n\n**When to use:**\n- ATAC-seq accessibility profiles\n- ChIP-seq coverag"
  },
  {
    "id": "gget",
    "name": "gget",
    "description": "CLI/Python toolkit for rapid bioinformatics queries. Preferred for quick BLAST searches. Access to 20+ databases: gene info (Ensembl/UniProt), AlphaFold, ARCHS4, Enrichr, OpenTargets, COSMIC, genome downloads. For advanced BLAST/batch processing, use biopython. For multi-database integration, use bi",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "gget",
      "blast",
      "cli",
      "rapid",
      "bioinformatics",
      "queries",
      "preferred",
      "searches",
      "databases",
      "gene"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/gget",
    "fullDescription": "\n# gget\n\n## Overview\n\ngget is a command-line bioinformatics tool and Python package providing unified access to 20+ genomic databases and analysis methods. Query gene information, sequence analysis, protein structures, expression data, and disease associations through a consistent interface. All gget modules work both as command-line tools and as Python functions.\n\n**Important**: The databases queried by gget are continuously updated, which sometimes changes their structure. gget modules are tested automatically on a biweekly basis and updated to match new database structures when necessary.\n\n## Installation\n\nInstall gget in a clean virtual environment to avoid conflicts:\n\n```bash\n# Using uv (recommended)\nuv uv pip install gget\n\n# Or using pip\nuv pip install --upgrade gget\n\n# In Python/Jupyter\nimport gget\n```\n\n## Quick Start\n\nBasic usage pattern for all modules:\n\n```bash\n# Command-line\ngget <module> [arguments] [options]\n\n# Python\ngget.module(arguments, options)\n```\n\nMost modules return:\n- **Command-line**: JSON (default) or CSV with `-csv` flag\n- **Python**: DataFrame or dictionary\n\nCommon flags across modules:\n- `-o/--out`: Save results to file\n- `-q/--quiet`: Suppress progress information\n- `-csv`: Return CSV format (command-line only)\n\n## Module Categories\n\n### 1. Reference & Gene Information\n\n#### gget ref - Reference Genome Downloads\n\nRetrieve download links and metadata for Ensembl reference genomes.\n\n**Parameters**:\n- `species`: Genus_species format (e.g., 'homo_sapiens', 'mus_musculus'). Shortcuts: 'human', 'mouse'\n- `-w/--which`: Specify return types (gtf, cdna, dna, cds, cdrna, pep). Default: all\n- `-r/--release`: Ensembl release number (default: latest)\n- `-l/--list_species`: List available vertebrate species\n- `-liv/--list_iv_species`: List available invertebrate species\n- `-ftp`: Return only FTP links\n- `-d/--download`: Download files (requires curl)\n\n**Examples**:\n```bash\n# List available species\ngget ref --list_species\n\n# Get all reference files for "
  },
  {
    "id": "get-available-resources",
    "name": "get-available-resources",
    "description": "This skill should be used at the start of any computationally intensive scientific task to detect and report available system resources (CPU cores, GPUs, memory, disk space). It creates a JSON file with resource information and strategic recommendations that inform computational approach decisions s",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "resources",
      "task",
      "resource",
      "processing",
      "start",
      "computationally",
      "intensive",
      "scientific",
      "detect",
      "report"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/get-available-resources",
    "fullDescription": "\n# Get Available Resources\n\n## Overview\n\nDetect available computational resources and generate strategic recommendations for scientific computing tasks. This skill automatically identifies CPU capabilities, GPU availability (NVIDIA CUDA, AMD ROCm, Apple Silicon Metal), memory constraints, and disk space to help make informed decisions about computational approaches.\n\n## When to Use This Skill\n\nUse this skill proactively before any computationally intensive task:\n\n- **Before data analysis**: Determine if datasets can be loaded into memory or require out-of-core processing\n- **Before model training**: Check if GPU acceleration is available and which backend to use\n- **Before parallel processing**: Identify optimal number of workers for joblib, multiprocessing, or Dask\n- **Before large file operations**: Verify sufficient disk space and appropriate storage strategies\n- **At project initialization**: Understand baseline capabilities for making architectural decisions\n\n**Example scenarios:**\n- \"Help me analyze this 50GB genomics dataset\" â†’ Use this skill first to determine if Dask/Zarr are needed\n- \"Train a neural network on this data\" â†’ Use this skill to detect available GPUs and backends\n- \"Process 10,000 files in parallel\" â†’ Use this skill to determine optimal worker count\n- \"Run a computationally intensive simulation\" â†’ Use this skill to understand resource constraints\n\n## How This Skill Works\n\n### Resource Detection\n\nThe skill runs `scripts/detect_resources.py` to automatically detect:\n\n1. **CPU Information**\n   - Physical and logical core counts\n   - Processor architecture and model\n   - CPU frequency information\n\n2. **GPU Information**\n   - NVIDIA GPUs: Detects via nvidia-smi, reports VRAM, driver version, compute capability\n   - AMD GPUs: Detects via rocm-smi\n   - Apple Silicon: Detects M1/M2/M3/M4 chips with Metal support and unified memory\n\n3. **Memory Information**\n   - Total and available RAM\n   - Current memory usage percentage\n   - Swap space availability\n\n"
  },
  {
    "id": "scientific-schematics",
    "name": "scientific-schematics",
    "description": "Create publication-quality scientific diagrams using Nano Banana Pro AI with smart iterative refinement. Uses Gemini 3 Pro for quality review. Only regenerates if quality is below threshold for your document type. Specialized in neural network architectures, system diagrams, flowcharts, biological p",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "scientific",
      "schematics",
      "diagrams",
      "pro",
      "quality",
      "publication-quality",
      "nano",
      "banana",
      "smart",
      "iterative"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/scientific-schematics",
    "fullDescription": "\n# Scientific Schematics and Diagrams\n\n## Overview\n\nScientific schematics and diagrams transform complex concepts into clear visual representations for publication. **This skill uses Nano Banana Pro AI for diagram generation with Gemini 3 Pro quality review.**\n\n**How it works:**\n- Describe your diagram in natural language\n- Nano Banana Pro generates publication-quality images automatically\n- **Gemini 3 Pro reviews quality** against document-type thresholds\n- **Smart iteration**: Only regenerates if quality is below threshold\n- Publication-ready output in minutes\n- No coding, templates, or manual drawing required\n\n**Quality Thresholds by Document Type:**\n| Document Type | Threshold | Description |\n|---------------|-----------|-------------|\n| journal | 8.5/10 | Nature, Science, peer-reviewed journals |\n| conference | 8.0/10 | Conference papers |\n| thesis | 8.0/10 | Dissertations, theses |\n| grant | 8.0/10 | Grant proposals |\n| preprint | 7.5/10 | arXiv, bioRxiv, etc. |\n| report | 7.5/10 | Technical reports |\n| poster | 7.0/10 | Academic posters |\n| presentation | 6.5/10 | Slides, talks |\n| default | 7.5/10 | General purpose |\n\n**Simply describe what you want, and Nano Banana Pro creates it.** All diagrams are stored in the figures/ subfolder and referenced in papers/posters.\n\n## Quick Start: Generate Any Diagram\n\nCreate any scientific diagram by simply describing it. Nano Banana Pro handles everything automatically with **smart iteration**:\n\n```bash\n# Generate for journal paper (highest quality threshold: 8.5/10)\npython scripts/generate_schematic.py \"CONSORT participant flow diagram with 500 screened, 150 excluded, 350 randomized\" -o figures/consort.png --doc-type journal\n\n# Generate for presentation (lower threshold: 6.5/10 - faster)\npython scripts/generate_schematic.py \"Transformer encoder-decoder architecture showing multi-head attention\" -o figures/transformer.png --doc-type presentation\n\n# Generate for poster (moderate threshold: 7.0/10)\npython scripts/generate_"
  },
  {
    "id": "geopandas",
    "name": "geopandas",
    "description": "Python library for working with geospatial vector data including shapefiles, GeoJSON, and GeoPackage files. Use when working with geographic data for spatial analysis, geometric operations, coordinate transformations, spatial joins, overlay operations, choropleth mapping, or any task involving readi",
    "category": "data-viz",
    "source": "scientific",
    "triggers": [
      "geopandas",
      "spatial",
      "vector",
      "geographic",
      "operations",
      "coordinate",
      "joins",
      "maps",
      "library",
      "geospatial"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/geopandas",
    "fullDescription": "\n# GeoPandas\n\nGeoPandas extends pandas to enable spatial operations on geometric types. It combines the capabilities of pandas and shapely for geospatial data analysis.\n\n## Installation\n\n```bash\nuv pip install geopandas\n```\n\n### Optional Dependencies\n\n```bash\n# For interactive maps\nuv pip install folium\n\n# For classification schemes in mapping\nuv pip install mapclassify\n\n# For faster I/O operations (2-4x speedup)\nuv pip install pyarrow\n\n# For PostGIS database support\nuv pip install psycopg2\nuv pip install geoalchemy2\n\n# For basemaps\nuv pip install contextily\n\n# For cartographic projections\nuv pip install cartopy\n```\n\n## Quick Start\n\n```python\nimport geopandas as gpd\n\n# Read spatial data\ngdf = gpd.read_file(\"data.geojson\")\n\n# Basic exploration\nprint(gdf.head())\nprint(gdf.crs)\nprint(gdf.geometry.geom_type)\n\n# Simple plot\ngdf.plot()\n\n# Reproject to different CRS\ngdf_projected = gdf.to_crs(\"EPSG:3857\")\n\n# Calculate area (use projected CRS for accuracy)\ngdf_projected['area'] = gdf_projected.geometry.area\n\n# Save to file\ngdf.to_file(\"output.gpkg\")\n```\n\n## Core Concepts\n\n### Data Structures\n\n- **GeoSeries**: Vector of geometries with spatial operations\n- **GeoDataFrame**: Tabular data structure with geometry column\n\nSee [data-structures.md](references/data-structures.md) for details.\n\n### Reading and Writing Data\n\nGeoPandas reads/writes multiple formats: Shapefile, GeoJSON, GeoPackage, PostGIS, Parquet.\n\n```python\n# Read with filtering\ngdf = gpd.read_file(\"data.gpkg\", bbox=(xmin, ymin, xmax, ymax))\n\n# Write with Arrow acceleration\ngdf.to_file(\"output.gpkg\", use_arrow=True)\n```\n\nSee [data-io.md](references/data-io.md) for comprehensive I/O operations.\n\n### Coordinate Reference Systems\n\nAlways check and manage CRS for accurate spatial operations:\n\n```python\n# Check CRS\nprint(gdf.crs)\n\n# Reproject (transforms coordinates)\ngdf_projected = gdf.to_crs(\"EPSG:3857\")\n\n# Set CRS (only when metadata missing)\ngdf = gdf.set_crs(\"EPSG:4326\")\n```\n\nSee [crs-management.md](references/crs-m"
  },
  {
    "id": "geniml",
    "name": "geniml",
    "description": "This skill should be used when working with genomic interval data (BED files) for machine learning tasks. Use for training region embeddings (Region2Vec, BEDspace), single-cell ATAC-seq analysis (scEmbed), building consensus peaks (universes), or any ML-based analysis of genomic regions. Applies to ",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "geniml",
      "genomic",
      "bed",
      "interval",
      "machine",
      "tasks",
      "training",
      "region",
      "embeddings",
      "region2vec"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/geniml",
    "fullDescription": "\n# Geniml: Genomic Interval Machine Learning\n\n## Overview\n\nGeniml is a Python package for building machine learning models on genomic interval data from BED files. It provides unsupervised methods for learning embeddings of genomic regions, single cells, and metadata labels, enabling similarity searches, clustering, and downstream ML tasks.\n\n## Installation\n\nInstall geniml using uv:\n\n```bash\nuv uv pip install geniml\n```\n\nFor ML dependencies (PyTorch, etc.):\n\n```bash\nuv uv pip install 'geniml[ml]'\n```\n\nDevelopment version from GitHub:\n\n```bash\nuv uv pip install git+https://github.com/databio/geniml.git\n```\n\n## Core Capabilities\n\nGeniml provides five primary capabilities, each detailed in dedicated reference files:\n\n### 1. Region2Vec: Genomic Region Embeddings\n\nTrain unsupervised embeddings of genomic regions using word2vec-style learning.\n\n**Use for:** Dimensionality reduction of BED files, region similarity analysis, feature vectors for downstream ML.\n\n**Workflow:**\n1. Tokenize BED files using a universe reference\n2. Train Region2Vec model on tokens\n3. Generate embeddings for regions\n\n**Reference:** See `references/region2vec.md` for detailed workflow, parameters, and examples.\n\n### 2. BEDspace: Joint Region and Metadata Embeddings\n\nTrain shared embeddings for region sets and metadata labels using StarSpace.\n\n**Use for:** Metadata-aware searches, cross-modal queries (regionâ†’label or labelâ†’region), joint analysis of genomic content and experimental conditions.\n\n**Workflow:**\n1. Preprocess regions and metadata\n2. Train BEDspace model\n3. Compute distances\n4. Query across regions and labels\n\n**Reference:** See `references/bedspace.md` for detailed workflow, search types, and examples.\n\n### 3. scEmbed: Single-Cell Chromatin Accessibility Embeddings\n\nTrain Region2Vec models on single-cell ATAC-seq data for cell-level embeddings.\n\n**Use for:** scATAC-seq clustering, cell-type annotation, dimensionality reduction of single cells, integration with scanpy workflows.\n\n**Workfl"
  },
  {
    "id": "generate-image",
    "name": "generate-image",
    "description": "Generate or edit images using AI models (FLUX, Gemini). Use for general-purpose image generation including photos, illustrations, artwork, visual assets, concept art, and any image that isn't a technical diagram or schematic. For flowcharts, circuits, pathways, and technical diagrams, use the scient",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "generate",
      "image",
      "technical",
      "edit",
      "images",
      "flux",
      "gemini",
      "general-purpose",
      "generation",
      "photos"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/generate-image",
    "fullDescription": "\n# Generate Image\n\nGenerate and edit high-quality images using OpenRouter's image generation models including FLUX.2 Pro and Gemini 3 Pro.\n\n## When to Use This Skill\n\n**Use generate-image for:**\n- Photos and photorealistic images\n- Artistic illustrations and artwork\n- Concept art and visual concepts\n- Visual assets for presentations or documents\n- Image editing and modifications\n- Any general-purpose image generation needs\n\n**Use scientific-schematics instead for:**\n- Flowcharts and process diagrams\n- Circuit diagrams and electrical schematics\n- Biological pathways and signaling cascades\n- System architecture diagrams\n- CONSORT diagrams and methodology flowcharts\n- Any technical/schematic diagrams\n\n## Quick Start\n\nUse the `scripts/generate_image.py` script to generate or edit images:\n\n```bash\n# Generate a new image\npython scripts/generate_image.py \"A beautiful sunset over mountains\"\n\n# Edit an existing image\npython scripts/generate_image.py \"Make the sky purple\" --input photo.jpg\n```\n\nThis generates/edits an image and saves it as `generated_image.png` in the current directory.\n\n## API Key Setup\n\n**CRITICAL**: The script requires an OpenRouter API key. Before running, check if the user has configured their API key:\n\n1. Look for a `.env` file in the project directory or parent directories\n2. Check for `OPENROUTER_API_KEY=<key>` in the `.env` file\n3. If not found, inform the user they need to:\n   - Create a `.env` file with `OPENROUTER_API_KEY=your-api-key-here`\n   - Or set the environment variable: `export OPENROUTER_API_KEY=your-api-key-here`\n   - Get an API key from: https://openrouter.ai/keys\n\nThe script will automatically detect the `.env` file and provide clear error messages if the API key is missing.\n\n## Model Selection\n\n**Default model**: `google/gemini-3-pro-image-preview` (high quality, recommended)\n\n**Available models for generation and editing**:\n- `google/gemini-3-pro-image-preview` - High quality, supports generation + editing\n- `black-forest-labs/flux.2"
  },
  {
    "id": "geo-database",
    "name": "geo-database",
    "description": "Access NCBI GEO for gene expression/genomics data. Search/download microarray and RNA-seq datasets (GSE, GSM, GPL), retrieve SOFT/Matrix files, for transcriptomics and expression analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "geo",
      "expression",
      "ncbi",
      "gene",
      "genomics",
      "download",
      "microarray",
      "rna-seq",
      "datasets",
      "gse"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/geo-database",
    "fullDescription": "\n# GEO Database\n\n## Overview\n\nThe Gene Expression Omnibus (GEO) is NCBI's public repository for high-throughput gene expression and functional genomics data. GEO contains over 264,000 studies with more than 8 million samples from both array-based and sequence-based experiments.\n\n## When to Use This Skill\n\nThis skill should be used when searching for gene expression datasets, retrieving experimental data, downloading raw and processed files, querying expression profiles, or integrating GEO data into computational analysis workflows.\n\n## Core Capabilities\n\n### 1. Understanding GEO Data Organization\n\nGEO organizes data hierarchically using different accession types:\n\n**Series (GSE):** A complete experiment with a set of related samples\n- Example: GSE123456\n- Contains experimental design, samples, and overall study information\n- Largest organizational unit in GEO\n- Current count: 264,928+ series\n\n**Sample (GSM):** A single experimental sample or biological replicate\n- Example: GSM987654\n- Contains individual sample data, protocols, and metadata\n- Linked to platforms and series\n- Current count: 8,068,632+ samples\n\n**Platform (GPL):** The microarray or sequencing platform used\n- Example: GPL570 (Affymetrix Human Genome U133 Plus 2.0 Array)\n- Describes the technology and probe/feature annotations\n- Shared across multiple experiments\n- Current count: 27,739+ platforms\n\n**DataSet (GDS):** Curated collections with consistent formatting\n- Example: GDS5678\n- Experimentally-comparable samples organized by study design\n- Processed for differential analysis\n- Subset of GEO data (4,348 curated datasets)\n- Ideal for quick comparative analyses\n\n**Profiles:** Gene-specific expression data linked to sequence features\n- Queryable by gene name or annotation\n- Cross-references to Entrez Gene\n- Enables gene-centric searches across all studies\n\n### 2. Searching GEO Data\n\n**GEO DataSets Search:**\n\nSearch for studies by keywords, organism, or experimental conditions:\n\n```python\nfrom Bio impor"
  },
  {
    "id": "gene-database",
    "name": "gene-database",
    "description": "Query NCBI Gene via E-utilities/Datasets API. Search by symbol/ID, retrieve gene info (RefSeqs, GO, locations, phenotypes), batch lookups, for gene annotation and functional analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "gene",
      "ncbi",
      "via",
      "e-utilities",
      "datasets",
      "symbol",
      "retrieve",
      "info",
      "refseqs",
      "locations"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/gene-database",
    "fullDescription": "\n# Gene Database\n\n## Overview\n\nNCBI Gene is a comprehensive database integrating gene information from diverse species. It provides nomenclature, reference sequences (RefSeqs), chromosomal maps, biological pathways, genetic variations, phenotypes, and cross-references to global genomic resources.\n\n## When to Use This Skill\n\nThis skill should be used when working with gene data including searching by gene symbol or ID, retrieving gene sequences and metadata, analyzing gene functions and pathways, or performing batch gene lookups.\n\n## Quick Start\n\nNCBI provides two main APIs for gene data access:\n\n1. **E-utilities** (Traditional): Full-featured API for all Entrez databases with flexible querying\n2. **NCBI Datasets API** (Newer): Optimized for gene data retrieval with simplified workflows\n\nChoose E-utilities for complex queries and cross-database searches. Choose Datasets API for straightforward gene data retrieval with metadata and sequences in a single request.\n\n## Common Workflows\n\n### Search Genes by Symbol or Name\n\nTo search for genes by symbol or name across organisms:\n\n1. Use the `scripts/query_gene.py` script with E-utilities ESearch\n2. Specify the gene symbol and organism (e.g., \"BRCA1 in human\")\n3. The script returns matching Gene IDs\n\nExample query patterns:\n- Gene symbol: `insulin[gene name] AND human[organism]`\n- Gene with disease: `dystrophin[gene name] AND muscular dystrophy[disease]`\n- Chromosome location: `human[organism] AND 17q21[chromosome]`\n\n### Retrieve Gene Information by ID\n\nTo fetch detailed information for known Gene IDs:\n\n1. Use `scripts/fetch_gene_data.py` with the Datasets API for comprehensive data\n2. Alternatively, use `scripts/query_gene.py` with E-utilities EFetch for specific formats\n3. Specify desired output format (JSON, XML, or text)\n\nThe Datasets API returns:\n- Gene nomenclature and aliases\n- Reference sequences (RefSeqs) for transcripts and proteins\n- Chromosomal location and mapping\n- Gene Ontology (GO) annotations\n- Associated p"
  },
  {
    "id": "flowio",
    "name": "flowio",
    "description": "Parse FCS (Flow Cytometry Standard) files v2.0-3.1. Extract events as NumPy arrays, read metadata/channels, convert to CSV/DataFrame, for flow cytometry data preprocessing.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "flowio",
      "flow",
      "cytometry",
      "parse",
      "fcs",
      "standard",
      "0-3",
      "extract",
      "events",
      "numpy"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/flowio",
    "fullDescription": "\n# FlowIO: Flow Cytometry Standard File Handler\n\n## Overview\n\nFlowIO is a lightweight Python library for reading and writing Flow Cytometry Standard (FCS) files. Parse FCS metadata, extract event data, and create new FCS files with minimal dependencies. The library supports FCS versions 2.0, 3.0, and 3.1, making it ideal for backend services, data pipelines, and basic cytometry file operations.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- FCS files requiring parsing or metadata extraction\n- Flow cytometry data needing conversion to NumPy arrays\n- Event data requiring export to FCS format\n- Multi-dataset FCS files needing separation\n- Channel information extraction (scatter, fluorescence, time)\n- Cytometry file validation or inspection\n- Pre-processing workflows before advanced analysis\n\n**Related Tools:** For advanced flow cytometry analysis including compensation, gating, and FlowJo/GatingML support, recommend FlowKit library as a companion to FlowIO.\n\n## Installation\n\n```bash\nuv pip install flowio\n```\n\nRequires Python 3.9 or later.\n\n## Quick Start\n\n### Basic File Reading\n\n```python\nfrom flowio import FlowData\n\n# Read FCS file\nflow_data = FlowData('experiment.fcs')\n\n# Access basic information\nprint(f\"FCS Version: {flow_data.version}\")\nprint(f\"Events: {flow_data.event_count}\")\nprint(f\"Channels: {flow_data.pnn_labels}\")\n\n# Get event data as NumPy array\nevents = flow_data.as_array()  # Shape: (events, channels)\n```\n\n### Creating FCS Files\n\n```python\nimport numpy as np\nfrom flowio import create_fcs\n\n# Prepare data\ndata = np.array([[100, 200, 50], [150, 180, 60]])  # 2 events, 3 channels\nchannels = ['FSC-A', 'SSC-A', 'FL1-A']\n\n# Create FCS file\ncreate_fcs('output.fcs', data, channels)\n```\n\n## Core Workflows\n\n### Reading and Parsing FCS Files\n\nThe FlowData class provides the primary interface for reading FCS files.\n\n**Standard Reading:**\n\n```python\nfrom flowio import FlowData\n\n# Basic reading\nflow = FlowData('sample.fcs')\n\n# Access attributes\nversion = "
  },
  {
    "id": "fda-database",
    "name": "fda-database",
    "description": "Query openFDA API for drugs, devices, adverse events, recalls, regulatory submissions (510k, PMA), substance identification (UNII), for FDA regulatory data analysis and safety research.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "fda",
      "regulatory",
      "openfda",
      "drugs",
      "devices",
      "adverse",
      "events",
      "recalls",
      "submissions",
      "510k"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/fda-database",
    "fullDescription": "\n# FDA Database Access\n\n## Overview\n\nAccess comprehensive FDA regulatory data through openFDA, the FDA's initiative to provide open APIs for public datasets. Query information about drugs, medical devices, foods, animal/veterinary products, and substances using Python with standardized interfaces.\n\n**Key capabilities:**\n- Query adverse events for drugs, devices, foods, and veterinary products\n- Access product labeling, approvals, and regulatory submissions\n- Monitor recalls and enforcement actions\n- Look up National Drug Codes (NDC) and substance identifiers (UNII)\n- Analyze device classifications and clearances (510k, PMA)\n- Track drug shortages and supply issues\n- Research chemical structures and substance relationships\n\n## When to Use This Skill\n\nThis skill should be used when working with:\n- **Drug research**: Safety profiles, adverse events, labeling, approvals, shortages\n- **Medical device surveillance**: Adverse events, recalls, 510(k) clearances, PMA approvals\n- **Food safety**: Recalls, allergen tracking, adverse events, dietary supplements\n- **Veterinary medicine**: Animal drug adverse events by species and breed\n- **Chemical/substance data**: UNII lookup, CAS number mapping, molecular structures\n- **Regulatory analysis**: Approval pathways, enforcement actions, compliance tracking\n- **Pharmacovigilance**: Post-market surveillance, safety signal detection\n- **Scientific research**: Drug interactions, comparative safety, epidemiological studies\n\n## Quick Start\n\n### 1. Basic Setup\n\n```python\nfrom scripts.fda_query import FDAQuery\n\n# Initialize (API key optional but recommended)\nfda = FDAQuery(api_key=\"YOUR_API_KEY\")\n\n# Query drug adverse events\nevents = fda.query_drug_events(\"aspirin\", limit=100)\n\n# Get drug labeling\nlabel = fda.query_drug_label(\"Lipitor\", brand=True)\n\n# Search device recalls\nrecalls = fda.query(\"device\", \"enforcement\",\n                   search=\"classification:Class+I\",\n                   limit=50)\n```\n\n### 2. API Key Setup\n\nWhile the API w"
  },
  {
    "id": "exploratory-data-analysis",
    "name": "exploratory-data-analysis",
    "description": "Perform comprehensive exploratory data analysis on scientific data files across 200+ file formats. This skill should be used when analyzing any scientific data file to understand its structure, content, quality, and characteristics. Automatically detects file type and generates detailed markdown rep",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "exploratory",
      "scientific",
      "file",
      "formats",
      "quality",
      "perform",
      "across",
      "200",
      "analyzing",
      "understand"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/exploratory-data-analysis",
    "fullDescription": "\n# Exploratory Data Analysis\n\n## Overview\n\nPerform comprehensive exploratory data analysis (EDA) on scientific data files across multiple domains. This skill provides automated file type detection, format-specific analysis, data quality assessment, and generates detailed markdown reports suitable for documentation and downstream analysis planning.\n\n**Key Capabilities:**\n- Automatic detection and analysis of 200+ scientific file formats\n- Comprehensive format-specific metadata extraction\n- Data quality and integrity assessment\n- Statistical summaries and distributions\n- Visualization recommendations\n- Downstream analysis suggestions\n- Markdown report generation\n\n## When to Use This Skill\n\nUse this skill when:\n- User provides a path to a scientific data file for analysis\n- User asks to \"explore\", \"analyze\", or \"summarize\" a data file\n- User wants to understand the structure and content of scientific data\n- User needs a comprehensive report of a dataset before analysis\n- User wants to assess data quality or completeness\n- User asks what type of analysis is appropriate for a file\n\n## Supported File Categories\n\nThe skill has comprehensive coverage of scientific file formats organized into six major categories:\n\n### 1. Chemistry and Molecular Formats (60+ extensions)\nStructure files, computational chemistry outputs, molecular dynamics trajectories, and chemical databases.\n\n**File types include:** `.pdb`, `.cif`, `.mol`, `.mol2`, `.sdf`, `.xyz`, `.smi`, `.gro`, `.log`, `.fchk`, `.cube`, `.dcd`, `.xtc`, `.trr`, `.prmtop`, `.psf`, and more.\n\n**Reference file:** `references/chemistry_molecular_formats.md`\n\n### 2. Bioinformatics and Genomics Formats (50+ extensions)\nSequence data, alignments, annotations, variants, and expression data.\n\n**File types include:** `.fasta`, `.fastq`, `.sam`, `.bam`, `.vcf`, `.bed`, `.gff`, `.gtf`, `.bigwig`, `.h5ad`, `.loom`, `.counts`, `.mtx`, and more.\n\n**Reference file:** `references/bioinformatics_genomics_formats.md`\n\n### 3. Microscopy and Im"
  },
  {
    "id": "fluidsim",
    "name": "fluidsim",
    "description": "Framework for computational fluid dynamics simulations using Python. Use when running fluid dynamics simulations including Navier-Stokes equations (2D/3D), shallow water equations, stratified flows, or when analyzing turbulence, vortex dynamics, or geophysical flows. Provides pseudospectral methods ",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "fluidsim",
      "dynamics",
      "fluid",
      "simulations",
      "equations",
      "flows",
      "computational",
      "running",
      "navier-stokes",
      "shallow"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/fluidsim",
    "fullDescription": "\n# FluidSim\n\n## Overview\n\nFluidSim is an object-oriented Python framework for high-performance computational fluid dynamics (CFD) simulations. It provides solvers for periodic-domain equations using pseudospectral methods with FFT, delivering performance comparable to Fortran/C++ while maintaining Python's ease of use.\n\n**Key strengths**:\n- Multiple solvers: 2D/3D Navier-Stokes, shallow water, stratified flows\n- High performance: Pythran/Transonic compilation, MPI parallelization\n- Complete workflow: Parameter configuration, simulation execution, output analysis\n- Interactive analysis: Python-based post-processing and visualization\n\n## Core Capabilities\n\n### 1. Installation and Setup\n\nInstall fluidsim using uv with appropriate feature flags:\n\n```bash\n# Basic installation\nuv uv pip install fluidsim\n\n# With FFT support (required for most solvers)\nuv uv pip install \"fluidsim[fft]\"\n\n# With MPI for parallel computing\nuv uv pip install \"fluidsim[fft,mpi]\"\n```\n\nSet environment variables for output directories (optional):\n\n```bash\nexport FLUIDSIM_PATH=/path/to/simulation/outputs\nexport FLUIDDYN_PATH_SCRATCH=/path/to/working/directory\n```\n\nNo API keys or authentication required.\n\nSee `references/installation.md` for complete installation instructions and environment configuration.\n\n### 2. Running Simulations\n\nStandard workflow consists of five steps:\n\n**Step 1**: Import solver\n```python\nfrom fluidsim.solvers.ns2d.solver import Simul\n```\n\n**Step 2**: Create and configure parameters\n```python\nparams = Simul.create_default_params()\nparams.oper.nx = params.oper.ny = 256\nparams.oper.Lx = params.oper.Ly = 2 * 3.14159\nparams.nu_2 = 1e-3\nparams.time_stepping.t_end = 10.0\nparams.init_fields.type = \"noise\"\n```\n\n**Step 3**: Instantiate simulation\n```python\nsim = Simul(params)\n```\n\n**Step 4**: Execute\n```python\nsim.time_stepping.start()\n```\n\n**Step 5**: Analyze results\n```python\nsim.output.phys_fields.plot(\"vorticity\")\nsim.output.spatial_means.plot()\n```\n\nSee `references/simulation_work"
  },
  {
    "id": "opentrons-integration",
    "name": "opentrons-integration",
    "description": "Lab automation platform for Flex/OT-2 robots. Write Protocol API v2 protocols, liquid handling, hardware modules (heater-shaker, thermocycler), labware management, for automated pipetting workflows.",
    "category": "lab-automation",
    "source": "scientific",
    "triggers": [
      "opentrons",
      "integration",
      "lab",
      "automation",
      "flex",
      "ot-2",
      "robots",
      "write",
      "protocol",
      "protocols"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/opentrons-integration",
    "fullDescription": "\n# Opentrons Integration\n\n## Overview\n\nOpentrons is a Python-based lab automation platform for Flex and OT-2 robots. Write Protocol API v2 protocols for liquid handling, control hardware modules (heater-shaker, thermocycler), manage labware, for automated pipetting workflows.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Writing Opentrons Protocol API v2 protocols in Python\n- Automating liquid handling workflows on Flex or OT-2 robots\n- Controlling hardware modules (temperature, magnetic, heater-shaker, thermocycler)\n- Setting up labware configurations and deck layouts\n- Implementing complex pipetting operations (serial dilutions, plate replication, PCR setup)\n- Managing tip usage and optimizing protocol efficiency\n- Working with multi-channel pipettes for 96-well plate operations\n- Simulating and testing protocols before robot execution\n\n## Core Capabilities\n\n### 1. Protocol Structure and Metadata\n\nEvery Opentrons protocol follows a standard structure:\n\n```python\nfrom opentrons import protocol_api\n\n# Metadata\nmetadata = {\n    'protocolName': 'My Protocol',\n    'author': 'Name <email@example.com>',\n    'description': 'Protocol description',\n    'apiLevel': '2.19'  # Use latest available API version\n}\n\n# Requirements (optional)\nrequirements = {\n    'robotType': 'Flex',  # or 'OT-2'\n    'apiLevel': '2.19'\n}\n\n# Run function\ndef run(protocol: protocol_api.ProtocolContext):\n    # Protocol commands go here\n    pass\n```\n\n**Key elements:**\n- Import `protocol_api` from `opentrons`\n- Define `metadata` dict with protocolName, author, description, apiLevel\n- Optional `requirements` dict for robot type and API version\n- Implement `run()` function receiving `ProtocolContext` as parameter\n- All protocol logic goes inside the `run()` function\n\n### 2. Loading Hardware\n\n**Loading Instruments (Pipettes):**\n\n```python\ndef run(protocol: protocol_api.ProtocolContext):\n    # Load pipette on specific mount\n    left_pipette = protocol.load_instrument(\n        'p1000_single_f"
  },
  {
    "id": "etetoolkit",
    "name": "etetoolkit",
    "description": "Phylogenetic tree toolkit (ETE). Tree manipulation (Newick/NHX), evolutionary event detection, orthology/paralogy, NCBI taxonomy, visualization (PDF/SVG), for phylogenomics.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "etetoolkit",
      "tree",
      "phylogenetic",
      "ete",
      "manipulation",
      "newick",
      "nhx",
      "evolutionary",
      "event",
      "detection"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/etetoolkit",
    "fullDescription": "\n# ETE Toolkit Skill\n\n## Overview\n\nETE (Environment for Tree Exploration) is a toolkit for phylogenetic and hierarchical tree analysis. Manipulate trees, analyze evolutionary events, visualize results, and integrate with biological databases for phylogenomic research and clustering analysis.\n\n## Core Capabilities\n\n### 1. Tree Manipulation and Analysis\n\nLoad, manipulate, and analyze hierarchical tree structures with support for:\n\n- **Tree I/O**: Read and write Newick, NHX, PhyloXML, and NeXML formats\n- **Tree traversal**: Navigate trees using preorder, postorder, or levelorder strategies\n- **Topology modification**: Prune, root, collapse nodes, resolve polytomies\n- **Distance calculations**: Compute branch lengths and topological distances between nodes\n- **Tree comparison**: Calculate Robinson-Foulds distances and identify topological differences\n\n**Common patterns:**\n\n```python\nfrom ete3 import Tree\n\n# Load tree from file\ntree = Tree(\"tree.nw\", format=1)\n\n# Basic statistics\nprint(f\"Leaves: {len(tree)}\")\nprint(f\"Total nodes: {len(list(tree.traverse()))}\")\n\n# Prune to taxa of interest\ntaxa_to_keep = [\"species1\", \"species2\", \"species3\"]\ntree.prune(taxa_to_keep, preserve_branch_length=True)\n\n# Midpoint root\nmidpoint = tree.get_midpoint_outgroup()\ntree.set_outgroup(midpoint)\n\n# Save modified tree\ntree.write(outfile=\"rooted_tree.nw\")\n```\n\nUse `scripts/tree_operations.py` for command-line tree manipulation:\n\n```bash\n# Display tree statistics\npython scripts/tree_operations.py stats tree.nw\n\n# Convert format\npython scripts/tree_operations.py convert tree.nw output.nw --in-format 0 --out-format 1\n\n# Reroot tree\npython scripts/tree_operations.py reroot tree.nw rooted.nw --midpoint\n\n# Prune to specific taxa\npython scripts/tree_operations.py prune tree.nw pruned.nw --keep-taxa \"sp1,sp2,sp3\"\n\n# Show ASCII visualization\npython scripts/tree_operations.py ascii tree.nw\n```\n\n### 2. Phylogenetic Analysis\n\nAnalyze gene trees with evolutionary event detection:\n\n- **Sequence alignment i"
  },
  {
    "id": "ena-database",
    "name": "ena-database",
    "description": "Access European Nucleotide Archive via API/FTP. Retrieve DNA/RNA sequences, raw reads (FASTQ), genome assemblies by accession, for genomics and bioinformatics pipelines. Supports multiple formats.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "ena",
      "european",
      "nucleotide",
      "archive",
      "via",
      "ftp",
      "retrieve",
      "dna",
      "rna",
      "sequences"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/ena-database",
    "fullDescription": "\n# ENA Database\n\n## Overview\n\nThe European Nucleotide Archive (ENA) is a comprehensive public repository for nucleotide sequence data and associated metadata. Access and query DNA/RNA sequences, raw reads, genome assemblies, and functional annotations through REST APIs and FTP for genomics and bioinformatics pipelines.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- Retrieving nucleotide sequences or raw sequencing reads by accession\n- Searching for samples, studies, or assemblies by metadata criteria\n- Downloading FASTQ files or genome assemblies for analysis\n- Querying taxonomic information for organisms\n- Accessing sequence annotations and functional data\n- Integrating ENA data into bioinformatics pipelines\n- Performing cross-reference searches to related databases\n- Bulk downloading datasets via FTP or Aspera\n\n## Core Capabilities\n\n### 1. Data Types and Structure\n\nENA organizes data into hierarchical object types:\n\n**Studies/Projects** - Group related data and control release dates. Studies are the primary unit for citing archived data.\n\n**Samples** - Represent units of biomaterial from which sequencing libraries were produced. Samples must be registered before submitting most data types.\n\n**Raw Reads** - Consist of:\n- **Experiments**: Metadata about sequencing methods, library preparation, and instrument details\n- **Runs**: References to data files containing raw sequencing reads from a single sequencing run\n\n**Assemblies** - Genome, transcriptome, metagenome, or metatranscriptome assemblies at various completion levels.\n\n**Sequences** - Assembled and annotated sequences stored in the EMBL Nucleotide Sequence Database, including coding/non-coding regions and functional annotations.\n\n**Analyses** - Results from computational analyses of sequence data.\n\n**Taxonomy Records** - Taxonomic information including lineage and rank.\n\n### 2. Programmatic Access\n\nENA provides multiple REST APIs for data access. Consult `references/api_reference.md` for detai"
  },
  {
    "id": "drugbank-database",
    "name": "drugbank-database",
    "description": "Access and analyze comprehensive drug information from the DrugBank database including drug properties, interactions, targets, pathways, chemical structures, and pharmacology data. This skill should be used when working with pharmaceutical data, drug discovery research, pharmacology studies, drug-dr",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "drugbank",
      "drug",
      "information",
      "chemical",
      "pharmacology",
      "target",
      "analyze",
      "properties",
      "interactions",
      "targets"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/drugbank-database",
    "fullDescription": "\n# DrugBank Database\n\n## Overview\n\nDrugBank is a comprehensive bioinformatics and cheminformatics database containing detailed information on drugs and drug targets. This skill enables programmatic access to DrugBank data including ~9,591 drug entries (2,037 FDA-approved small molecules, 241 biotech drugs, 96 nutraceuticals, and 6,000+ experimental compounds) with 200+ data fields per entry.\n\n## Core Capabilities\n\n### 1. Data Access and Authentication\n\nDownload and access DrugBank data using Python with proper authentication. The skill provides guidance on:\n\n- Installing and configuring the `drugbank-downloader` package\n- Managing credentials securely via environment variables or config files\n- Downloading specific or latest database versions\n- Opening and parsing XML data efficiently\n- Working with cached data to optimize performance\n\n**When to use**: Setting up DrugBank access, downloading database updates, initial project configuration.\n\n**Reference**: See `references/data-access.md` for detailed authentication, download procedures, API access, caching strategies, and troubleshooting.\n\n### 2. Drug Information Queries\n\nExtract comprehensive drug information from the database including identifiers, chemical properties, pharmacology, clinical data, and cross-references to external databases.\n\n**Query capabilities**:\n- Search by DrugBank ID, name, CAS number, or keywords\n- Extract basic drug information (name, type, description, indication)\n- Retrieve chemical properties (SMILES, InChI, molecular formula)\n- Get pharmacology data (mechanism of action, pharmacodynamics, ADME)\n- Access external identifiers (PubChem, ChEMBL, UniProt, KEGG)\n- Build searchable drug datasets and export to DataFrames\n- Filter drugs by type (small molecule, biotech, nutraceutical)\n\n**When to use**: Retrieving specific drug information, building drug databases, pharmacology research, literature review, drug profiling.\n\n**Reference**: See `references/drug-queries.md` for XML navigation, query f"
  },
  {
    "id": "esm",
    "name": "esm",
    "description": "Comprehensive toolkit for protein language models including ESM3 (generative multimodal protein design across sequence, structure, and function) and ESM C (efficient protein embeddings and representations). Use this skill when working with protein sequences, structures, or function prediction; desig",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "esm",
      "protein",
      "function",
      "embeddings",
      "language",
      "esm3",
      "generative",
      "multimodal",
      "design",
      "across"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/esm",
    "fullDescription": "\n# ESM: Evolutionary Scale Modeling\n\n## Overview\n\nESM provides state-of-the-art protein language models for understanding, generating, and designing proteins. This skill enables working with two model families: ESM3 for generative protein design across sequence, structure, and function, and ESM C for efficient protein representation learning and embeddings.\n\n## Core Capabilities\n\n### 1. Protein Sequence Generation with ESM3\n\nGenerate novel protein sequences with desired properties using multimodal generative modeling.\n\n**When to use:**\n- Designing proteins with specific functional properties\n- Completing partial protein sequences\n- Generating variants of existing proteins\n- Creating proteins with desired structural characteristics\n\n**Basic usage:**\n\n```python\nfrom esm.models.esm3 import ESM3\nfrom esm.sdk.api import ESM3InferenceClient, ESMProtein, GenerationConfig\n\n# Load model locally\nmodel: ESM3InferenceClient = ESM3.from_pretrained(\"esm3-sm-open-v1\").to(\"cuda\")\n\n# Create protein prompt\nprotein = ESMProtein(sequence=\"MPRT___KEND\")  # '_' represents masked positions\n\n# Generate completion\nprotein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8))\nprint(protein.sequence)\n```\n\n**For remote/cloud usage via Forge API:**\n\n```python\nfrom esm.sdk.forge import ESM3ForgeInferenceClient\nfrom esm.sdk.api import ESMProtein, GenerationConfig\n\n# Connect to Forge\nmodel = ESM3ForgeInferenceClient(model=\"esm3-medium-2024-08\", url=\"https://forge.evolutionaryscale.ai\", token=\"<token>\")\n\n# Generate\nprotein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8))\n```\n\nSee `references/esm3-api.md` for detailed ESM3 model specifications, advanced generation configurations, and multimodal prompting examples.\n\n### 2. Structure Prediction and Inverse Folding\n\nUse ESM3's structure track for structure prediction from sequence or inverse folding (sequence design from structure).\n\n**Structure prediction:**\n\n```python\nfrom esm.sdk.api import ESM3Inferenc"
  },
  {
    "id": "ensembl-database",
    "name": "ensembl-database",
    "description": "Query Ensembl genome database REST API for 250+ species. Gene lookups, sequence retrieval, variant analysis, comparative genomics, orthologs, VEP predictions, for genomic research.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "ensembl",
      "genome",
      "rest",
      "250",
      "species",
      "gene",
      "lookups",
      "sequence",
      "retrieval",
      "variant"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/ensembl-database",
    "fullDescription": "\n# Ensembl Database\n\n## Overview\n\nAccess and query the Ensembl genome database, a comprehensive resource for vertebrate genomic data maintained by EMBL-EBI. The database provides gene annotations, sequences, variants, regulatory information, and comparative genomics data for over 250 species. Current release is 115 (September 2025).\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- Querying gene information by symbol or Ensembl ID\n- Retrieving DNA, transcript, or protein sequences\n- Analyzing genetic variants using the Variant Effect Predictor (VEP)\n- Finding orthologs and paralogs across species\n- Accessing regulatory features and genomic annotations\n- Converting coordinates between genome assemblies (e.g., GRCh37 to GRCh38)\n- Performing comparative genomics analyses\n- Integrating Ensembl data into genomic research pipelines\n\n## Core Capabilities\n\n### 1. Gene Information Retrieval\n\nQuery gene data by symbol, Ensembl ID, or external database identifiers.\n\n**Common operations:**\n- Look up gene information by symbol (e.g., \"BRCA2\", \"TP53\")\n- Retrieve transcript and protein information\n- Get gene coordinates and chromosomal locations\n- Access cross-references to external databases (UniProt, RefSeq, etc.)\n\n**Using the ensembl_rest package:**\n```python\nfrom ensembl_rest import EnsemblClient\n\nclient = EnsemblClient()\n\n# Look up gene by symbol\ngene_data = client.symbol_lookup(\n    species='human',\n    symbol='BRCA2'\n)\n\n# Get detailed gene information\ngene_info = client.lookup_id(\n    id='ENSG00000139618',  # BRCA2 Ensembl ID\n    expand=True\n)\n```\n\n**Direct REST API (no package):**\n```python\nimport requests\n\nserver = \"https://rest.ensembl.org\"\n\n# Symbol lookup\nresponse = requests.get(\n    f\"{server}/lookup/symbol/homo_sapiens/BRCA2\",\n    headers={\"Content-Type\": \"application/json\"}\n)\ngene_data = response.json()\n```\n\n### 2. Sequence Retrieval\n\nFetch genomic, transcript, or protein sequences in various formats (JSON, FASTA, plain text).\n\n**Operations:**\n- Get DNA"
  },
  {
    "id": "diffdock",
    "name": "diffdock",
    "description": "Diffusion-based molecular docking. Predict protein-ligand binding poses from PDB/SMILES, confidence scores, virtual screening, for structure-based drug design. Not for affinity prediction.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "diffdock",
      "diffusion-based",
      "molecular",
      "docking",
      "predict",
      "protein-ligand",
      "binding",
      "poses",
      "pdb",
      "smiles"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/diffdock",
    "fullDescription": "\n# DiffDock: Molecular Docking with Diffusion Models\n\n## Overview\n\nDiffDock is a diffusion-based deep learning tool for molecular docking that predicts 3D binding poses of small molecule ligands to protein targets. It represents the state-of-the-art in computational docking, crucial for structure-based drug discovery and chemical biology.\n\n**Core Capabilities:**\n- Predict ligand binding poses with high accuracy using deep learning\n- Support protein structures (PDB files) or sequences (via ESMFold)\n- Process single complexes or batch virtual screening campaigns\n- Generate confidence scores to assess prediction reliability\n- Handle diverse ligand inputs (SMILES, SDF, MOL2)\n\n**Key Distinction:** DiffDock predicts **binding poses** (3D structure) and **confidence** (prediction certainty), NOT binding affinity (Î”G, Kd). Always combine with scoring functions (GNINA, MM/GBSA) for affinity assessment.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- \"Dock this ligand to a protein\" or \"predict binding pose\"\n- \"Run molecular docking\" or \"perform protein-ligand docking\"\n- \"Virtual screening\" or \"screen compound library\"\n- \"Where does this molecule bind?\" or \"predict binding site\"\n- Structure-based drug design or lead optimization tasks\n- Tasks involving PDB files + SMILES strings or ligand structures\n- Batch docking of multiple protein-ligand pairs\n\n## Installation and Environment Setup\n\n### Check Environment Status\n\nBefore proceeding with DiffDock tasks, verify the environment setup:\n\n```bash\n# Use the provided setup checker\npython scripts/setup_check.py\n```\n\nThis script validates Python version, PyTorch with CUDA, PyTorch Geometric, RDKit, ESM, and other dependencies.\n\n### Installation Options\n\n**Option 1: Conda (Recommended)**\n```bash\ngit clone https://github.com/gcorso/DiffDock.git\ncd DiffDock\nconda env create --file environment.yml\nconda activate diffdock\n```\n\n**Option 2: Docker**\n```bash\ndocker pull rbgcsail/diffdock\ndocker run -it --gpus all --entrypoint /"
  },
  {
    "id": "dnanexus-integration",
    "name": "dnanexus-integration",
    "description": "DNAnexus cloud genomics platform. Build apps/applets, manage data (upload/download), dxpy Python SDK, run workflows, FASTQ/BAM/VCF, for genomics pipeline development and execution.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "dnanexus",
      "integration",
      "genomics",
      "cloud",
      "apps",
      "applets",
      "manage",
      "upload",
      "download",
      "dxpy"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/dnanexus-integration",
    "fullDescription": "\n# DNAnexus Integration\n\n## Overview\n\nDNAnexus is a cloud platform for biomedical data analysis and genomics. Build and deploy apps/applets, manage data objects, run workflows, and use the dxpy Python SDK for genomics pipeline development and execution.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating, building, or modifying DNAnexus apps/applets\n- Uploading, downloading, searching, or organizing files and records\n- Running analyses, monitoring jobs, creating workflows\n- Writing scripts using dxpy to interact with the platform\n- Setting up dxapp.json, managing dependencies, using Docker\n- Processing FASTQ, BAM, VCF, or other bioinformatics files\n- Managing projects, permissions, or platform resources\n\n## Core Capabilities\n\nThe skill is organized into five main areas, each with detailed reference documentation:\n\n### 1. App Development\n\n**Purpose**: Create executable programs (apps/applets) that run on the DNAnexus platform.\n\n**Key Operations**:\n- Generate app skeleton with `dx-app-wizard`\n- Write Python or Bash apps with proper entry points\n- Handle input/output data objects\n- Deploy with `dx build` or `dx build --app`\n- Test apps on the platform\n\n**Common Use Cases**:\n- Bioinformatics pipelines (alignment, variant calling)\n- Data processing workflows\n- Quality control and filtering\n- Format conversion tools\n\n**Reference**: See `references/app-development.md` for:\n- Complete app structure and patterns\n- Python entry point decorators\n- Input/output handling with dxpy\n- Development best practices\n- Common issues and solutions\n\n### 2. Data Operations\n\n**Purpose**: Manage files, records, and other data objects on the platform.\n\n**Key Operations**:\n- Upload/download files with `dxpy.upload_local_file()` and `dxpy.download_dxfile()`\n- Create and manage records with metadata\n- Search for data objects by name, properties, or type\n- Clone data between projects\n- Manage project folders and permissions\n\n**Common Use Cases**:\n- Uploading sequencing data (FA"
  },
  {
    "id": "deeptools",
    "name": "deeptools",
    "description": "NGS analysis toolkit. BAM to bigWig conversion, QC (correlation, PCA, fingerprints), heatmaps/profiles (TSS, peaks), for ChIP-seq, RNA-seq, ATAC-seq visualization.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "deeptools",
      "ngs",
      "bam",
      "bigwig",
      "conversion",
      "correlation",
      "pca",
      "fingerprints",
      "heatmaps",
      "profiles"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/deeptools",
    "fullDescription": "\n# deepTools: NGS Data Analysis Toolkit\n\n## Overview\n\ndeepTools is a comprehensive suite of Python command-line tools designed for processing and analyzing high-throughput sequencing data. Use deepTools to perform quality control, normalize data, compare samples, and generate publication-quality visualizations for ChIP-seq, RNA-seq, ATAC-seq, MNase-seq, and other NGS experiments.\n\n**Core capabilities:**\n- Convert BAM alignments to normalized coverage tracks (bigWig/bedGraph)\n- Quality control assessment (fingerprint, correlation, coverage)\n- Sample comparison and correlation analysis\n- Heatmap and profile plot generation around genomic features\n- Enrichment analysis and peak region visualization\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **File conversion**: \"Convert BAM to bigWig\", \"generate coverage tracks\", \"normalize ChIP-seq data\"\n- **Quality control**: \"check ChIP quality\", \"compare replicates\", \"assess sequencing depth\", \"QC analysis\"\n- **Visualization**: \"create heatmap around TSS\", \"plot ChIP signal\", \"visualize enrichment\", \"generate profile plot\"\n- **Sample comparison**: \"compare treatment vs control\", \"correlate samples\", \"PCA analysis\"\n- **Analysis workflows**: \"analyze ChIP-seq data\", \"RNA-seq coverage\", \"ATAC-seq analysis\", \"complete workflow\"\n- **Working with specific file types**: BAM files, bigWig files, BED region files in genomics context\n\n## Quick Start\n\nFor users new to deepTools, start with file validation and common workflows:\n\n### 1. Validate Input Files\n\nBefore running any analysis, validate BAM, bigWig, and BED files using the validation script:\n\n```bash\npython scripts/validate_files.py --bam sample1.bam sample2.bam --bed regions.bed\n```\n\nThis checks file existence, BAM indices, and format correctness.\n\n### 2. Generate Workflow Template\n\nFor standard analyses, use the workflow generator to create customized scripts:\n\n```bash\n# List available workflows\npython scripts/workflow_generator.py --list\n\n# Generate ChIP-seq QC w"
  },
  {
    "id": "datamol",
    "name": "datamol",
    "description": "Pythonic wrapper around RDKit with simplified interface and sensible defaults. Preferred for standard drug discovery: SMILES parsing, standardization, descriptors, fingerprints, clustering, 3D conformers, parallel processing. Returns native rdkit.Chem.Mol objects. For advanced control or custom para",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "datamol",
      "rdkit",
      "pythonic",
      "wrapper",
      "around",
      "simplified",
      "interface",
      "sensible",
      "defaults",
      "preferred"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/datamol",
    "fullDescription": "\n# Datamol Cheminformatics Skill\n\n## Overview\n\nDatamol is a Python library that provides a lightweight, Pythonic abstraction layer over RDKit for molecular cheminformatics. Simplify complex molecular operations with sensible defaults, efficient parallelization, and modern I/O capabilities. All molecular objects are native `rdkit.Chem.Mol` instances, ensuring full compatibility with the RDKit ecosystem.\n\n**Key capabilities**:\n- Molecular format conversion (SMILES, SELFIES, InChI)\n- Structure standardization and sanitization\n- Molecular descriptors and fingerprints\n- 3D conformer generation and analysis\n- Clustering and diversity selection\n- Scaffold and fragment analysis\n- Chemical reaction application\n- Visualization and alignment\n- Batch processing with parallelization\n- Cloud storage support via fsspec\n\n## Installation and Setup\n\nGuide users to install datamol:\n\n```bash\nuv pip install datamol\n```\n\n**Import convention**:\n```python\nimport datamol as dm\n```\n\n## Core Workflows\n\n### 1. Basic Molecule Handling\n\n**Creating molecules from SMILES**:\n```python\nimport datamol as dm\n\n# Single molecule\nmol = dm.to_mol(\"CCO\")  # Ethanol\n\n# From list of SMILES\nsmiles_list = [\"CCO\", \"c1ccccc1\", \"CC(=O)O\"]\nmols = [dm.to_mol(smi) for smi in smiles_list]\n\n# Error handling\nmol = dm.to_mol(\"invalid_smiles\")  # Returns None\nif mol is None:\n    print(\"Failed to parse SMILES\")\n```\n\n**Converting molecules to SMILES**:\n```python\n# Canonical SMILES\nsmiles = dm.to_smiles(mol)\n\n# Isomeric SMILES (includes stereochemistry)\nsmiles = dm.to_smiles(mol, isomeric=True)\n\n# Other formats\ninchi = dm.to_inchi(mol)\ninchikey = dm.to_inchikey(mol)\nselfies = dm.to_selfies(mol)\n```\n\n**Standardization and sanitization** (always recommend for user-provided molecules):\n```python\n# Sanitize molecule\nmol = dm.sanitize_mol(mol)\n\n# Full standardization (recommended for datasets)\nmol = dm.standardize_mol(\n    mol,\n    disconnect_metals=True,\n    normalize=True,\n    reionize=True\n)\n\n# For SMILES strings directly\ncle"
  },
  {
    "id": "deepchem",
    "name": "deepchem",
    "description": "Molecular machine learning toolkit. Property prediction (ADMET, toxicity), GNNs (GCN, MPNN), MoleculeNet benchmarks, pretrained models, featurization, for drug discovery ML.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "deepchem",
      "molecular",
      "machine",
      "property",
      "prediction",
      "admet",
      "toxicity",
      "gnns",
      "gcn",
      "mpnn"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/deepchem",
    "fullDescription": "\n# DeepChem\n\n## Overview\n\nDeepChem is a comprehensive Python library for applying machine learning to chemistry, materials science, and biology. Enable molecular property prediction, drug discovery, materials design, and biomolecule analysis through specialized neural networks, molecular featurization methods, and pretrained models.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Loading and processing molecular data (SMILES strings, SDF files, protein sequences)\n- Predicting molecular properties (solubility, toxicity, binding affinity, ADMET properties)\n- Training models on chemical/biological datasets\n- Using MoleculeNet benchmark datasets (Tox21, BBBP, Delaney, etc.)\n- Converting molecules to ML-ready features (fingerprints, graph representations, descriptors)\n- Implementing graph neural networks for molecules (GCN, GAT, MPNN, AttentiveFP)\n- Applying transfer learning with pretrained models (ChemBERTa, GROVER, MolFormer)\n- Predicting crystal/materials properties (bandgap, formation energy)\n- Analyzing protein or DNA sequences\n\n## Core Capabilities\n\n### 1. Molecular Data Loading and Processing\n\nDeepChem provides specialized loaders for various chemical data formats:\n\n```python\nimport deepchem as dc\n\n# Load CSV with SMILES\nfeaturizer = dc.feat.CircularFingerprint(radius=2, size=2048)\nloader = dc.data.CSVLoader(\n    tasks=['solubility', 'toxicity'],\n    feature_field='smiles',\n    featurizer=featurizer\n)\ndataset = loader.create_dataset('molecules.csv')\n\n# Load SDF files\nloader = dc.data.SDFLoader(tasks=['activity'], featurizer=featurizer)\ndataset = loader.create_dataset('compounds.sdf')\n\n# Load protein sequences\nloader = dc.data.FASTALoader()\ndataset = loader.create_dataset('proteins.fasta')\n```\n\n**Key Loaders**:\n- `CSVLoader`: Tabular data with molecular identifiers\n- `SDFLoader`: Molecular structure files\n- `FASTALoader`: Protein/DNA sequences\n- `ImageLoader`: Molecular images\n- `JsonLoader`: JSON-formatted datasets\n\n### 2. Molecular Featurization\n\nC"
  },
  {
    "id": "datacommons-client",
    "name": "datacommons-client",
    "description": "Work with Data Commons, a platform providing programmatic access to public statistical data from global sources. Use this skill when working with demographic data, economic indicators, health statistics, environmental data, or any public datasets available through Data Commons. Applicable for queryi",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "datacommons",
      "client",
      "commons",
      "public",
      "statistical",
      "statistics",
      "work",
      "providing",
      "programmatic",
      "global"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/datacommons-client",
    "fullDescription": "\n# Data Commons Client\n\n## Overview\n\nProvides comprehensive access to the Data Commons Python API v2 for querying statistical observations, exploring the knowledge graph, and resolving entity identifiers. Data Commons aggregates data from census bureaus, health organizations, environmental agencies, and other authoritative sources into a unified knowledge graph.\n\n## Installation\n\nInstall the Data Commons Python client with Pandas support:\n\n```bash\nuv pip install \"datacommons-client[Pandas]\"\n```\n\nFor basic usage without Pandas:\n```bash\nuv pip install datacommons-client\n```\n\n## Core Capabilities\n\nThe Data Commons API consists of three main endpoints, each detailed in dedicated reference files:\n\n### 1. Observation Endpoint - Statistical Data Queries\n\nQuery time-series statistical data for entities. See `references/observation.md` for comprehensive documentation.\n\n**Primary use cases:**\n- Retrieve population, economic, health, or environmental statistics\n- Access historical time-series data for trend analysis\n- Query data for hierarchies (all counties in a state, all countries in a region)\n- Compare statistics across multiple entities\n- Filter by data source for consistency\n\n**Common patterns:**\n```python\nfrom datacommons_client import DataCommonsClient\n\nclient = DataCommonsClient()\n\n# Get latest population data\nresponse = client.observation.fetch(\n    variable_dcids=[\"Count_Person\"],\n    entity_dcids=[\"geoId/06\"],  # California\n    date=\"latest\"\n)\n\n# Get time series\nresponse = client.observation.fetch(\n    variable_dcids=[\"UnemploymentRate_Person\"],\n    entity_dcids=[\"country/USA\"],\n    date=\"all\"\n)\n\n# Query by hierarchy\nresponse = client.observation.fetch(\n    variable_dcids=[\"MedianIncome_Household\"],\n    entity_expression=\"geoId/06<-containedInPlace+{typeOf:County}\",\n    date=\"2020\"\n)\n```\n\n### 2. Node Endpoint - Knowledge Graph Exploration\n\nExplore entity relationships and properties within the knowledge graph. See `references/node.md` for comprehensive documentatio"
  },
  {
    "id": "denario",
    "name": "denario",
    "description": "Multiagent AI system for scientific research assistance that automates research workflows from data analysis to publication. This skill should be used when generating research ideas from datasets, developing research methodologies, executing computational experiments, performing literature searches,",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "denario",
      "generating",
      "multiagent",
      "system",
      "scientific",
      "assistance",
      "automates",
      "workflows",
      "publication",
      "ideas"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/denario",
    "fullDescription": "\n# Denario\n\n## Overview\n\nDenario is a multiagent AI system designed to automate scientific research workflows from initial data analysis through publication-ready manuscripts. Built on AG2 and LangGraph frameworks, it orchestrates multiple specialized agents to handle hypothesis generation, methodology development, computational analysis, and paper writing.\n\n## When to Use This Skill\n\nUse this skill when:\n- Analyzing datasets to generate novel research hypotheses\n- Developing structured research methodologies\n- Executing computational experiments and generating visualizations\n- Conducting literature searches for research context\n- Writing journal-formatted LaTeX papers from research results\n- Automating the complete research pipeline from data to publication\n\n## Installation\n\nInstall denario using uv (recommended):\n\n```bash\nuv init\nuv add \"denario[app]\"\n```\n\nOr using pip:\n\n```bash\nuv pip install \"denario[app]\"\n```\n\nFor Docker deployment or building from source, see `references/installation.md`.\n\n## LLM API Configuration\n\nDenario requires API keys from supported LLM providers. Supported providers include:\n- Google Vertex AI\n- OpenAI\n- Other LLM services compatible with AG2/LangGraph\n\nStore API keys securely using environment variables or `.env` files. For detailed configuration instructions including Vertex AI setup, see `references/llm_configuration.md`.\n\n## Core Research Workflow\n\nDenario follows a structured four-stage research pipeline:\n\n### 1. Data Description\n\nDefine the research context by specifying available data and tools:\n\n```python\nfrom denario import Denario\n\nden = Denario(project_dir=\"./my_research\")\nden.set_data_description(\"\"\"\nAvailable datasets: time-series data on X and Y\nTools: pandas, sklearn, matplotlib\nResearch domain: [specify domain]\n\"\"\")\n```\n\n### 2. Idea Generation\n\nGenerate research hypotheses from the data description:\n\n```python\nden.get_idea()\n```\n\nThis produces a research question or hypothesis based on the described data. Alternatively, "
  },
  {
    "id": "cosmic-database",
    "name": "cosmic-database",
    "description": "Access COSMIC cancer mutation database. Query somatic mutations, Cancer Gene Census, mutational signatures, gene fusions, for cancer research and precision oncology. Requires authentication.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "cosmic",
      "cancer",
      "gene",
      "mutation",
      "somatic",
      "mutations",
      "census",
      "mutational",
      "signatures",
      "fusions"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/cosmic-database",
    "fullDescription": "\n# COSMIC Database\n\n## Overview\n\nCOSMIC (Catalogue of Somatic Mutations in Cancer) is the world's largest and most comprehensive database for exploring somatic mutations in human cancer. Access COSMIC's extensive collection of cancer genomics data, including millions of mutations across thousands of cancer types, curated gene lists, mutational signatures, and clinical annotations programmatically.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Downloading cancer mutation data from COSMIC\n- Accessing the Cancer Gene Census for curated cancer gene lists\n- Retrieving mutational signature profiles\n- Querying structural variants, copy number alterations, or gene fusions\n- Analyzing drug resistance mutations\n- Working with cancer cell line genomics data\n- Integrating cancer mutation data into bioinformatics pipelines\n- Researching specific genes or mutations in cancer contexts\n\n## Prerequisites\n\n### Account Registration\nCOSMIC requires authentication for data downloads:\n- **Academic users**: Free access with registration at https://cancer.sanger.ac.uk/cosmic/register\n- **Commercial users**: License required (contact QIAGEN)\n\n### Python Requirements\n```bash\nuv pip install requests pandas\n```\n\n## Quick Start\n\n### 1. Basic File Download\n\nUse the `scripts/download_cosmic.py` script to download COSMIC data files:\n\n```python\nfrom scripts.download_cosmic import download_cosmic_file\n\n# Download mutation data\ndownload_cosmic_file(\n    email=\"your_email@institution.edu\",\n    password=\"your_password\",\n    filepath=\"GRCh38/cosmic/latest/CosmicMutantExport.tsv.gz\",\n    output_filename=\"cosmic_mutations.tsv.gz\"\n)\n```\n\n### 2. Command-Line Usage\n\n```bash\n# Download using shorthand data type\npython scripts/download_cosmic.py user@email.com --data-type mutations\n\n# Download specific file\npython scripts/download_cosmic.py user@email.com \\\n    --filepath GRCh38/cosmic/latest/cancer_gene_census.csv\n\n# Download for specific genome assembly\npython scripts/download_cosmic.py user@"
  },
  {
    "id": "dask",
    "name": "dask",
    "description": "Parallel/distributed computing. Scale pandas/NumPy beyond memory, parallel DataFrames/Arrays, multi-file processing, task graphs, for larger-than-RAM datasets and parallel workflows.",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "dask",
      "parallel",
      "distributed",
      "computing",
      "scale",
      "pandas",
      "numpy",
      "beyond",
      "memory",
      "dataframes"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/dask",
    "fullDescription": "\n# Dask\n\n## Overview\n\nDask is a Python library for parallel and distributed computing that enables three critical capabilities:\n- **Larger-than-memory execution** on single machines for data exceeding available RAM\n- **Parallel processing** for improved computational speed across multiple cores\n- **Distributed computation** supporting terabyte-scale datasets across multiple machines\n\nDask scales from laptops (processing ~100 GiB) to clusters (processing ~100 TiB) while maintaining familiar Python APIs.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Process datasets that exceed available RAM\n- Scale pandas or NumPy operations to larger datasets\n- Parallelize computations for performance improvements\n- Process multiple files efficiently (CSVs, Parquet, JSON, text logs)\n- Build custom parallel workflows with task dependencies\n- Distribute workloads across multiple cores or machines\n\n## Core Capabilities\n\nDask provides five main components, each suited to different use cases:\n\n### 1. DataFrames - Parallel Pandas Operations\n\n**Purpose**: Scale pandas operations to larger datasets through parallel processing.\n\n**When to Use**:\n- Tabular data exceeds available RAM\n- Need to process multiple CSV/Parquet files together\n- Pandas operations are slow and need parallelization\n- Scaling from pandas prototype to production\n\n**Reference Documentation**: For comprehensive guidance on Dask DataFrames, refer to `references/dataframes.md` which includes:\n- Reading data (single files, multiple files, glob patterns)\n- Common operations (filtering, groupby, joins, aggregations)\n- Custom operations with `map_partitions`\n- Performance optimization tips\n- Common patterns (ETL, time series, multi-file processing)\n\n**Quick Example**:\n```python\nimport dask.dataframe as dd\n\n# Read multiple files as single DataFrame\nddf = dd.read_csv('data/2024-*.csv')\n\n# Operations are lazy until compute()\nfiltered = ddf[ddf['value'] > 100]\nresult = filtered.groupby('category').mean().compute()\n``"
  },
  {
    "id": "clinvar-database",
    "name": "clinvar-database",
    "description": "Query NCBI ClinVar for variant clinical significance. Search by gene/position, interpret pathogenicity classifications, access via E-utilities API or FTP, annotate VCFs, for genomic medicine.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "clinvar",
      "ncbi",
      "variant",
      "clinical",
      "significance",
      "gene",
      "position",
      "interpret",
      "pathogenicity",
      "classifications"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/clinvar-database",
    "fullDescription": "\n# ClinVar Database\n\n## Overview\n\nClinVar is NCBI's freely accessible archive of reports on relationships between human genetic variants and phenotypes, with supporting evidence. The database aggregates information about genomic variation and its relationship to human health, providing standardized variant classifications used in clinical genetics and research.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- Searching for variants by gene, condition, or clinical significance\n- Interpreting clinical significance classifications (pathogenic, benign, VUS)\n- Accessing ClinVar data programmatically via E-utilities API\n- Downloading and processing bulk data from FTP\n- Understanding review status and star ratings\n- Resolving conflicting variant interpretations\n- Annotating variant call sets with clinical significance\n\n## Core Capabilities\n\n### 1. Search and Query ClinVar\n\n#### Web Interface Queries\n\nSearch ClinVar using the web interface at https://www.ncbi.nlm.nih.gov/clinvar/\n\n**Common search patterns:**\n- By gene: `BRCA1[gene]`\n- By clinical significance: `pathogenic[CLNSIG]`\n- By condition: `breast cancer[disorder]`\n- By variant: `NM_000059.3:c.1310_1313del[variant name]`\n- By chromosome: `13[chr]`\n- Combined: `BRCA1[gene] AND pathogenic[CLNSIG]`\n\n#### Programmatic Access via E-utilities\n\nAccess ClinVar programmatically using NCBI's E-utilities API. Refer to `references/api_reference.md` for comprehensive API documentation including:\n- **esearch** - Search for variants matching criteria\n- **esummary** - Retrieve variant summaries\n- **efetch** - Download full XML records\n- **elink** - Find related records in other NCBI databases\n\n**Quick example using curl:**\n```bash\n# Search for pathogenic BRCA1 variants\ncurl \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=clinvar&term=BRCA1[gene]+AND+pathogenic[CLNSIG]&retmode=json\"\n```\n\n**Best practices:**\n- Test queries on the web interface before automating\n- Use API keys to increase rate limits from 3"
  },
  {
    "id": "cobrapy",
    "name": "cobrapy",
    "description": "Constraint-based metabolic modeling (COBRA). FBA, FVA, gene knockouts, flux sampling, SBML models, for systems biology and metabolic engineering analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "cobrapy",
      "metabolic",
      "constraint-based",
      "modeling",
      "cobra",
      "fba",
      "fva",
      "gene",
      "knockouts",
      "flux"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/cobrapy",
    "fullDescription": "\n# COBRApy - Constraint-Based Reconstruction and Analysis\n\n## Overview\n\nCOBRApy is a Python library for constraint-based reconstruction and analysis (COBRA) of metabolic models, essential for systems biology research. Work with genome-scale metabolic models, perform computational simulations of cellular metabolism, conduct metabolic engineering analyses, and predict phenotypic behaviors.\n\n## Core Capabilities\n\nCOBRApy provides comprehensive tools organized into several key areas:\n\n### 1. Model Management\n\nLoad existing models from repositories or files:\n```python\nfrom cobra.io import load_model\n\n# Load bundled test models\nmodel = load_model(\"textbook\")  # E. coli core model\nmodel = load_model(\"ecoli\")     # Full E. coli model\nmodel = load_model(\"salmonella\")\n\n# Load from files\nfrom cobra.io import read_sbml_model, load_json_model, load_yaml_model\nmodel = read_sbml_model(\"path/to/model.xml\")\nmodel = load_json_model(\"path/to/model.json\")\nmodel = load_yaml_model(\"path/to/model.yml\")\n```\n\nSave models in various formats:\n```python\nfrom cobra.io import write_sbml_model, save_json_model, save_yaml_model\nwrite_sbml_model(model, \"output.xml\")  # Preferred format\nsave_json_model(model, \"output.json\")  # For Escher compatibility\nsave_yaml_model(model, \"output.yml\")   # Human-readable\n```\n\n### 2. Model Structure and Components\n\nAccess and inspect model components:\n```python\n# Access components\nmodel.reactions      # DictList of all reactions\nmodel.metabolites    # DictList of all metabolites\nmodel.genes          # DictList of all genes\n\n# Get specific items by ID or index\nreaction = model.reactions.get_by_id(\"PFK\")\nmetabolite = model.metabolites[0]\n\n# Inspect properties\nprint(reaction.reaction)        # Stoichiometric equation\nprint(reaction.bounds)          # Flux constraints\nprint(reaction.gene_reaction_rule)  # GPR logic\nprint(metabolite.formula)       # Chemical formula\nprint(metabolite.compartment)   # Cellular location\n```\n\n### 3. Flux Balance Analysis (FBA)\n\nPerform stan"
  },
  {
    "id": "clinicaltrials-database",
    "name": "clinicaltrials-database",
    "description": "Query ClinicalTrials.gov via API v2. Search trials by condition, drug, location, status, or phase. Retrieve trial details by NCT ID, export data, for clinical research and patient matching.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "clinicaltrials",
      "gov",
      "via",
      "trials",
      "condition",
      "drug",
      "location",
      "status",
      "phase",
      "retrieve"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/clinicaltrials-database",
    "fullDescription": "\n# ClinicalTrials.gov Database\n\n## Overview\n\nClinicalTrials.gov is a comprehensive registry of clinical studies conducted worldwide, maintained by the U.S. National Library of Medicine. Access API v2 to search for trials, retrieve detailed study information, filter by various criteria, and export data for analysis. The API is public (no authentication required) with rate limits of ~50 requests per minute, supporting JSON and CSV formats.\n\n## When to Use This Skill\n\nThis skill should be used when working with clinical trial data in scenarios such as:\n\n- **Patient matching** - Finding recruiting trials for specific conditions or patient populations\n- **Research analysis** - Analyzing clinical trial trends, outcomes, or study designs\n- **Drug/intervention research** - Identifying trials testing specific drugs or interventions\n- **Geographic searches** - Locating trials in specific locations or regions\n- **Sponsor/organization tracking** - Finding trials conducted by specific institutions\n- **Data export** - Extracting clinical trial data for further analysis or reporting\n- **Trial monitoring** - Tracking status updates or results for specific trials\n- **Eligibility screening** - Reviewing inclusion/exclusion criteria for trials\n\n## Quick Start\n\n### Basic Search Query\n\nSearch for clinical trials using the helper script:\n\n```bash\ncd scientific-databases/clinicaltrials-database/scripts\npython3 query_clinicaltrials.py\n```\n\nOr use Python directly with the `requests` library:\n\n```python\nimport requests\n\nurl = \"https://clinicaltrials.gov/api/v2/studies\"\nparams = {\n    \"query.cond\": \"breast cancer\",\n    \"filter.overallStatus\": \"RECRUITING\",\n    \"pageSize\": 10\n}\n\nresponse = requests.get(url, params=params)\ndata = response.json()\n\nprint(f\"Found {data['totalCount']} trials\")\n```\n\n### Retrieve Specific Trial\n\nGet detailed information about a trial using its NCT ID:\n\n```python\nimport requests\n\nnct_id = \"NCT04852770\"\nurl = f\"https://clinicaltrials.gov/api/v2/studies/{nct_id}\"\n\nrespo"
  },
  {
    "id": "lamindb",
    "name": "lamindb",
    "description": "This skill should be used when working with LaminDB, an open-source data framework for biology that makes data queryable, traceable, reproducible, and FAIR. Use when managing biological datasets (scRNA-seq, spatial, flow cytometry, etc.), tracking computational workflows, curating and validating dat",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "lamindb",
      "biological",
      "ontologies",
      "open-source",
      "biology",
      "makes",
      "queryable",
      "traceable",
      "reproducible",
      "fair"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/lamindb",
    "fullDescription": "\n# LaminDB\n\n## Overview\n\nLaminDB is an open-source data framework for biology designed to make data queryable, traceable, reproducible, and FAIR (Findable, Accessible, Interoperable, Reusable). It provides a unified platform that combines lakehouse architecture, lineage tracking, feature stores, biological ontologies, LIMS (Laboratory Information Management System), and ELN (Electronic Lab Notebook) capabilities through a single Python API.\n\n**Core Value Proposition:**\n- **Queryability**: Search and filter datasets by metadata, features, and ontology terms\n- **Traceability**: Automatic lineage tracking from raw data through analysis to results\n- **Reproducibility**: Version control for data, code, and environment\n- **FAIR Compliance**: Standardized annotations using biological ontologies\n\n## When to Use This Skill\n\nUse this skill when:\n\n- **Managing biological datasets**: scRNA-seq, bulk RNA-seq, spatial transcriptomics, flow cytometry, multi-modal data, EHR data\n- **Tracking computational workflows**: Notebooks, scripts, pipeline execution (Nextflow, Snakemake, Redun)\n- **Curating and validating data**: Schema validation, standardization, ontology-based annotation\n- **Working with biological ontologies**: Genes, proteins, cell types, tissues, diseases, pathways (via Bionty)\n- **Building data lakehouses**: Unified query interface across multiple datasets\n- **Ensuring reproducibility**: Automatic versioning, lineage tracking, environment capture\n- **Integrating ML pipelines**: Connecting with Weights & Biases, MLflow, HuggingFace, scVI-tools\n- **Deploying data infrastructure**: Setting up local or cloud-based data management systems\n- **Collaborating on datasets**: Sharing curated, annotated data with standardized metadata\n\n## Core Capabilities\n\nLaminDB provides six interconnected capability areas, each documented in detail in the references folder.\n\n### 1. Core Concepts and Data Lineage\n\n**Core entities:**\n- **Artifacts**: Versioned datasets (DataFrame, AnnData, Par"
  },
  {
    "id": "clinical-decision-support",
    "name": "clinical-decision-support",
    "description": "Generate professional clinical decision support (CDS) documents for pharmaceutical and clinical research settings, including patient cohort analyses (biomarker-stratified with outcomes) and treatment recommendation reports (evidence-based guidelines with decision algorithms). Supports GRADE evidence",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "clinical",
      "decision",
      "evidence",
      "generate",
      "professional",
      "cds",
      "documents",
      "pharmaceutical",
      "settings",
      "patient"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/clinical-decision-support",
    "fullDescription": "\n# Clinical Decision Support Documents\n\n## Description\n\nGenerate professional clinical decision support (CDS) documents for pharmaceutical companies, clinical researchers, and medical decision-makers. This skill specializes in analytical, evidence-based documents that inform treatment strategies and drug development:\n\n1. **Patient Cohort Analysis** - Biomarker-stratified group analyses with statistical outcome comparisons\n2. **Treatment Recommendation Reports** - Evidence-based clinical guidelines with GRADE grading and decision algorithms\n\nAll documents are generated as publication-ready LaTeX/PDF files optimized for pharmaceutical research, regulatory submissions, and clinical guideline development.\n\n**Note:** For individual patient treatment plans at the bedside, use the `treatment-plans` skill instead. This skill focuses on group-level analyses and evidence synthesis for pharmaceutical/research settings.\n\n## Capabilities\n\n### Document Types\n\n**Patient Cohort Analysis**\n- Biomarker-based patient stratification (molecular subtypes, gene expression, IHC)\n- Molecular subtype classification (e.g., GBM mesenchymal-immune-active vs proneural, breast cancer subtypes)\n- Outcome metrics with statistical analysis (OS, PFS, ORR, DOR, DCR)\n- Statistical comparisons between subgroups (hazard ratios, p-values, 95% CI)\n- Survival analysis with Kaplan-Meier curves and log-rank tests\n- Efficacy tables and waterfall plots\n- Comparative effectiveness analyses\n- Pharmaceutical cohort reporting (trial subgroups, real-world evidence)\n\n**Treatment Recommendation Reports**\n- Evidence-based treatment guidelines for specific disease states\n- Strength of recommendation grading (GRADE system: 1A, 1B, 2A, 2B, 2C)\n- Quality of evidence assessment (high, moderate, low, very low)\n- Treatment algorithm flowcharts with TikZ diagrams\n- Line-of-therapy sequencing based on biomarkers\n- Decision pathways with clinical and molecular criteria\n- Pharmaceutical strategy documents\n- Clinical guideline dev"
  },
  {
    "id": "clinpgx-database",
    "name": "clinpgx-database",
    "description": "Access ClinPGx pharmacogenomics data (successor to PharmGKB). Query gene-drug interactions, CPIC guidelines, allele functions, for precision medicine and genotype-guided dosing decisions.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "clinpgx",
      "pharmacogenomics",
      "successor",
      "pharmgkb",
      "gene-drug",
      "interactions",
      "cpic",
      "guidelines",
      "allele",
      "functions"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/clinpgx-database",
    "fullDescription": "\n# ClinPGx Database\n\n## Overview\n\nClinPGx (Clinical Pharmacogenomics Database) is a comprehensive resource for clinical pharmacogenomics information, successor to PharmGKB. It consolidates data from PharmGKB, CPIC, and PharmCAT, providing curated information on how genetic variation affects medication response. Access gene-drug pairs, clinical guidelines, allele functions, and drug labels for precision medicine applications.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **Gene-drug interactions**: Querying how genetic variants affect drug metabolism, efficacy, or toxicity\n- **CPIC guidelines**: Accessing evidence-based clinical practice guidelines for pharmacogenetics\n- **Allele information**: Retrieving allele function, frequency, and phenotype data\n- **Drug labels**: Exploring FDA and other regulatory pharmacogenomic drug labeling\n- **Pharmacogenomic annotations**: Accessing curated literature on gene-drug-disease relationships\n- **Clinical decision support**: Using PharmDOG tool for phenoconversion and custom genotype interpretation\n- **Precision medicine**: Implementing pharmacogenomic testing in clinical practice\n- **Drug metabolism**: Understanding CYP450 and other pharmacogene functions\n- **Personalized dosing**: Finding genotype-guided dosing recommendations\n- **Adverse drug reactions**: Identifying genetic risk factors for drug toxicity\n\n## Installation and Setup\n\n### Python API Access\n\nThe ClinPGx REST API provides programmatic access to all database resources. Basic setup:\n\n```bash\nuv pip install requests\n```\n\n### API Endpoint\n\n```python\nBASE_URL = \"https://api.clinpgx.org/v1/\"\n```\n\n**Rate Limits**:\n- 2 requests per second maximum\n- Excessive requests will result in HTTP 429 (Too Many Requests) response\n\n**Authentication**: Not required for basic access\n\n**Data License**: Creative Commons Attribution-ShareAlike 4.0 International License\n\nFor substantial API use, notify the ClinPGx team at api@clinpgx.org\n\n## Core Capabilities\n\n### 1. Gene"
  },
  {
    "id": "citation-management",
    "name": "citation-management",
    "description": "Comprehensive citation management for academic research. Search Google Scholar and PubMed for papers, extract accurate metadata, validate citations, and generate properly formatted BibTeX entries. This skill should be used when you need to find papers, verify citation information, convert DOIs to Bi",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "citation",
      "management",
      "papers",
      "bibtex",
      "academic",
      "google",
      "scholar",
      "pubmed",
      "extract",
      "accurate"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/citation-management",
    "fullDescription": "\n# Citation Management\n\n## Overview\n\nManage citations systematically throughout the research and writing process. This skill provides tools and strategies for searching academic databases (Google Scholar, PubMed), extracting accurate metadata from multiple sources (CrossRef, PubMed, arXiv), validating citation information, and generating properly formatted BibTeX entries.\n\nCritical for maintaining citation accuracy, avoiding reference errors, and ensuring reproducible research. Integrates seamlessly with the literature-review skill for comprehensive research workflows.\n\n## When to Use This Skill\n\nUse this skill when:\n- Searching for specific papers on Google Scholar or PubMed\n- Converting DOIs, PMIDs, or arXiv IDs to properly formatted BibTeX\n- Extracting complete metadata for citations (authors, title, journal, year, etc.)\n- Validating existing citations for accuracy\n- Cleaning and formatting BibTeX files\n- Finding highly cited papers in a specific field\n- Verifying that citation information matches the actual publication\n- Building a bibliography for a manuscript or thesis\n- Checking for duplicate citations\n- Ensuring consistent citation formatting\n\n## Visual Enhancement with Scientific Schematics\n\n**When creating documents with this skill, always consider adding scientific diagrams and schematics to enhance visual communication.**\n\nIf your document does not already contain schematics or diagrams:\n- Use the **scientific-schematics** skill to generate AI-powered publication-quality diagrams\n- Simply describe your desired diagram in natural language\n- Nano Banana Pro will automatically generate, review, and refine the schematic\n\n**For new documents:** Scientific schematics should be generated by default to visually represent key concepts, workflows, architectures, or relationships described in the text.\n\n**How to generate schematics:**\n```bash\npython scripts/generate_schematic.py \"your diagram description\" -o figures/output.png\n```\n\nThe AI will automatically:\n- Crea"
  },
  {
    "id": "cirq",
    "name": "cirq",
    "description": "Quantum computing framework for building, simulating, optimizing, and executing quantum circuits. Use this skill when working with quantum algorithms, quantum circuit design, quantum simulation (noiseless or noisy), running on quantum hardware (Google, IonQ, AQT, Pasqal), circuit optimization and co",
    "category": "physics-materials",
    "source": "scientific",
    "triggers": [
      "cirq",
      "quantum",
      "circuit",
      "benchmarking",
      "computing",
      "simulating",
      "optimizing",
      "executing",
      "circuits",
      "algorithms"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/cirq",
    "fullDescription": "\n# Cirq - Quantum Computing with Python\n\nCirq is Google Quantum AI's open-source framework for designing, simulating, and running quantum circuits on quantum computers and simulators.\n\n## Installation\n\n```bash\nuv pip install cirq\n```\n\nFor hardware integration:\n```bash\n# Google Quantum Engine\nuv pip install cirq-google\n\n# IonQ\nuv pip install cirq-ionq\n\n# AQT (Alpine Quantum Technologies)\nuv pip install cirq-aqt\n\n# Pasqal\nuv pip install cirq-pasqal\n\n# Azure Quantum\nuv pip install azure-quantum cirq\n```\n\n## Quick Start\n\n### Basic Circuit\n\n```python\nimport cirq\nimport numpy as np\n\n# Create qubits\nq0, q1 = cirq.LineQubit.range(2)\n\n# Build circuit\ncircuit = cirq.Circuit(\n    cirq.H(q0),              # Hadamard on q0\n    cirq.CNOT(q0, q1),       # CNOT with q0 control, q1 target\n    cirq.measure(q0, q1, key='result')\n)\n\nprint(circuit)\n\n# Simulate\nsimulator = cirq.Simulator()\nresult = simulator.run(circuit, repetitions=1000)\n\n# Display results\nprint(result.histogram(key='result'))\n```\n\n### Parameterized Circuit\n\n```python\nimport sympy\n\n# Define symbolic parameter\ntheta = sympy.Symbol('theta')\n\n# Create parameterized circuit\ncircuit = cirq.Circuit(\n    cirq.ry(theta)(q0),\n    cirq.measure(q0, key='m')\n)\n\n# Sweep over parameter values\nsweep = cirq.Linspace('theta', start=0, stop=2*np.pi, length=20)\nresults = simulator.run_sweep(circuit, params=sweep, repetitions=1000)\n\n# Process results\nfor params, result in zip(sweep, results):\n    theta_val = params['theta']\n    counts = result.histogram(key='m')\n    print(f\"Î¸={theta_val:.2f}: {counts}\")\n```\n\n## Core Capabilities\n\n### Circuit Building\nFor comprehensive information about building quantum circuits, including qubits, gates, operations, custom gates, and circuit patterns, see:\n- **[references/building.md](references/building.md)** - Complete guide to circuit construction\n\nCommon topics:\n- Qubit types (GridQubit, LineQubit, NamedQubit)\n- Single and two-qubit gates\n- Parameterized gates and operations\n- Custom gate decomposition\n"
  },
  {
    "id": "clinical-reports",
    "name": "clinical-reports",
    "description": "Write comprehensive clinical reports including case reports (CARE guidelines), diagnostic reports (radiology/pathology/lab), clinical trial reports (ICH-E3, SAE, CSR), and patient documentation (SOAP, H&P, discharge summaries). Full support with templates, regulatory compliance (HIPAA, FDA, ICH-GCP)",
    "category": "clinical",
    "source": "scientific",
    "triggers": [
      "clinical",
      "reports",
      "write",
      "case",
      "care",
      "guidelines",
      "diagnostic",
      "radiology",
      "pathology",
      "lab"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/clinical-reports",
    "fullDescription": "\n# Clinical Report Writing\n\n## Overview\n\nClinical report writing is the process of documenting medical information with precision, accuracy, and compliance with regulatory standards. This skill covers four major categories of clinical reports: case reports for journal publication, diagnostic reports for clinical practice, clinical trial reports for regulatory submission, and patient documentation for medical records. Apply this skill for healthcare documentation, research dissemination, and regulatory compliance.\n\n**Critical Principle: Clinical reports must be accurate, complete, objective, and compliant with applicable regulations (HIPAA, FDA, ICH-GCP).** Patient privacy and data integrity are paramount. All clinical documentation must support evidence-based decision-making and meet professional standards.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Writing clinical case reports for journal submission (CARE guidelines)\n- Creating diagnostic reports (radiology, pathology, laboratory)\n- Documenting clinical trial data and adverse events\n- Preparing clinical study reports (CSR) for regulatory submission\n- Writing patient progress notes, SOAP notes, and clinical summaries\n- Drafting discharge summaries, H&P documents, or consultation notes\n- Ensuring HIPAA compliance and proper de-identification\n- Validating clinical documentation for completeness and accuracy\n- Preparing serious adverse event (SAE) reports\n- Creating data safety monitoring board (DSMB) reports\n\n## Visual Enhancement with Scientific Schematics\n\n**âš ï¸ MANDATORY: Every clinical report MUST include at least 1 AI-generated figure using the scientific-schematics skill.**\n\nThis is not optional. Clinical reports benefit greatly from visual elements. Before finalizing any document:\n1. Generate at minimum ONE schematic or diagram (e.g., patient timeline, diagnostic algorithm, or treatment workflow)\n2. For case reports: include clinical progression timeline\n3. For trial reports: include CONSORT "
  },
  {
    "id": "brenda-database",
    "name": "brenda-database",
    "description": "Access BRENDA enzyme database via SOAP API. Retrieve kinetic parameters (Km, kcat), reaction equations, organism data, and substrate-specific enzyme information for biochemical research and metabolic pathway analysis.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "brenda",
      "enzyme",
      "via",
      "soap",
      "retrieve",
      "kinetic",
      "parameters",
      "kcat",
      "reaction",
      "equations"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/brenda-database",
    "fullDescription": "\n# BRENDA Database\n\n## Overview\n\nBRENDA (BRaunschweig ENzyme DAtabase) is the world's most comprehensive enzyme information system, containing detailed enzyme data from scientific literature. Query kinetic parameters (Km, kcat), reaction equations, substrate specificities, organism information, and optimal conditions for enzymes using the official SOAP API. Access over 45,000 enzymes with millions of kinetic data points for biochemical research, metabolic engineering, and enzyme discovery.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Searching for enzyme kinetic parameters (Km, kcat, Vmax)\n- Retrieving reaction equations and stoichiometry\n- Finding enzymes for specific substrates or reactions\n- Comparing enzyme properties across different organisms\n- Investigating optimal pH, temperature, and conditions\n- Accessing enzyme inhibition and activation data\n- Supporting metabolic pathway reconstruction and retrosynthesis\n- Performing enzyme engineering and optimization studies\n- Analyzing substrate specificity and cofactor requirements\n\n## Core Capabilities\n\n### 1. Kinetic Parameter Retrieval\n\nAccess comprehensive kinetic data for enzymes:\n\n**Get Km Values by EC Number**:\n```python\nfrom brenda_client import get_km_values\n\n# Get Km values for all organisms\nkm_data = get_km_values(\"1.1.1.1\")  # Alcohol dehydrogenase\n\n# Get Km values for specific organism\nkm_data = get_km_values(\"1.1.1.1\", organism=\"Saccharomyces cerevisiae\")\n\n# Get Km values for specific substrate\nkm_data = get_km_values(\"1.1.1.1\", substrate=\"ethanol\")\n```\n\n**Parse Km Results**:\n```python\nfor entry in km_data:\n    print(f\"Km: {entry}\")\n    # Example output: \"organism*Homo sapiens#substrate*ethanol#kmValue*1.2#commentary*\"\n```\n\n**Extract Specific Information**:\n```python\nfrom scripts.brenda_queries import parse_km_entry, extract_organism_data\n\nfor entry in km_data:\n    parsed = parse_km_entry(entry)\n    organism = extract_organism_data(entry)\n    print(f\"Organism: {parsed['organism']}\")\n   "
  },
  {
    "id": "cellxgene-census",
    "name": "cellxgene-census",
    "description": "Query CZ CELLxGENE Census (61M+ cells). Filter by cell type/tissue/disease, retrieve expression data, integrate with scanpy/PyTorch, for population-scale single-cell analysis.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "cellxgene",
      "census",
      "61m",
      "cells",
      "filter",
      "cell",
      "type",
      "tissue",
      "disease",
      "retrieve"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/cellxgene-census",
    "fullDescription": "\n# CZ CELLxGENE Census\n\n## Overview\n\nThe CZ CELLxGENE Census provides programmatic access to a comprehensive, versioned collection of standardized single-cell genomics data from CZ CELLxGENE Discover. This skill enables efficient querying and analysis of millions of cells across thousands of datasets.\n\nThe Census includes:\n- **61+ million cells** from human and mouse\n- **Standardized metadata** (cell types, tissues, diseases, donors)\n- **Raw gene expression** matrices\n- **Pre-calculated embeddings** and statistics\n- **Integration with PyTorch, scanpy, and other analysis tools**\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Querying single-cell expression data by cell type, tissue, or disease\n- Exploring available single-cell datasets and metadata\n- Training machine learning models on single-cell data\n- Performing large-scale cross-dataset analyses\n- Integrating Census data with scanpy or other analysis frameworks\n- Computing statistics across millions of cells\n- Accessing pre-calculated embeddings or model predictions\n\n## Installation and Setup\n\nInstall the Census API:\n```bash\nuv pip install cellxgene-census\n```\n\nFor machine learning workflows, install additional dependencies:\n```bash\nuv pip install cellxgene-census[experimental]\n```\n\n## Core Workflow Patterns\n\n### 1. Opening the Census\n\nAlways use the context manager to ensure proper resource cleanup:\n\n```python\nimport cellxgene_census\n\n# Open latest stable version\nwith cellxgene_census.open_soma() as census:\n    # Work with census data\n\n# Open specific version for reproducibility\nwith cellxgene_census.open_soma(census_version=\"2023-07-25\") as census:\n    # Work with census data\n```\n\n**Key points:**\n- Use context manager (`with` statement) for automatic cleanup\n- Specify `census_version` for reproducible analyses\n- Default opens latest \"stable\" release\n\n### 2. Exploring Census Information\n\nBefore querying expression data, explore available datasets and metadata.\n\n**Access summary information:**\n```p"
  },
  {
    "id": "biopython",
    "name": "biopython",
    "description": "Primary Python toolkit for molecular biology. Preferred for Python-based PubMed/NCBI queries (Bio.Entrez), sequence manipulation, file parsing (FASTA, GenBank, FASTQ, PDB), advanced BLAST workflows, structures, phylogenetics. For quick BLAST, use gget. For direct REST API, use pubmed-database.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "biopython",
      "blast",
      "primary",
      "molecular",
      "biology",
      "preferred",
      "python-based",
      "pubmed",
      "ncbi",
      "queries"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/biopython",
    "fullDescription": "\n# Biopython: Computational Molecular Biology in Python\n\n## Overview\n\nBiopython is a comprehensive set of freely available Python tools for biological computation. It provides functionality for sequence manipulation, file I/O, database access, structural bioinformatics, phylogenetics, and many other bioinformatics tasks. The current version is **Biopython 1.85** (released January 2025), which supports Python 3 and requires NumPy.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Working with biological sequences (DNA, RNA, or protein)\n- Reading, writing, or converting biological file formats (FASTA, GenBank, FASTQ, PDB, mmCIF, etc.)\n- Accessing NCBI databases (GenBank, PubMed, Protein, Gene, etc.) via Entrez\n- Running BLAST searches or parsing BLAST results\n- Performing sequence alignments (pairwise or multiple sequence alignments)\n- Analyzing protein structures from PDB files\n- Creating, manipulating, or visualizing phylogenetic trees\n- Finding sequence motifs or analyzing motif patterns\n- Calculating sequence statistics (GC content, molecular weight, melting temperature, etc.)\n- Performing structural bioinformatics tasks\n- Working with population genetics data\n- Any other computational molecular biology task\n\n## Core Capabilities\n\nBiopython is organized into modular sub-packages, each addressing specific bioinformatics domains:\n\n1. **Sequence Handling** - Bio.Seq and Bio.SeqIO for sequence manipulation and file I/O\n2. **Alignment Analysis** - Bio.Align and Bio.AlignIO for pairwise and multiple sequence alignments\n3. **Database Access** - Bio.Entrez for programmatic access to NCBI databases\n4. **BLAST Operations** - Bio.Blast for running and parsing BLAST searches\n5. **Structural Bioinformatics** - Bio.PDB for working with 3D protein structures\n6. **Phylogenetics** - Bio.Phylo for phylogenetic tree manipulation and visualization\n7. **Advanced Features** - Motifs, population genetics, sequence utilities, and more\n\n## Installation and Setup\n\nInstall Biopython using"
  },
  {
    "id": "bioservices",
    "name": "bioservices",
    "description": "Primary Python tool for 40+ bioinformatics services. Preferred for multi-database workflows: UniProt, KEGG, ChEMBL, PubChem, Reactome, QuickGO. Unified API for queries, ID mapping, pathway analysis. For direct REST control, use individual database skills (uniprot-database, kegg-database).",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "bioservices",
      "primary",
      "tool",
      "bioinformatics",
      "services",
      "preferred",
      "multi-database",
      "workflows",
      "uniprot",
      "kegg"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/bioservices",
    "fullDescription": "\n# BioServices\n\n## Overview\n\nBioServices is a Python package providing programmatic access to approximately 40 bioinformatics web services and databases. Retrieve biological data, perform cross-database queries, map identifiers, analyze sequences, and integrate multiple biological resources in Python workflows. The package handles both REST and SOAP/WSDL protocols transparently.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Retrieving protein sequences, annotations, or structures from UniProt, PDB, Pfam\n- Analyzing metabolic pathways and gene functions via KEGG or Reactome\n- Searching compound databases (ChEBI, ChEMBL, PubChem) for chemical information\n- Converting identifiers between different biological databases (KEGGâ†”UniProt, compound IDs)\n- Running sequence similarity searches (BLAST, MUSCLE alignment)\n- Querying gene ontology terms (QuickGO, GO annotations)\n- Accessing protein-protein interaction data (PSICQUIC, IntactComplex)\n- Mining genomic data (BioMart, ArrayExpress, ENA)\n- Integrating data from multiple bioinformatics resources in a single workflow\n\n## Core Capabilities\n\n### 1. Protein Analysis\n\nRetrieve protein information, sequences, and functional annotations:\n\n```python\nfrom bioservices import UniProt\n\nu = UniProt(verbose=False)\n\n# Search for protein by name\nresults = u.search(\"ZAP70_HUMAN\", frmt=\"tab\", columns=\"id,genes,organism\")\n\n# Retrieve FASTA sequence\nsequence = u.retrieve(\"P43403\", \"fasta\")\n\n# Map identifiers between databases\nkegg_ids = u.mapping(fr=\"UniProtKB_AC-ID\", to=\"KEGG\", query=\"P43403\")\n```\n\n**Key methods:**\n- `search()`: Query UniProt with flexible search terms\n- `retrieve()`: Get protein entries in various formats (FASTA, XML, tab)\n- `mapping()`: Convert identifiers between databases\n\nReference: `references/services_reference.md` for complete UniProt API details.\n\n### 2. Pathway Discovery and Analysis\n\nAccess KEGG pathway information for genes and organisms:\n\n```python\nfrom bioservices import KEGG\n\nk = KEGG()\nk.orga"
  },
  {
    "id": "chembl-database",
    "name": "chembl-database",
    "description": "Query ChEMBL's bioactive molecules and drug discovery data. Search compounds by structure/properties, retrieve bioactivity data (IC50, Ki), find inhibitors, perform SAR studies, for medicinal chemistry.",
    "category": "cheminformatics",
    "source": "scientific",
    "triggers": [
      "chembl",
      "bioactive",
      "molecules",
      "drug",
      "discovery",
      "compounds",
      "structure",
      "properties",
      "retrieve",
      "bioactivity"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/chembl-database",
    "fullDescription": "\n# ChEMBL Database\n\n## Overview\n\nChEMBL is a manually curated database of bioactive molecules maintained by the European Bioinformatics Institute (EBI), containing over 2 million compounds, 19 million bioactivity measurements, 13,000+ drug targets, and data on approved drugs and clinical candidates. Access and query this data programmatically using the ChEMBL Python client for drug discovery and medicinal chemistry research.\n\n## When to Use This Skill\n\nThis skill should be used when:\n\n- **Compound searches**: Finding molecules by name, structure, or properties\n- **Target information**: Retrieving data about proteins, enzymes, or biological targets\n- **Bioactivity data**: Querying IC50, Ki, EC50, or other activity measurements\n- **Drug information**: Looking up approved drugs, mechanisms, or indications\n- **Structure searches**: Performing similarity or substructure searches\n- **Cheminformatics**: Analyzing molecular properties and drug-likeness\n- **Target-ligand relationships**: Exploring compound-target interactions\n- **Drug discovery**: Identifying inhibitors, agonists, or bioactive molecules\n\n## Installation and Setup\n\n### Python Client\n\nThe ChEMBL Python client is required for programmatic access:\n\n```bash\nuv pip install chembl_webresource_client\n```\n\n### Basic Usage Pattern\n\n```python\nfrom chembl_webresource_client.new_client import new_client\n\n# Access different endpoints\nmolecule = new_client.molecule\ntarget = new_client.target\nactivity = new_client.activity\ndrug = new_client.drug\n```\n\n## Core Capabilities\n\n### 1. Molecule Queries\n\n**Retrieve by ChEMBL ID:**\n```python\nmolecule = new_client.molecule\naspirin = molecule.get('CHEMBL25')\n```\n\n**Search by name:**\n```python\nresults = molecule.filter(pref_name__icontains='aspirin')\n```\n\n**Filter by properties:**\n```python\n# Find small molecules (MW <= 500) with favorable LogP\nresults = molecule.filter(\n    molecule_properties__mw_freebase__lte=500,\n    molecule_properties__alogp__lte=5\n)\n```\n\n### 2. Target Queries\n\n*"
  },
  {
    "id": "biorxiv-database",
    "name": "biorxiv-database",
    "description": "Efficient database search tool for bioRxiv preprint server. Use this skill when searching for life sciences preprints by keywords, authors, date ranges, or categories, retrieving paper metadata, downloading PDFs, or conducting literature reviews.",
    "category": "sci-databases",
    "source": "scientific",
    "triggers": [
      "biorxiv",
      "efficient",
      "tool",
      "preprint",
      "server",
      "searching",
      "life",
      "sciences",
      "preprints",
      "keywords"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/biorxiv-database",
    "fullDescription": "\n# bioRxiv Database\n\n## Overview\n\nThis skill provides efficient Python-based tools for searching and retrieving preprints from the bioRxiv database. It enables comprehensive searches by keywords, authors, date ranges, and categories, returning structured JSON metadata that includes titles, abstracts, DOIs, and citation information. The skill also supports PDF downloads for full-text analysis.\n\n## When to Use This Skill\n\nUse this skill when:\n- Searching for recent preprints in specific research areas\n- Tracking publications by particular authors\n- Conducting systematic literature reviews\n- Analyzing research trends over time periods\n- Retrieving metadata for citation management\n- Downloading preprint PDFs for analysis\n- Filtering papers by bioRxiv subject categories\n\n## Core Search Capabilities\n\n### 1. Keyword Search\n\nSearch for preprints containing specific keywords in titles, abstracts, or author lists.\n\n**Basic Usage:**\n```python\npython scripts/biorxiv_search.py \\\n  --keywords \"CRISPR\" \"gene editing\" \\\n  --start-date 2024-01-01 \\\n  --end-date 2024-12-31 \\\n  --output results.json\n```\n\n**With Category Filter:**\n```python\npython scripts/biorxiv_search.py \\\n  --keywords \"neural networks\" \"deep learning\" \\\n  --days-back 180 \\\n  --category neuroscience \\\n  --output recent_neuroscience.json\n```\n\n**Search Fields:**\nBy default, keywords are searched in both title and abstract. Customize with `--search-fields`:\n```python\npython scripts/biorxiv_search.py \\\n  --keywords \"AlphaFold\" \\\n  --search-fields title \\\n  --days-back 365\n```\n\n### 2. Author Search\n\nFind all papers by a specific author within a date range.\n\n**Basic Usage:**\n```python\npython scripts/biorxiv_search.py \\\n  --author \"Smith\" \\\n  --start-date 2023-01-01 \\\n  --end-date 2024-12-31 \\\n  --output smith_papers.json\n```\n\n**Recent Publications:**\n```python\n# Last year by default if no dates specified\npython scripts/biorxiv_search.py \\\n  --author \"Johnson\" \\\n  --output johnson_recent.json\n```\n\n### 3. Date Range Search\n\n"
  },
  {
    "id": "biomni",
    "name": "biomni",
    "description": "Autonomous biomedical AI agent framework for executing complex research tasks across genomics, drug discovery, molecular biology, and clinical analysis. Use this skill when conducting multi-step biomedical research including CRISPR screening design, single-cell RNA-seq analysis, ADMET prediction, GW",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "biomni",
      "biomedical",
      "autonomous",
      "agent",
      "executing",
      "complex",
      "tasks",
      "across",
      "genomics",
      "drug"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/biomni",
    "fullDescription": "\n# Biomni\n\n## Overview\n\nBiomni is an open-source biomedical AI agent framework from Stanford's SNAP lab that autonomously executes complex research tasks across biomedical domains. Use this skill when working on multi-step biological reasoning tasks, analyzing biomedical data, or conducting research spanning genomics, drug discovery, molecular biology, and clinical analysis.\n\n## Core Capabilities\n\nBiomni excels at:\n\n1. **Multi-step biological reasoning** - Autonomous task decomposition and planning for complex biomedical queries\n2. **Code generation and execution** - Dynamic analysis pipeline creation for data processing\n3. **Knowledge retrieval** - Access to ~11GB of integrated biomedical databases and literature\n4. **Cross-domain problem solving** - Unified interface for genomics, proteomics, drug discovery, and clinical tasks\n\n## When to Use This Skill\n\nUse biomni for:\n- **CRISPR screening** - Design screens, prioritize genes, analyze knockout effects\n- **Single-cell RNA-seq** - Cell type annotation, differential expression, trajectory analysis\n- **Drug discovery** - ADMET prediction, target identification, compound optimization\n- **GWAS analysis** - Variant interpretation, causal gene identification, pathway enrichment\n- **Clinical genomics** - Rare disease diagnosis, variant pathogenicity, phenotype-genotype mapping\n- **Lab protocols** - Protocol optimization, literature synthesis, experimental design\n\n## Quick Start\n\n### Installation and Setup\n\nInstall Biomni and configure API keys for LLM providers:\n\n```bash\nuv pip install biomni --upgrade\n```\n\nConfigure API keys (store in `.env` file or environment variables):\n```bash\nexport ANTHROPIC_API_KEY=\"your-key-here\"\n# Optional: OpenAI, Azure, Google, Groq, AWS Bedrock keys\n```\n\nUse `scripts/setup_environment.py` for interactive setup assistance.\n\n### Basic Usage Pattern\n\n```python\nfrom biomni.agent import A1\n\n# Initialize agent with data path and LLM choice\nagent = A1(path='./data', llm='claude-sonnet-4-20250514')\n\n"
  },
  {
    "id": "astropy",
    "name": "astropy",
    "description": "Comprehensive Python library for astronomy and astrophysics. This skill should be used when working with astronomical data including celestial coordinates, physical units, FITS files, cosmological calculations, time systems, tables, world coordinate systems (WCS), and astronomical data analysis. Use",
    "category": "scientific",
    "source": "scientific",
    "triggers": [
      "astropy",
      "astronomical",
      "fits",
      "cosmological",
      "calculations",
      "time",
      "systems",
      "coordinate",
      "conversions",
      "library"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/astropy",
    "fullDescription": "\n# Astropy\n\n## Overview\n\nAstropy is the core Python package for astronomy, providing essential functionality for astronomical research and data analysis. Use astropy for coordinate transformations, unit and quantity calculations, FITS file operations, cosmological calculations, precise time handling, tabular data manipulation, and astronomical image processing.\n\n## When to Use This Skill\n\nUse astropy when tasks involve:\n- Converting between celestial coordinate systems (ICRS, Galactic, FK5, AltAz, etc.)\n- Working with physical units and quantities (converting Jy to mJy, parsecs to km, etc.)\n- Reading, writing, or manipulating FITS files (images or tables)\n- Cosmological calculations (luminosity distance, lookback time, Hubble parameter)\n- Precise time handling with different time scales (UTC, TAI, TT, TDB) and formats (JD, MJD, ISO)\n- Table operations (reading catalogs, cross-matching, filtering, joining)\n- WCS transformations between pixel and world coordinates\n- Astronomical constants and calculations\n\n## Quick Start\n\n```python\nimport astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom astropy.time import Time\nfrom astropy.io import fits\nfrom astropy.table import Table\nfrom astropy.cosmology import Planck18\n\n# Units and quantities\ndistance = 100 * u.pc\ndistance_km = distance.to(u.km)\n\n# Coordinates\ncoord = SkyCoord(ra=10.5*u.degree, dec=41.2*u.degree, frame='icrs')\ncoord_galactic = coord.galactic\n\n# Time\nt = Time('2023-01-15 12:30:00')\njd = t.jd  # Julian Date\n\n# FITS files\ndata = fits.getdata('image.fits')\nheader = fits.getheader('image.fits')\n\n# Tables\ntable = Table.read('catalog.fits')\n\n# Cosmology\nd_L = Planck18.luminosity_distance(z=1.0)\n```\n\n## Core Capabilities\n\n### 1. Units and Quantities (`astropy.units`)\n\nHandle physical quantities with units, perform unit conversions, and ensure dimensional consistency in calculations.\n\n**Key operations:**\n- Create quantities by multiplying values with units\n- Convert between units using `.to()` method\n- Pe"
  },
  {
    "id": "benchling-integration",
    "name": "benchling-integration",
    "description": "Benchling R&D platform integration. Access registry (DNA, proteins), inventory, ELN entries, workflows via API, build Benchling Apps, query Data Warehouse, for lab data management automation.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "benchling",
      "integration",
      "registry",
      "dna",
      "proteins",
      "inventory",
      "eln",
      "entries",
      "workflows",
      "via"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/benchling-integration",
    "fullDescription": "\n# Benchling Integration\n\n## Overview\n\nBenchling is a cloud platform for life sciences R&D. Access registry entities (DNA, proteins), inventory, electronic lab notebooks, and workflows programmatically via Python SDK and REST API.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Working with Benchling's Python SDK or REST API\n- Managing biological sequences (DNA, RNA, proteins) and registry entities\n- Automating inventory operations (samples, containers, locations, transfers)\n- Creating or querying electronic lab notebook entries\n- Building workflow automations or Benchling Apps\n- Syncing data between Benchling and external systems\n- Querying the Benchling Data Warehouse for analytics\n- Setting up event-driven integrations with AWS EventBridge\n\n## Core Capabilities\n\n### 1. Authentication & Setup\n\n**Python SDK Installation:**\n```python\n# Stable release\nuv pip install benchling-sdk\n# or with Poetry\npoetry add benchling-sdk\n```\n\n**Authentication Methods:**\n\nAPI Key Authentication (recommended for scripts):\n```python\nfrom benchling_sdk.benchling import Benchling\nfrom benchling_sdk.auth.api_key_auth import ApiKeyAuth\n\nbenchling = Benchling(\n    url=\"https://your-tenant.benchling.com\",\n    auth_method=ApiKeyAuth(\"your_api_key\")\n)\n```\n\nOAuth Client Credentials (for apps):\n```python\nfrom benchling_sdk.auth.client_credentials_oauth2 import ClientCredentialsOAuth2\n\nauth_method = ClientCredentialsOAuth2(\n    client_id=\"your_client_id\",\n    client_secret=\"your_client_secret\"\n)\nbenchling = Benchling(\n    url=\"https://your-tenant.benchling.com\",\n    auth_method=auth_method\n)\n```\n\n**Key Points:**\n- API keys are obtained from Profile Settings in Benchling\n- Store credentials securely (use environment variables or password managers)\n- All API requests require HTTPS\n- Authentication permissions mirror user permissions in the UI\n\nFor detailed authentication information including OIDC and security best practices, refer to `references/authentication.md`.\n\n### 2. Registry & "
  },
  {
    "id": "anndata",
    "name": "anndata",
    "description": "This skill should be used when working with annotated data matrices in Python, particularly for single-cell genomics analysis, managing experimental measurements with metadata, or handling large-scale biological datasets. Use when tasks involve AnnData objects, h5ad files, single-cell RNA-seq data, ",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "anndata",
      "single-cell",
      "annotated",
      "matrices",
      "particularly",
      "genomics",
      "managing",
      "experimental",
      "measurements",
      "metadata"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/anndata",
    "fullDescription": "\n# AnnData\n\n## Overview\n\nAnnData is a Python package for handling annotated data matrices, storing experimental measurements (X) alongside observation metadata (obs), variable metadata (var), and multi-dimensional annotations (obsm, varm, obsp, varp, uns). Originally designed for single-cell genomics through Scanpy, it now serves as a general-purpose framework for any annotated data requiring efficient storage, manipulation, and analysis.\n\n## When to Use This Skill\n\nUse this skill when:\n- Creating, reading, or writing AnnData objects\n- Working with h5ad, zarr, or other genomics data formats\n- Performing single-cell RNA-seq analysis\n- Managing large datasets with sparse matrices or backed mode\n- Concatenating multiple datasets or experimental batches\n- Subsetting, filtering, or transforming annotated data\n- Integrating with scanpy, scvi-tools, or other scverse ecosystem tools\n\n## Installation\n\n```bash\nuv pip install anndata\n\n# With optional dependencies\nuv pip install anndata[dev,test,doc]\n```\n\n## Quick Start\n\n### Creating an AnnData object\n```python\nimport anndata as ad\nimport numpy as np\nimport pandas as pd\n\n# Minimal creation\nX = np.random.rand(100, 2000)  # 100 cells Ã— 2000 genes\nadata = ad.AnnData(X)\n\n# With metadata\nobs = pd.DataFrame({\n    'cell_type': ['T cell', 'B cell'] * 50,\n    'sample': ['A', 'B'] * 50\n}, index=[f'cell_{i}' for i in range(100)])\n\nvar = pd.DataFrame({\n    'gene_name': [f'Gene_{i}' for i in range(2000)]\n}, index=[f'ENSG{i:05d}' for i in range(2000)])\n\nadata = ad.AnnData(X=X, obs=obs, var=var)\n```\n\n### Reading data\n```python\n# Read h5ad file\nadata = ad.read_h5ad('data.h5ad')\n\n# Read with backed mode (for large files)\nadata = ad.read_h5ad('large_data.h5ad', backed='r')\n\n# Read other formats\nadata = ad.read_csv('data.csv')\nadata = ad.read_loom('data.loom')\nadata = ad.read_10x_h5('filtered_feature_bc_matrix.h5')\n```\n\n### Writing data\n```python\n# Write h5ad file\nadata.write_h5ad('output.h5ad')\n\n# Write with compression\nadata.write_h5ad('output."
  },
  {
    "id": "adaptyv",
    "name": "adaptyv",
    "description": "Cloud laboratory platform for automated protein testing and validation. Use when designing proteins and needing experimental validation including binding assays, expression testing, thermostability measurements, enzyme activity assays, or protein sequence optimization. Also use for submitting experi",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "adaptyv",
      "protein",
      "validation",
      "testing",
      "assays",
      "expression",
      "cloud",
      "laboratory",
      "automated",
      "designing"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/adaptyv",
    "fullDescription": "\n# Adaptyv\n\nAdaptyv is a cloud laboratory platform that provides automated protein testing and validation services. Submit protein sequences via API or web interface and receive experimental results in approximately 21 days.\n\n## Quick Start\n\n### Authentication Setup\n\nAdaptyv requires API authentication. Set up your credentials:\n\n1. Contact support@adaptyvbio.com to request API access (platform is in alpha/beta)\n2. Receive your API access token\n3. Set environment variable:\n\n```bash\nexport ADAPTYV_API_KEY=\"your_api_key_here\"\n```\n\nOr create a `.env` file:\n\n```\nADAPTYV_API_KEY=your_api_key_here\n```\n\n### Installation\n\nInstall the required package using uv:\n\n```bash\nuv pip install requests python-dotenv\n```\n\n### Basic Usage\n\nSubmit protein sequences for testing:\n\n```python\nimport os\nimport requests\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv(\"ADAPTYV_API_KEY\")\nbase_url = \"https://kq5jp7qj7wdqklhsxmovkzn4l40obksv.lambda-url.eu-central-1.on.aws\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Submit experiment\nresponse = requests.post(\n    f\"{base_url}/experiments\",\n    headers=headers,\n    json={\n        \"sequences\": \">protein1\\nMKVLWALLGLLGAA...\",\n        \"experiment_type\": \"binding\",\n        \"webhook_url\": \"https://your-webhook.com/callback\"\n    }\n)\n\nexperiment_id = response.json()[\"experiment_id\"]\n```\n\n## Available Experiment Types\nAdaptyv supports multiple assay types:\n- **Binding assays** - Test protein-target interactions using biolayer interferometry\n- **Expression testing** - Measure protein expression levels\n- **Thermostability** - Characterize protein thermal stability\n- **Enzyme activity** - Assess enzymatic function\n\nSee `reference/experiments.md` for detailed information on each experiment type and workflows.\n\n## Protein Sequence Optimization\nBefore submitting sequences, optimize them for better expression and stability:\n\n**Common issues to address:**\n- Unpaired cysteines that create unw"
  },
  {
    "id": "alphafold-database",
    "name": "alphafold-database",
    "description": "Access AlphaFold's 200M+ AI-predicted protein structures. Retrieve structures by UniProt ID, download PDB/mmCIF files, analyze confidence metrics (pLDDT, PAE), for drug discovery and structural biology.",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "alphafold",
      "structures",
      "200m",
      "ai-predicted",
      "protein",
      "retrieve",
      "uniprot",
      "download",
      "pdb",
      "mmcif"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/alphafold-database",
    "fullDescription": "\n# AlphaFold Database\n\n## Overview\n\nAlphaFold DB is a public repository of AI-predicted 3D protein structures for over 200 million proteins, maintained by DeepMind and EMBL-EBI. Access structure predictions with confidence metrics, download coordinate files, retrieve bulk datasets, and integrate predictions into computational workflows.\n\n## When to Use This Skill\n\nThis skill should be used when working with AI-predicted protein structures in scenarios such as:\n\n- Retrieving protein structure predictions by UniProt ID or protein name\n- Downloading PDB/mmCIF coordinate files for structural analysis\n- Analyzing prediction confidence metrics (pLDDT, PAE) to assess reliability\n- Accessing bulk proteome datasets via Google Cloud Platform\n- Comparing predicted structures with experimental data\n- Performing structure-based drug discovery or protein engineering\n- Building structural models for proteins lacking experimental structures\n- Integrating AlphaFold predictions into computational pipelines\n\n## Core Capabilities\n\n### 1. Searching and Retrieving Predictions\n\n**Using Biopython (Recommended):**\n\nThe Biopython library provides the simplest interface for retrieving AlphaFold structures:\n\n```python\nfrom Bio.PDB import alphafold_db\n\n# Get all predictions for a UniProt accession\npredictions = list(alphafold_db.get_predictions(\"P00520\"))\n\n# Download structure file (mmCIF format)\nfor prediction in predictions:\n    cif_file = alphafold_db.download_cif_for(prediction, directory=\"./structures\")\n    print(f\"Downloaded: {cif_file}\")\n\n# Get Structure objects directly\nfrom Bio.PDB import MMCIFParser\nstructures = list(alphafold_db.get_structural_models_for(\"P00520\"))\n```\n\n**Direct API Access:**\n\nQuery predictions using REST endpoints:\n\n```python\nimport requests\n\n# Get prediction metadata for a UniProt accession\nuniprot_id = \"P00520\"\napi_url = f\"https://alphafold.ebi.ac.uk/api/prediction/{uniprot_id}\"\nresponse = requests.get(api_url)\nprediction_data = response.json()\n\n# Extract AlphaFol"
  },
  {
    "id": "aeon",
    "name": "aeon",
    "description": "This skill should be used for time series machine learning tasks including classification, regression, clustering, forecasting, anomaly detection, segmentation, and similarity search. Use when working with temporal data, sequential patterns, or time-indexed observations requiring specialized algorit",
    "category": "ml-ai",
    "source": "scientific",
    "triggers": [
      "aeon",
      "time",
      "series",
      "machine",
      "tasks",
      "classification",
      "regression",
      "clustering",
      "forecasting",
      "anomaly"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/aeon",
    "fullDescription": "\n# Aeon Time Series Machine Learning\n\n## Overview\n\nAeon is a scikit-learn compatible Python toolkit for time series machine learning. It provides state-of-the-art algorithms for classification, regression, clustering, forecasting, anomaly detection, segmentation, and similarity search.\n\n## When to Use This Skill\n\nApply this skill when:\n- Classifying or predicting from time series data\n- Detecting anomalies or change points in temporal sequences\n- Clustering similar time series patterns\n- Forecasting future values\n- Finding repeated patterns (motifs) or unusual subsequences (discords)\n- Comparing time series with specialized distance metrics\n- Extracting features from temporal data\n\n## Installation\n\n```bash\nuv pip install aeon\n```\n\n## Core Capabilities\n\n### 1. Time Series Classification\n\nCategorize time series into predefined classes. See `references/classification.md` for complete algorithm catalog.\n\n**Quick Start:**\n```python\nfrom aeon.classification.convolution_based import RocketClassifier\nfrom aeon.datasets import load_classification\n\n# Load data\nX_train, y_train = load_classification(\"GunPoint\", split=\"train\")\nX_test, y_test = load_classification(\"GunPoint\", split=\"test\")\n\n# Train classifier\nclf = RocketClassifier(n_kernels=10000)\nclf.fit(X_train, y_train)\naccuracy = clf.score(X_test, y_test)\n```\n\n**Algorithm Selection:**\n- **Speed + Performance**: `MiniRocketClassifier`, `Arsenal`\n- **Maximum Accuracy**: `HIVECOTEV2`, `InceptionTimeClassifier`\n- **Interpretability**: `ShapeletTransformClassifier`, `Catch22Classifier`\n- **Small Datasets**: `KNeighborsTimeSeriesClassifier` with DTW distance\n\n### 2. Time Series Regression\n\nPredict continuous values from time series. See `references/regression.md` for algorithms.\n\n**Quick Start:**\n```python\nfrom aeon.regression.convolution_based import RocketRegressor\nfrom aeon.datasets import load_regression\n\nX_train, y_train = load_regression(\"Covid3Month\", split=\"train\")\nX_test, y_test = load_regression(\"Covid3Month\", split=\"te"
  },
  {
    "id": "arboreto",
    "name": "arboreto",
    "description": "Infer gene regulatory networks (GRNs) from gene expression data using scalable algorithms (GRNBoost2, GENIE3). Use when analyzing transcriptomics data (bulk RNA-seq, single-cell RNA-seq) to identify transcription factor-target gene relationships and regulatory interactions. Supports distributed comp",
    "category": "bioinformatics",
    "source": "scientific",
    "triggers": [
      "arboreto",
      "gene",
      "regulatory",
      "rna-seq",
      "infer",
      "networks",
      "grns",
      "expression",
      "scalable",
      "algorithms"
    ],
    "path": "/Users/marovole/GitHub/fastskills/scientific-skills/scientific-skills/arboreto",
    "fullDescription": "\n# Arboreto\n\n## Overview\n\nArboreto is a computational library for inferring gene regulatory networks (GRNs) from gene expression data using parallelized algorithms that scale from single machines to multi-node clusters.\n\n**Core capability**: Identify which transcription factors (TFs) regulate which target genes based on expression patterns across observations (cells, samples, conditions).\n\n## Quick Start\n\nInstall arboreto:\n```bash\nuv pip install arboreto\n```\n\nBasic GRN inference:\n```python\nimport pandas as pd\nfrom arboreto.algo import grnboost2\n\nif __name__ == '__main__':\n    # Load expression data (genes as columns)\n    expression_matrix = pd.read_csv('expression_data.tsv', sep='\\t')\n\n    # Infer regulatory network\n    network = grnboost2(expression_data=expression_matrix)\n\n    # Save results (TF, target, importance)\n    network.to_csv('network.tsv', sep='\\t', index=False, header=False)\n```\n\n**Critical**: Always use `if __name__ == '__main__':` guard because Dask spawns new processes.\n\n## Core Capabilities\n\n### 1. Basic GRN Inference\n\nFor standard GRN inference workflows including:\n- Input data preparation (Pandas DataFrame or NumPy array)\n- Running inference with GRNBoost2 or GENIE3\n- Filtering by transcription factors\n- Output format and interpretation\n\n**See**: `references/basic_inference.md`\n\n**Use the ready-to-run script**: `scripts/basic_grn_inference.py` for standard inference tasks:\n```bash\npython scripts/basic_grn_inference.py expression_data.tsv output_network.tsv --tf-file tfs.txt --seed 777\n```\n\n### 2. Algorithm Selection\n\nArboreto provides two algorithms:\n\n**GRNBoost2 (Recommended)**:\n- Fast gradient boosting-based inference\n- Optimized for large datasets (10k+ observations)\n- Default choice for most analyses\n\n**GENIE3**:\n- Random Forest-based inference\n- Original multiple regression approach\n- Use for comparison or validation\n\nQuick comparison:\n```python\nfrom arboreto.algo import grnboost2, genie3\n\n# Fast, recommended\nnetwork_grnboost = grnboost2(expr"
  },
  {
    "id": "xlsx",
    "name": "xlsx",
    "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing dat",
    "category": "document",
    "source": "composio",
    "triggers": [
      "xlsx",
      "formulas",
      "spreadsheets",
      "formatting",
      "visualization",
      "spreadsheet",
      "creation",
      "editing",
      "claude",
      "needs"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/document-skills/xlsx",
    "fullDescription": "\n# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero value"
  },
  {
    "id": "docx",
    "name": "docx",
    "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tra",
    "category": "document",
    "source": "composio",
    "triggers": [
      "docx",
      "document",
      "editing",
      "tracked",
      "changes",
      "comments",
      "documents",
      "creation",
      "formatting",
      "preservation"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/document-skills/docx",
    "fullDescription": "\n# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTI"
  },
  {
    "id": "pptx",
    "name": "pptx",
    "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
    "category": "document",
    "source": "composio",
    "triggers": [
      "pptx",
      "presentation",
      "editing",
      "presentations",
      "creation",
      "claude",
      "needs",
      "work",
      "modifying",
      "content"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/document-skills/pptx",
    "fullDescription": "\n# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for pat"
  },
  {
    "id": "pdf",
    "name": "pdf",
    "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "category": "document",
    "source": "composio",
    "triggers": [
      "pdf",
      "documents",
      "manipulation",
      "extracting",
      "text",
      "tables",
      "pdfs",
      "merging",
      "splitting",
      "handling"
    ],
    "path": "/Users/marovole/GitHub/fastskills/composio-skills/document-skills/pdf",
    "fullDescription": "\n# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n    "
  },
  {
    "id": "modern-frontend-design",
    "name": "modern-frontend-design",
    "description": "Comprehensive frontend design system for creating distinctive, production-grade interfaces that avoid generic AI aesthetics. Use when users request web components, pages, applications, or any frontend interface. Provides design workflows, aesthetic guidelines, code patterns, animation libraries, typ",
    "category": "ml-ai",
    "source": "anthropic",
    "triggers": [
      "modern",
      "frontend",
      "design",
      "system",
      "distinctive",
      "production-grade",
      "interfaces",
      "avoid",
      "generic",
      "aesthetics"
    ],
    "path": "/Users/marovole/GitHub/fastskills/anthropic-skills/skills/modern-frontend-design",
    "fullDescription": "\n# Modern Frontend Design\n\nThis skill provides a comprehensive frontend design system for creating distinctive, production-grade interfaces that avoid generic \"AI slop\" aesthetics. It guides the creation of memorable, context-specific designs that feel genuinely crafted rather than generated.\n\n## Design Philosophy\n\n### Core Principles\n\n1. **Intentionality Over Defaults**\n   - Every design choice should be deliberate\n   - Avoid generic defaults (system fonts, standard colors, predictable layouts)\n   - Question \"why\" for every aesthetic decision\n\n2. **Context-Specific Design**\n   - Design for the specific use case, audience, and purpose\n   - Consider the brand identity, user needs, and functional requirements\n   - Create designs that are unique to the project, not generic templates\n\n3. **Production-Grade Quality**\n   - Implement working, functional code\n   - Ensure accessibility and responsiveness\n   - Focus on attention to detail in every element\n\n4. **Distinctive Aesthetics**\n   - Commit to bold, memorable visual directions\n   - Avoid cliched design patterns and overused visual elements\n   - Create designs that stand out and leave a lasting impression\n\n## Design Workflow\n\n### Step 1: Discovery and Context\n\nBefore starting any design work, gather information about:\n\n- **Purpose**: What problem does this interface solve? What is the core function?\n- **Audience**: Who are the users? What are their needs, preferences, and technical level?\n- **Tone**: What feeling should the interface convey? (e.g., professional, playful, luxurious, minimalist)\n- **Constraints**: Are there technical limitations? (e.g., framework requirements, performance budgets, accessibility standards)\n\n### Step 2: Conceptual Direction\n\nChoose a clear aesthetic vision and commit to it fully:\n\n- **Minimalist/Refined**: Clean lines, generous whitespace, subtle interactions, restrained color palette\n- **Bold/Maximalist**: Strong visual statements, vibrant colors, complex layouts, dramatic animations\n- **R"
  },
  {
    "id": "frontend-design",
    "name": "frontend-design",
    "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautify",
    "category": "ml-ai",
    "source": "anthropic",
    "triggers": [
      "frontend",
      "design",
      "web",
      "components",
      "pages",
      "distinctive",
      "production-grade",
      "interfaces",
      "high",
      "quality"
    ],
    "path": "/Users/marovole/GitHub/fastskills/anthropic-skills/skills/frontend-design",
    "fullDescription": "\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed p"
  },
  {
    "id": "web-artifacts-builder",
    "name": "web-artifacts-builder",
    "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
    "category": "ml-ai",
    "source": "anthropic",
    "triggers": [
      "web",
      "artifacts",
      "builder",
      "html",
      "shadcn",
      "suite",
      "tools",
      "elaborate",
      "multi-component",
      "claude"
    ],
    "path": "/Users/marovole/GitHub/fastskills/anthropic-skills/skills/web-artifacts-builder",
    "fullDescription": "\n# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- âœ… React + TypeScript (via Vite)\n- âœ… Tailwind CSS 3.4.1 with shadcn/ui theming system\n- âœ… Path aliases (`@/`) configured\n- âœ… 40+ shadcn/ui components pre-installed\n- âœ… All Radix UI dependencies included\n- âœ… Parcel configured for bundling (via .parcelrc)\n- âœ… Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inlin"
  },
  {
    "id": "algorithmic-art",
    "name": "algorithmic-art",
    "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avo",
    "category": "skill-dev",
    "source": "anthropic",
    "triggers": [
      "algorithmic",
      "art",
      "seeded",
      "randomness",
      "interactive",
      "parameter",
      "exploration",
      "users",
      "request",
      "code"
    ],
    "path": "/Users/marovole/GitHub/fastskills/anthropic-skills/skills/algorithmic-art",
    "fullDescription": "\nAlgorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**:"
  },
  {
    "id": "doc-coauthoring",
    "name": "doc-coauthoring",
    "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc",
    "category": "sci-communication",
    "source": "anthropic",
    "triggers": [
      "doc",
      "coauthoring",
      "documentation",
      "users",
      "structured",
      "workflow",
      "user",
      "proposals",
      "specs",
      "docs"
    ],
    "path": "/Users/marovole/GitHub/fastskills/anthropic-skills/skills/doc-coauthoring",
    "fullDescription": "\n# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fe"
  },
  {
    "id": "synthesizer",
    "name": "synthesizer",
    "description": "å°†å¤šä¸ªç ”ç©¶æ™ºèƒ½ä½“çš„å‘çŽ°ç»¼åˆæˆè¿žè´¯ã€ç»“æž„åŒ–çš„ç ”ç©¶æŠ¥å‘Šã€‚è§£å†³çŸ›ç›¾ã€æå–å…±è¯†ã€åˆ›å»ºç»Ÿä¸€å™è¿°ã€‚å½“å¤šä¸ªç ”ç©¶æ™ºèƒ½ä½“å®Œæˆç ”ç©¶ã€éœ€è¦å°†å‘çŽ°ç»„åˆæˆç»Ÿä¸€æŠ¥å‘Šã€å‘çŽ°ä¹‹é—´å­˜åœ¨çŸ›ç›¾æ—¶ä½¿ç”¨æ­¤æŠ€èƒ½ã€‚",
    "category": "ml-ai",
    "source": "unknown",
    "triggers": [
      "synthesizer"
    ],
    "path": "/Users/marovole/GitHub/fastskills/deep-research-skills/.claude/skills/synthesizer",
    "fullDescription": "\n# Synthesizer\n\n## Role\n\nYou are a **Research Synthesizer** responsible for combining findings from multiple research agents into a coherent, well-structured, and insightful research report.\n\n## Core Responsibilities\n\n1. **Integrate Findings**: Combine multiple research sources into unified content\n2. **Resolve Contradictions**: Identify and explain conflicting information\n3. **Extract Consensus**: Identify themes and conclusions supported by multiple sources\n4. **Create Narrative**: Build a logical flow from introduction to conclusions\n5. **Maintain Citations**: Preserve source attribution throughout synthesis\n6. **Identify Gaps**: Note what is still unknown or needs further research\n\n## Synthesis Process\n\n### Phase 1: Review and Organize\n\n- Review all research findings from agents\n- Identify common themes and topics\n- Note contradictions and discrepancies\n- Assess source quality and credibility\n- Group related findings together\n\n### Phase 2: Consensus Building\n\nFor each theme, identify:\n1. **Strong Consensus**: Findings supported by 3+ high-quality sources\n2. **Moderate Consensus**: Findings supported by 2 sources\n3. **Weak Consensus**: Findings from only 1 source\n4. **No Consensus**: Contradictory findings with no resolution\n\n### Phase 3: Contradiction Resolution\n\n**Types of Contradictions**:\n\n**Type A: Numerical Discrepancies**\n- Check publication dates, methodology, scope\n- Present range or explain discrepancy\n\n**Type B: Causal Claims**\n- Prioritize RCT over observational studies\n- Present as \"evidence suggests\" not \"proven\"\n\n**Type C: Temporal Changes**\n- Present as trend/growth\n- Use newer data for current state\n\n**Type D: Scope Differences**\n- Contextualize both findings\n- Explain conditions matter\n\n### Phase 4: Structured Synthesis\n\n**Report Structure**:\n```markdown\n# [Research Topic]: Comprehensive Report\n\n## Executive Summary\n## 1. Introduction\n## 2. [Theme 1] - Consensus Findings\n## 3. [Theme 2]\n## 4. [Theme with Contradictions] - Resolution\n## 5. Integr"
  },
  {
    "id": "research-executor",
    "name": "research-executor",
    "description": "æ‰§è¡Œå®Œæ•´çš„ 7 é˜¶æ®µæ·±åº¦ç ”ç©¶æµç¨‹ã€‚æŽ¥æ”¶ç»“æž„åŒ–ç ”ç©¶ä»»åŠ¡ï¼Œè‡ªåŠ¨éƒ¨ç½²å¤šä¸ªå¹¶è¡Œç ”ç©¶æ™ºèƒ½ä½“ï¼Œç”Ÿæˆå¸¦å®Œæ•´å¼•ç”¨çš„ç»¼åˆç ”ç©¶æŠ¥å‘Šã€‚å½“ç”¨æˆ·æœ‰ç»“æž„åŒ–çš„ç ”ç©¶æç¤ºè¯æ—¶ä½¿ç”¨æ­¤æŠ€èƒ½ã€‚",
    "category": "ml-ai",
    "source": "unknown",
    "triggers": [
      "executor",
      "research-executor"
    ],
    "path": "/Users/marovole/GitHub/fastskills/deep-research-skills/.claude/skills/research-executor",
    "fullDescription": "\n# Research Executor\n\n## Role\n\nYou are a **Deep Research Executor** responsible for conducting comprehensive, multi-phase research using the 7-stage deep research methodology and Graph of Thoughts (GoT) framework.\n\n## Core Responsibilities\n\n1. **Execute the 7-Phase Deep Research Process**\n2. **Deploy Multi-Agent Research Strategy**\n3. **Ensure Citation Accuracy and Quality**\n4. **Generate Structured Research Outputs**\n\n## The 7-Phase Deep Research Process\n\n### Phase 1: Question Scoping âœ“ (Already Done)\n\nVerify the structured prompt is complete and ask for clarification if any critical information is missing.\n\n### Phase 2: Retrieval Planning\n\nBreak down the main research question into actionable subtopics and create a research plan.\n\n**Actions**:\n1. Decompose the main question into 3-7 subtopics based on SPECIFIC_QUESTIONS\n2. Generate specific search queries for each subtopic\n3. Identify appropriate data sources based on CONSTRAINTS\n4. Create a research execution plan\n5. Present the plan for approval\n\n### Phase 3: Iterative Querying (Multi-Agent Execution)\n\nDeploy multiple Task agents in parallel to gather information from different sources.\n\n**Agent Types**:\n- **Web Research Agents (3-5 agents)**: Current information, trends, news, industry reports\n- **Academic/Technical Agent (1-2 agents)**: Research papers, technical specifications, methodologies\n- **Cross-Reference Agent (1 agent)**: Fact-checking and verification\n\n**Execution Protocol**: Launch ALL agents in a single response using multiple Task tool calls. Use `run_in_background: true` for long-running agents.\n\n### Phase 4: Source Triangulation\n\nCompare findings across multiple sources and validate claims.\n\n**Source Quality Ratings**:\n- **A**: Peer-reviewed RCTs, systematic reviews, meta-analyses\n- **B**: Cohort studies, case-control studies, clinical guidelines\n- **C**: Expert opinion, case reports, mechanistic studies\n- **D**: Preliminary research, preprints, conference abstracts\n- **E**: Anecdotal, theoretic"
  },
  {
    "id": "question-refiner",
    "name": "question-refiner",
    "description": "å°†åŽŸå§‹ç ”ç©¶é—®é¢˜ç»†åŒ–ä¸ºç»“æž„åŒ–çš„æ·±åº¦ç ”ç©¶ä»»åŠ¡ã€‚é€šè¿‡æé—®æ¾„æ¸…éœ€æ±‚ï¼Œç”Ÿæˆç¬¦åˆ OpenAI/Google Deep Research æ ‡å‡†çš„ç»“æž„åŒ–æç¤ºè¯ã€‚å½“ç”¨æˆ·æå‡ºç ”ç©¶é—®é¢˜ã€éœ€è¦å¸®åŠ©å®šä¹‰ç ”ç©¶èŒƒå›´ã€æˆ–æƒ³è¦ç”Ÿæˆç»“æž„åŒ–ç ”ç©¶æç¤ºè¯æ—¶ä½¿ç”¨æ­¤æŠ€èƒ½ã€‚",
    "category": "ml-ai",
    "source": "unknown",
    "triggers": [
      "question",
      "refiner",
      "openai",
      "google",
      "deep",
      "question-refiner"
    ],
    "path": "/Users/marovole/GitHub/fastskills/deep-research-skills/.claude/skills/question-refiner",
    "fullDescription": "\n# Question Refiner\n\n## Role\n\nYou are a **Deep Research Question Refiner** specializing in crafting, refining, and optimizing prompts for deep research. Your primary objectives are:\n\n1. **Ask clarifying questions first** to ensure full understanding of the user's needs, scope, and context\n2. **Generate structured research prompts** that follow best practices for deep research\n3. **Eliminate the need for external tools** (like ChatGPT) - everything is done within Claude Code\n\n## Core Directives\n\n- **Do Not Answer the Research Query Directly**: Focus on prompt crafting, not solving the research request\n- **Be Explicit & Skeptical**: If the user's instructions are vague or contradictory, request more detail\n- **Enforce Structure**: Encourage the user to use headings, bullet points, or other organizational methods\n- **Demand Constraints & Context**: Identify relevant timeframes, geographical scope, data sources, and desired output formats\n- **Invite Clarification**: Prompt the user to clarify ambiguous instructions or incomplete details\n\n## Interaction Flow\n\n### Step 1: Initial Response - Ask Clarifying Questions\n\nWhen a user provides a raw research question, ask ALL of these relevant questions:\n\n#### 1. Core Research Question\n- What is the main topic or question you want to investigate?\n- What specific aspects or angles are most important?\n- What problem are you trying to solve with this research?\n\n#### 2. Output Requirements\n- What format do you prefer? (comprehensive report, executive summary, presentation slides, data analysis)\n- How long should the output be? (3-5 pages, 20-30 pages, brief overview, detailed analysis)\n- Do you need visualizations? (charts, graphs, diagrams, comparison tables)\n- File structure preference? (single document vs. folder with multiple files)\n\n#### 3. Scope & Boundaries\n- Geographic focus? (global, US, Europe, specific countries/regions)\n- Time period? (current state, last 3 years, historical trends, future projections to 2028)\n- Industry"
  },
  {
    "id": "got-controller",
    "name": "got-controller",
    "description": "Graph of Thoughts (GoT) Controller - ç®¡ç†ç ”ç©¶å›¾çŠ¶æ€ï¼Œæ‰§è¡Œå›¾æ“ä½œï¼ˆGenerate, Aggregate, Refine, Scoreï¼‰ï¼Œä¼˜åŒ–ç ”ç©¶è·¯å¾„è´¨é‡ã€‚å½“ç ”ç©¶ä¸»é¢˜å¤æ‚æˆ–å¤šæ–¹é¢ã€éœ€è¦ç­–ç•¥æ€§æŽ¢ç´¢ï¼ˆæ·±åº¦ vs å¹¿åº¦ï¼‰ã€é«˜è´¨é‡ç ”ç©¶æ—¶ä½¿ç”¨æ­¤æŠ€èƒ½ã€‚",
    "category": "ml-ai",
    "source": "unknown",
    "triggers": [
      "controller",
      "graph",
      "thoughts",
      "generate",
      "aggregate",
      "refine",
      "score",
      "got-controller"
    ],
    "path": "/Users/marovole/GitHub/fastskills/deep-research-skills/.claude/skills/got-controller",
    "fullDescription": "\n# GoT Controller\n\n## Role\n\nYou are a **Graph of Thoughts (GoT) Controller** responsible for managing research as a graph operations framework. You orchestrate complex multi-agent research using the GoT paradigm, optimizing information quality through strategic generation, aggregation, refinement, and scoring operations.\n\n## What is Graph of Thoughts?\n\nGraph of Thoughts (GoT) is a framework inspired by [SPCL, ETH ZÃ¼rich](https://github.com/spcl/graph-of-thoughts) that models reasoning as a graph where:\n\n- **Nodes** = Research findings, insights, or conclusions\n- **Edges** = Dependencies and relationships between findings\n- **Scores** = Quality ratings (0-10 scale) assigned to each node\n- **Frontier** = Set of active nodes available for further exploration\n- **Operations** = Transformations that manipulate the graph state\n\n## Core GoT Operations\n\n### 1. Generate(k)\n\n**Purpose**: Create k new research paths from a parent node\n\n**When to Use**:\n- Initial exploration of a topic\n- Expanding on high-quality findings\n- Exploring multiple angles simultaneously\n\n**Implementation**: Spawn k parallel research agents, each exploring a distinct aspect\n\n### 2. Aggregate(k)\n\n**Purpose**: Combine k nodes into one stronger, comprehensive synthesis\n\n**When to Use**:\n- Multiple agents have researched related aspects\n- You need to combine findings into a cohesive whole\n- Resolving contradictions between sources\n\n**Implementation**: Combine findings, resolve conflicts, extract key insights\n\n### 3. Refine(1)\n\n**Purpose**: Improve and polish an existing finding without adding new research\n\n**When to Use**:\n- A node has good content but needs better organization\n- Clarifying ambiguous findings\n- Improving citation quality and completeness\n\n**Implementation**: Improve clarity, completeness, citations, structure\n\n### 4. Score\n\n**Purpose**: Evaluate the quality of a research finding (0-10 scale)\n\n**Scoring Criteria**:\n- **9-10 (Excellent)**: Multiple high-quality sources (A-B), no contradicti"
  },
  {
    "id": "citation-validator",
    "name": "citation-validator",
    "description": "éªŒè¯ç ”ç©¶æŠ¥å‘Šä¸­æ‰€æœ‰å£°æ˜Žçš„å¼•ç”¨å‡†ç¡®æ€§ã€æ¥æºè´¨é‡å’Œæ ¼å¼è§„èŒƒæ€§ã€‚ç¡®ä¿æ¯ä¸ªäº‹å®žæ€§å£°æ˜Žéƒ½æœ‰å¯éªŒè¯çš„æ¥æºï¼Œå¹¶æä¾›æ¥æºè´¨é‡è¯„çº§ã€‚å½“æœ€ç»ˆç¡®å®šç ”ç©¶æŠ¥å‘Šã€å®¡æŸ¥ä»–äººç ”ç©¶ã€å‘å¸ƒæˆ–åˆ†äº«ç ”ç©¶ä¹‹å‰ä½¿ç”¨æ­¤æŠ€èƒ½ã€‚",
    "category": "ml-ai",
    "source": "unknown",
    "triggers": [
      "citation",
      "validator",
      "citation-validator"
    ],
    "path": "/Users/marovole/GitHub/fastskills/deep-research-skills/.claude/skills/citation-validator",
    "fullDescription": "\n# Citation Validator\n\n## Role\n\nYou are a **Citation Validator** responsible for ensuring research integrity by verifying that every factual claim in a research report has accurate, complete, and high-quality citations.\n\n## Core Responsibilities\n\n1. **Verify Citation Presence**: Every factual claim must have a citation\n2. **Validate Citation Completeness**: Each citation must have all required elements\n3. **Assess Source Quality**: Rate each source using the A-E quality scale\n4. **Check Citation Accuracy**: Verify citations actually support the claims\n5. **Detect Hallucinations**: Identify claims with no supporting sources\n6. **Format Consistency**: Ensure uniform citation format throughout\n\n## Citation Completeness Requirements\n\n### Every Citation Must Include:\n\n1. **Author/Organization** - Who created the content\n2. **Publication Date** - When it was published (YYYY format)\n3. **Source Title** - Name of the work\n4. **URL/DOI** - Direct link to verify\n5. **Page Numbers** (if applicable) - For PDFs and long documents\n\n### Acceptable Citation Formats:\n\n**Academic Papers**:\n```\n(Smith et al., 2023, p. 145)\nFull: Smith, J., Johnson, K., & Lee, M. (2023). \"Title of Paper.\" Journal Name, 45(3), 140-156. https://doi.org/10.xxxx/xxxxx\n```\n\n**Industry Reports**:\n```\n(Gartner, 2024, \"Cloud Computing Forecast\")\nFull: Gartner. (2024). \"Cloud Computing Market Forecast, 2024.\" Retrieved [date] from https://www.gartner.com/en/research/xxxxx\n```\n\n## Source Quality Rating System\n\n- **A - Excellent**: Peer-reviewed journals with impact factor, meta-analyses, RCTs, government regulatory bodies\n- **B - Good**: Cohort studies, clinical guidelines, reputable analysts (Gartner, Forrester), government websites\n- **C - Acceptable**: Expert opinion pieces, case reports, company white papers, reputable news outlets\n- **D - Weak**: Preprints, conference abstracts, blog posts without editorial oversight, crowdsourced content\n- **E - Very Poor**: Anonymous content, clear bias/conflict of intere"
  },
  {
    "id": "web-frameworks",
    "name": "web-frameworks",
    "description": "Build modern full-stack web applications with Next.js (App Router, Server Components, RSC, PPR, SSR, SSG, ISR), Turborepo (monorepo management, task pipelines, remote caching, parallel execution), and RemixIcon (3100+ SVG icons in outlined/filled styles). Use when creating React applications, implem",
    "category": "frontend",
    "source": "claudekit",
    "triggers": [
      "web",
      "frameworks",
      "full-stack",
      "applications",
      "caching",
      "modern",
      "next",
      "app",
      "router",
      "server"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/web-frameworks",
    "fullDescription": "\n# Web Frameworks Skill Group\n\nComprehensive guide for building modern full-stack web applications using Next.js, Turborepo, and RemixIcon.\n\n## Overview\n\nThis skill group combines three powerful tools for web development:\n\n**Next.js** - React framework with SSR, SSG, RSC, and optimization features\n**Turborepo** - High-performance monorepo build system for JavaScript/TypeScript\n**RemixIcon** - Icon library with 3,100+ outlined and filled style icons\n\n## When to Use This Skill Group\n\n- Building new full-stack web applications with modern React\n- Setting up monorepos with multiple apps and shared packages\n- Implementing server-side rendering and static generation\n- Optimizing build performance with intelligent caching\n- Creating consistent UI with professional iconography\n- Managing workspace dependencies across multiple projects\n- Deploying production-ready applications with proper optimization\n\n## Stack Selection Guide\n\n### Single Application: Next.js + RemixIcon\n\nUse when building a standalone application:\n- E-commerce sites\n- Marketing websites\n- SaaS applications\n- Documentation sites\n- Blogs and content platforms\n\n**Setup:**\n```bash\nnpx create-next-app@latest my-app\ncd my-app\nnpm install remixicon\n```\n\n### Monorepo: Next.js + Turborepo + RemixIcon\n\nUse when building multiple applications with shared code:\n- Microfrontends\n- Multi-tenant platforms\n- Internal tools with shared component library\n- Multiple apps (web, admin, mobile-web) sharing logic\n- Design system with documentation site\n\n**Setup:**\n```bash\nnpx create-turbo@latest my-monorepo\n# Then configure Next.js apps in apps/ directory\n# Install remixicon in shared UI packages\n```\n\n### Framework Features Comparison\n\n| Feature | Next.js | Turborepo | RemixIcon |\n|---------|---------|-----------|-----------|\n| Primary Use | Web framework | Build system | UI icons |\n| Best For | SSR/SSG apps | Monorepos | Consistent iconography |\n| Performance | Built-in optimization | Caching & parallel tasks | Lightweight fonts"
  },
  {
    "id": "ui-styling",
    "name": "ui-styling",
    "description": "Create beautiful, accessible user interfaces with shadcn/ui components (built on Radix UI + Tailwind), Tailwind CSS utility-first styling, and canvas-based visual designs. Use when building user interfaces, implementing design systems, creating responsive layouts, adding accessible components (dialo",
    "category": "data-viz",
    "source": "claudekit",
    "triggers": [
      "styling",
      "accessible",
      "user",
      "interfaces",
      "components",
      "tailwind",
      "visual",
      "designs",
      "beautiful",
      "shadcn"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/ui-styling",
    "fullDescription": "\n# UI Styling Skill\n\nComprehensive skill for creating beautiful, accessible user interfaces combining shadcn/ui components, Tailwind CSS utility styling, and canvas-based visual design systems.\n\n## Reference\n\n- shadcn/ui: https://ui.shadcn.com/llms.txt\n- Tailwind CSS: https://tailwindcss.com/docs\n\n## When to Use This Skill\n\nUse when:\n- Building UI with React-based frameworks (Next.js, Vite, Remix, Astro)\n- Implementing accessible components (dialogs, forms, tables, navigation)\n- Styling with utility-first CSS approach\n- Creating responsive, mobile-first layouts\n- Implementing dark mode and theme customization\n- Building design systems with consistent tokens\n- Generating visual designs, posters, or brand materials\n- Rapid prototyping with immediate visual feedback\n- Adding complex UI patterns (data tables, charts, command palettes)\n\n## Core Stack\n\n### Component Layer: shadcn/ui\n- Pre-built accessible components via Radix UI primitives\n- Copy-paste distribution model (components live in your codebase)\n- TypeScript-first with full type safety\n- Composable primitives for complex UIs\n- CLI-based installation and management\n\n### Styling Layer: Tailwind CSS\n- Utility-first CSS framework\n- Build-time processing with zero runtime overhead\n- Mobile-first responsive design\n- Consistent design tokens (colors, spacing, typography)\n- Automatic dead code elimination\n\n### Visual Design Layer: Canvas\n- Museum-quality visual compositions\n- Philosophy-driven design approach\n- Sophisticated visual communication\n- Minimal text, maximum visual impact\n- Systematic patterns and refined aesthetics\n\n## Quick Start\n\n### Component + Styling Setup\n\n**Install shadcn/ui with Tailwind:**\n```bash\nnpx shadcn@latest init\n```\n\nCLI prompts for framework, TypeScript, paths, and theme preferences. This configures both shadcn/ui and Tailwind CSS.\n\n**Add components:**\n```bash\nnpx shadcn@latest add button card dialog form\n```\n\n**Use components with utility styling:**\n```tsx\nimport { Button } from \"@/compone"
  },
  {
    "id": "sequential-thinking",
    "name": "sequential-thinking",
    "description": "Use when complex problems require systematic step-by-step reasoning with ability to revise thoughts, branch into alternative approaches, or dynamically adjust scope. Ideal for multi-stage analysis, design planning, problem decomposition, or tasks with initially unclear scope.",
    "category": "frontend",
    "source": "claudekit",
    "triggers": [
      "sequential",
      "thinking",
      "scope",
      "complex",
      "problems",
      "require",
      "systematic",
      "step-by-step",
      "reasoning",
      "ability"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/sequential-thinking",
    "fullDescription": "\n# Sequential Thinking\n\nEnables structured problem-solving through iterative reasoning with revision and branching capabilities.\n\n## Core Capabilities\n\n- **Iterative reasoning**: Break complex problems into sequential thought steps\n- **Dynamic scope**: Adjust total thought count as understanding evolves\n- **Revision tracking**: Reconsider and modify previous conclusions\n- **Branch exploration**: Explore alternative reasoning paths from any point\n- **Maintained context**: Keep track of reasoning chain throughout analysis\n\n## When to Use\n\nUse `mcp__reasoning__sequentialthinking` when:\n- Problem requires multiple interconnected reasoning steps\n- Initial scope or approach is uncertain\n- Need to filter through complexity to find core issues\n- May need to backtrack or revise earlier conclusions\n- Want to explore alternative solution paths\n\n**Don't use for**: Simple queries, direct facts, or single-step tasks.\n\n## Basic Usage\n\nThe MCP tool `mcp__reasoning__sequentialthinking` accepts these parameters:\n\n### Required Parameters\n\n- `thought` (string): Current reasoning step\n- `nextThoughtNeeded` (boolean): Whether more reasoning is needed\n- `thoughtNumber` (integer): Current step number (starts at 1)\n- `totalThoughts` (integer): Estimated total steps needed\n\n### Optional Parameters\n\n- `isRevision` (boolean): Indicates this revises previous thinking\n- `revisesThought` (integer): Which thought number is being reconsidered\n- `branchFromThought` (integer): Thought number to branch from\n- `branchId` (string): Identifier for this reasoning branch\n\n## Workflow Pattern\n\n```\n1. Start with initial thought (thoughtNumber: 1)\n2. For each step:\n   - Express current reasoning in `thought`\n   - Estimate remaining work via `totalThoughts` (adjust dynamically)\n   - Set `nextThoughtNeeded: true` to continue\n3. When reaching conclusion, set `nextThoughtNeeded: false`\n```\n\n## Simple Example\n\n```typescript\n// First thought\n{\n  thought: \"Problem involves optimizing database queries. Need to identi"
  },
  {
    "id": "shopify",
    "name": "shopify",
    "description": "Build Shopify applications, extensions, and themes using GraphQL/REST APIs, Shopify CLI, Polaris UI components, and Liquid templating. Capabilities include app development with OAuth authentication, checkout UI extensions for customizing checkout flow, admin UI extensions for dashboard integration, ",
    "category": "lab-automation",
    "source": "claudekit",
    "triggers": [
      "shopify",
      "extensions",
      "checkout",
      "themes",
      "apis",
      "liquid",
      "development",
      "admin",
      "integration",
      "management"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/shopify",
    "fullDescription": "\n# Shopify Development\n\nComprehensive guide for building on Shopify platform: apps, extensions, themes, and API integrations.\n\n## Platform Overview\n\n**Core Components:**\n- **Shopify CLI** - Development workflow tool\n- **GraphQL Admin API** - Primary API for data operations (recommended)\n- **REST Admin API** - Legacy API (maintenance mode)\n- **Polaris UI** - Design system for consistent interfaces\n- **Liquid** - Template language for themes\n\n**Extension Points:**\n- Checkout UI - Customize checkout experience\n- Admin UI - Extend admin dashboard\n- POS UI - Point of Sale customization\n- Customer Account - Post-purchase pages\n- Theme App Extensions - Embedded theme functionality\n\n## Quick Start\n\n### Prerequisites\n\n```bash\n# Install Shopify CLI\nnpm install -g @shopify/cli@latest\n\n# Verify installation\nshopify version\n```\n\n### Create New App\n\n```bash\n# Initialize app\nshopify app init\n\n# Start development server\nshopify app dev\n\n# Generate extension\nshopify app generate extension --type checkout_ui_extension\n\n# Deploy\nshopify app deploy\n```\n\n### Theme Development\n\n```bash\n# Initialize theme\nshopify theme init\n\n# Start local preview\nshopify theme dev\n\n# Pull from store\nshopify theme pull --live\n\n# Push to store\nshopify theme push --development\n```\n\n## Development Workflow\n\n### 1. App Development\n\n**Setup:**\n```bash\nshopify app init\ncd my-app\n```\n\n**Configure Access Scopes** (`shopify.app.toml`):\n```toml\n[access_scopes]\nscopes = \"read_products,write_products,read_orders\"\n```\n\n**Start Development:**\n```bash\nshopify app dev  # Starts local server with tunnel\n```\n\n**Add Extensions:**\n```bash\nshopify app generate extension --type checkout_ui_extension\n```\n\n**Deploy:**\n```bash\nshopify app deploy  # Builds and uploads to Shopify\n```\n\n### 2. Extension Development\n\n**Available Types:**\n- Checkout UI - `checkout_ui_extension`\n- Admin Action - `admin_action`\n- Admin Block - `admin_block`\n- POS UI - `pos_ui_extension`\n- Function - `function` (discounts, payment, delivery, validation)\n\n*"
  },
  {
    "id": "repomix",
    "name": "repomix",
    "description": "Package entire code repositories into single AI-friendly files using Repomix. Capabilities include pack codebases with customizable include/exclude patterns, generate multiple output formats (XML, Markdown, plain text), preserve file structure and context, optimize for AI consumption with token coun",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "repomix",
      "codebases",
      "context",
      "file",
      "package",
      "entire",
      "code",
      "repositories",
      "single",
      "ai-friendly"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/repomix",
    "fullDescription": "\n# Repomix Skill\n\nRepomix packs entire repositories into single, AI-friendly files. Perfect for feeding codebases to LLMs like Claude, ChatGPT, and Gemini.\n\n## When to Use\n\nUse when:\n- Packaging codebases for AI analysis\n- Creating repository snapshots for LLM context\n- Analyzing third-party libraries\n- Preparing for security audits\n- Generating documentation context\n- Investigating bugs across large codebases\n- Creating AI-friendly code representations\n\n## Quick Start\n\n### Check Installation\n```bash\nrepomix --version\n```\n\n### Install\n```bash\n# npm\nnpm install -g repomix\n\n# Homebrew (macOS/Linux)\nbrew install repomix\n```\n\n### Basic Usage\n```bash\n# Package current directory (generates repomix-output.xml)\nrepomix\n\n# Specify output format\nrepomix --style markdown\nrepomix --style json\n\n# Package remote repository\nnpx repomix --remote owner/repo\n\n# Custom output with filters\nrepomix --include \"src/**/*.ts\" --remove-comments -o output.md\n```\n\n## Core Capabilities\n\n### Repository Packaging\n- AI-optimized formatting with clear separators\n- Multiple output formats: XML, Markdown, JSON, Plain text\n- Git-aware processing (respects .gitignore)\n- Token counting for LLM context management\n- Security checks for sensitive information\n\n### Remote Repository Support\nProcess remote repositories without cloning:\n```bash\n# Shorthand\nnpx repomix --remote yamadashy/repomix\n\n# Full URL\nnpx repomix --remote https://github.com/owner/repo\n\n# Specific commit\nnpx repomix --remote https://github.com/owner/repo/commit/hash\n```\n\n### Comment Removal\nStrip comments from supported languages (HTML, CSS, JavaScript, TypeScript, Vue, Svelte, Python, PHP, Ruby, C, C#, Java, Go, Rust, Swift, Kotlin, Dart, Shell, YAML):\n```bash\nrepomix --remove-comments\n```\n\n## Common Use Cases\n\n### Code Review Preparation\n```bash\n# Package feature branch for AI review\nrepomix --include \"src/**/*.ts\" --remove-comments -o review.md --style markdown\n```\n\n### Security Audit\n```bash\n# Package third-party library\nnpx repomix --"
  },
  {
    "id": "mermaidjs-v11",
    "name": "mermaidjs-v11",
    "description": "Create diagrams and visualizations using Mermaid.js v11 syntax. Use when generating flowcharts, sequence diagrams, class diagrams, state diagrams, ER diagrams, Gantt charts, user journeys, timelines, architecture diagrams, or any of 24+ diagram types. Supports JavaScript API integration, CLI renderi",
    "category": "data-viz",
    "source": "claudekit",
    "triggers": [
      "mermaidjs",
      "v11",
      "diagrams",
      "architecture",
      "visualizations",
      "mermaid",
      "syntax",
      "generating",
      "flowcharts",
      "sequence"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/mermaidjs-v11",
    "fullDescription": "\n# Mermaid.js v11\n\n## Overview\n\nCreate text-based diagrams using Mermaid.js v11 declarative syntax. Convert code to SVG/PNG/PDF via CLI or render in browsers/markdown files.\n\n## Quick Start\n\n**Basic Diagram Structure:**\n```\n{diagram-type}\n  {diagram-content}\n```\n\n**Common Diagram Types:**\n- `flowchart` - Process flows, decision trees\n- `sequenceDiagram` - Actor interactions, API flows\n- `classDiagram` - OOP structures, data models\n- `stateDiagram` - State machines, workflows\n- `erDiagram` - Database relationships\n- `gantt` - Project timelines\n- `journey` - User experience flows\n\nSee `references/diagram-types.md` for all 24+ types with syntax.\n\n## Creating Diagrams\n\n**Inline Markdown Code Blocks:**\n````markdown\n```mermaid\nflowchart TD\n    A[Start] --> B{Decision}\n    B -->|Yes| C[Action]\n    B -->|No| D[End]\n```\n````\n\n**Configuration via Frontmatter:**\n````markdown\n```mermaid\n---\ntheme: dark\n---\nflowchart LR\n    A --> B\n```\n````\n\n**Comments:** Use `%% ` prefix for single-line comments.\n\n## CLI Usage\n\nConvert `.mmd` files to images:\n```bash\n# Installation\nnpm install -g @mermaid-js/mermaid-cli\n\n# Basic conversion\nmmdc -i diagram.mmd -o diagram.svg\n\n# With theme and background\nmmdc -i input.mmd -o output.png -t dark -b transparent\n\n# Custom styling\nmmdc -i diagram.mmd --cssFile style.css -o output.svg\n```\n\nSee `references/cli-usage.md` for Docker, batch processing, and advanced workflows.\n\n## JavaScript Integration\n\n**HTML Embedding:**\n```html\n<pre class=\"mermaid\">\n  flowchart TD\n    A[Client] --> B[Server]\n</pre>\n<script src=\"https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.min.js\"></script>\n<script>mermaid.initialize({ startOnLoad: true });</script>\n```\n\nSee `references/integration.md` for Node.js API and advanced integration patterns.\n\n## Configuration & Theming\n\n**Common Options:**\n- `theme`: \"default\", \"dark\", \"forest\", \"neutral\", \"base\"\n- `look`: \"classic\", \"handDrawn\"\n- `fontFamily`: Custom font specification\n- `securityLevel`: \"strict\", \"loose\", \"antisc"
  },
  {
    "id": "media-processing",
    "name": "media-processing",
    "description": "Process multimedia files with FFmpeg (video/audio encoding, conversion, streaming, filtering, hardware acceleration) and ImageMagick (image manipulation, format conversion, batch processing, effects, composition). Use when converting media formats, encoding videos with specific codecs (H.264, H.265,",
    "category": "media",
    "source": "claudekit",
    "triggers": [
      "media",
      "processing",
      "images",
      "video",
      "audio",
      "encoding",
      "conversion",
      "streaming",
      "hardware",
      "acceleration"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/media-processing",
    "fullDescription": "\n# Media Processing Skill\n\nProcess video, audio, and images using FFmpeg and ImageMagick command-line tools for conversion, optimization, streaming, and manipulation tasks.\n\n## When to Use This Skill\n\nUse when:\n- Converting media formats (video, audio, images)\n- Encoding video with codecs (H.264, H.265, VP9, AV1)\n- Processing images (resize, crop, effects, watermarks)\n- Extracting audio from video\n- Creating streaming manifests (HLS/DASH)\n- Generating thumbnails and previews\n- Batch processing media files\n- Optimizing file sizes and quality\n- Applying filters and effects\n- Creating composite images or videos\n\n## Tool Selection Guide\n\n### FFmpeg: Video/Audio Processing\nUse FFmpeg for:\n- Video encoding, conversion, transcoding\n- Audio extraction, conversion, mixing\n- Live streaming (RTMP, HLS, DASH)\n- Video filters (scale, crop, rotate, overlay)\n- Hardware-accelerated encoding\n- Media file inspection (ffprobe)\n- Frame extraction, concatenation\n- Codec selection and optimization\n\n### ImageMagick: Image Processing\nUse ImageMagick for:\n- Image format conversion (PNG, JPEG, WebP, GIF)\n- Resizing, cropping, transformations\n- Batch image processing (mogrify)\n- Visual effects (blur, sharpen, sepia)\n- Text overlays and watermarks\n- Image composition and montages\n- Color adjustments, filters\n- Thumbnail generation\n\n### Decision Matrix\n\n| Task | Tool | Why |\n|------|------|-----|\n| Video encoding | FFmpeg | Native video codec support |\n| Audio extraction | FFmpeg | Direct stream manipulation |\n| Image resize | ImageMagick | Optimized for still images |\n| Batch images | ImageMagick | mogrify for in-place edits |\n| Video thumbnails | FFmpeg | Frame extraction built-in |\n| GIF creation | FFmpeg or ImageMagick | FFmpeg for video source, ImageMagick for images |\n| Streaming | FFmpeg | Live streaming protocols |\n| Image effects | ImageMagick | Rich filter library |\n\n## Installation\n\n### macOS\n```bash\nbrew install ffmpeg imagemagick\n```\n\n### Ubuntu/Debian\n```bash\nsudo apt-get install "
  },
  {
    "id": "mcp-management",
    "name": "mcp-management",
    "description": "Manage Model Context Protocol (MCP) servers - discover, analyze, and execute tools/prompts/resources from configured MCP servers. Use when working with MCP integrations, need to discover available MCP capabilities, filter MCP tools for specific tasks, execute MCP tools programmatically, access MCP p",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "mcp",
      "management",
      "tools",
      "servers",
      "discover",
      "execute",
      "prompts",
      "resources",
      "manage",
      "model"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/mcp-management",
    "fullDescription": "\n# MCP Management\n\nSkill for managing and interacting with Model Context Protocol (MCP) servers.\n\n## Overview\n\nMCP is an open protocol enabling AI agents to connect to external tools and data sources. This skill provides scripts and utilities to discover, analyze, and execute MCP capabilities from configured servers without polluting the main context window.\n\n**Key Benefits**:\n- Progressive disclosure of MCP capabilities (load only what's needed)\n- Intelligent tool/prompt/resource selection based on task requirements\n- Multi-server management from single config file\n- Context-efficient: subagents handle MCP discovery and execution\n- Persistent tool catalog: automatically saves discovered tools to JSON for fast reference\n\n## When to Use This Skill\n\nUse this skill when:\n1. **Discovering MCP Capabilities**: Need to list available tools/prompts/resources from configured servers\n2. **Task-Based Tool Selection**: Analyzing which MCP tools are relevant for a specific task\n3. **Executing MCP Tools**: Calling MCP tools programmatically with proper parameter handling\n4. **MCP Integration**: Building or debugging MCP client implementations\n5. **Context Management**: Avoiding context pollution by delegating MCP operations to subagents\n\n## Core Capabilities\n\n### 1. Configuration Management\n\nMCP servers configured in `.claude/.mcp.json`.\n\n**Gemini CLI Integration** (recommended): Create symlink to `.gemini/settings.json`:\n```bash\nmkdir -p .gemini && ln -sf .claude/.mcp.json .gemini/settings.json\n```\n\nSee [references/configuration.md](references/configuration.md) and [references/gemini-cli-integration.md](references/gemini-cli-integration.md).\n\n### 2. Capability Discovery\n\n```bash\nnpx tsx scripts/cli.ts list-tools  # Saves to assets/tools.json\nnpx tsx scripts/cli.ts list-prompts\nnpx tsx scripts/cli.ts list-resources\n```\n\nAggregates capabilities from multiple servers with server identification.\n\n### 3. Intelligent Tool Analysis\n\nLLM analyzes `assets/tools.json` directly - better th"
  },
  {
    "id": "google-adk-python",
    "name": "google-adk-python",
    "description": "You are an expert guide for Google's Agent Development Kit (ADK) Python - an open-source, code-first toolkit for building, evaluating, and deploying AI agents. Use this skill when users need to: - Build AI agents with tool integration and orchestration capabilities",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "google",
      "adk",
      "agents",
      "expert",
      "agent",
      "development",
      "kit",
      "open-source",
      "code-first",
      "evaluating"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/google-adk-python",
    "fullDescription": "# Google ADK Python Skill\n\nYou are an expert guide for Google's Agent Development Kit (ADK) Python - an open-source, code-first toolkit for building, evaluating, and deploying AI agents.\n\n## When to Use This Skill\n\nUse this skill when users need to:\n- Build AI agents with tool integration and orchestration capabilities\n- Create multi-agent systems with hierarchical coordination\n- Implement workflow agents (sequential, parallel, loop) for predictable pipelines\n- Integrate LLM-powered agents with Google Search, Code Execution, or custom tools\n- Deploy agents to Vertex AI Agent Engine, Cloud Run, or custom infrastructure\n- Evaluate and test agent performance systematically\n- Implement human-in-the-loop approval flows for tool execution\n\n## Core Concepts\n\n### Agent Types\n\n**LlmAgent**: LLM-powered agents capable of dynamic routing and adaptive behavior\n- Define with name, model, instruction, description, and tools\n- Supports sub-agents for delegation and coordination\n- Intelligent decision-making based on context\n\n**Workflow Agents**: Structured, predictable orchestration patterns\n- **SequentialAgent**: Execute agents in defined order\n- **ParallelAgent**: Run multiple agents concurrently\n- **LoopAgent**: Repeat execution with iteration logic\n\n**BaseAgent**: Foundation for custom agent implementations\n\n### Key Components\n\n**Tools Ecosystem**:\n- Pre-built tools (google_search, code_execution)\n- Custom Python functions as tools\n- OpenAPI specification integration\n- Tool confirmation flows for human approval\n\n**Multi-Agent Architecture**:\n- Hierarchical agent composition\n- Specialized agents for specific domains\n- Coordinator agents for delegation\n\n## Installation\n\n```bash\n# Stable release (recommended)\npip install google-adk\n\n# Development version (latest features)\npip install git+https://github.com/google/adk-python.git@main\n```\n\n## Implementation Patterns\n\n### Single Agent with Tools\n\n```python\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import google_se"
  },
  {
    "id": "frontend-dev-guidelines",
    "name": "frontend-dev-guidelines",
    "description": "Frontend development guidelines for React/TypeScript applications. Modern patterns including Suspense, lazy loading, useSuspenseQuery, file organization with features directory, MUI v7 styling, TanStack Router, performance optimization, and TypeScript best practices. Use when creating components, pa",
    "category": "frontend",
    "source": "claudekit",
    "triggers": [
      "frontend",
      "dev",
      "guidelines",
      "typescript",
      "styling",
      "development",
      "react",
      "applications",
      "modern",
      "patterns"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/frontend-development",
    "fullDescription": "\n# Frontend Development Guidelines\n\n## Purpose\n\nComprehensive guide for modern React development, emphasizing Suspense-based data fetching, lazy loading, proper file organization, and performance optimization.\n\n## When to Use This Skill\n\n- Creating new components or pages\n- Building new features\n- Fetching data with TanStack Query\n- Setting up routing with TanStack Router\n- Styling components with MUI v7\n- Performance optimization\n- Organizing frontend code\n- TypeScript best practices\n\n---\n\n## Quick Start\n\n### New Component Checklist\n\nCreating a component? Follow this checklist:\n\n- [ ] Use `React.FC<Props>` pattern with TypeScript\n- [ ] Lazy load if heavy component: `React.lazy(() => import())`\n- [ ] Wrap in `<SuspenseLoader>` for loading states\n- [ ] Use `useSuspenseQuery` for data fetching\n- [ ] Import aliases: `@/`, `~types`, `~components`, `~features`\n- [ ] Styles: Inline if <100 lines, separate file if >100 lines\n- [ ] Use `useCallback` for event handlers passed to children\n- [ ] Default export at bottom\n- [ ] No early returns with loading spinners\n- [ ] Use `useMuiSnackbar` for user notifications\n\n### New Feature Checklist\n\nCreating a feature? Set up this structure:\n\n- [ ] Create `features/{feature-name}/` directory\n- [ ] Create subdirectories: `api/`, `components/`, `hooks/`, `helpers/`, `types/`\n- [ ] Create API service file: `api/{feature}Api.ts`\n- [ ] Set up TypeScript types in `types/`\n- [ ] Create route in `routes/{feature-name}/index.tsx`\n- [ ] Lazy load feature components\n- [ ] Use Suspense boundaries\n- [ ] Export public API from feature `index.ts`\n\n---\n\n## Import Aliases Quick Reference\n\n| Alias | Resolves To | Example |\n|-------|-------------|---------|\n| `@/` | `src/` | `import { apiClient } from '@/lib/apiClient'` |\n| `~types` | `src/types` | `import type { User } from '~types/user'` |\n| `~components` | `src/components` | `import { SuspenseLoader } from '~components/SuspenseLoader'` |\n| `~features` | `src/features` | `import { authApi } from '~feat"
  },
  {
    "id": "docs-seeker",
    "name": "docs-seeker",
    "description": "Searching internet for technical documentation using llms.txt standard, GitHub repositories via Repomix, and parallel exploration. Use when user needs: (1) Latest documentation for libraries/frameworks, (2) Documentation in llms.txt format, (3) GitHub repository analysis, (4) Documentation without d",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "docs",
      "seeker",
      "documentation",
      "llms",
      "txt",
      "github",
      "parallel",
      "searching",
      "internet",
      "technical"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/docs-seeker",
    "fullDescription": "\n# Documentation Discovery & Analysis\n\n## Overview\n\nIntelligent discovery and analysis of technical documentation through multiple strategies:\n\n1. **llms.txt-first**: Search for standardized AI-friendly documentation\n2. **Repository analysis**: Use Repomix to analyze GitHub repositories\n3. **Parallel exploration**: Deploy multiple Explorer agents for comprehensive coverage\n4. **Fallback research**: Use Researcher agents when other methods unavailable\n\n## Core Workflow\n\n### Phase 1: Initial Discovery\n\n1. **Identify target**\n   - Extract library/framework name from user request\n   - Note version requirements (default: latest)\n   - Clarify scope if ambiguous\n   - Identify if target is GitHub repository or website\n\n2. **Search for llms.txt (PRIORITIZE context7.com)**\n\n   **First: Try context7.com patterns**\n\n   For GitHub repositories:\n   ```\n   Pattern: https://context7.com/{org}/{repo}/llms.txt\n   Examples:\n   - https://github.com/imagick/imagick â†’ https://context7.com/imagick/imagick/llms.txt\n   - https://github.com/vercel/next.js â†’ https://context7.com/vercel/next.js/llms.txt\n   - https://github.com/better-auth/better-auth â†’ https://context7.com/better-auth/better-auth/llms.txt\n   ```\n\n   For websites:\n   ```\n   Pattern: https://context7.com/websites/{normalized-domain-path}/llms.txt\n   Examples:\n   - https://docs.imgix.com/ â†’ https://context7.com/websites/imgix/llms.txt\n   - https://docs.byteplus.com/en/docs/ModelArk/ â†’ https://context7.com/websites/byteplus_en_modelark/llms.txt\n   - https://docs.haystack.deepset.ai/docs â†’ https://context7.com/websites/haystack_deepset_ai/llms.txt\n   - https://ffmpeg.org/doxygen/8.0/ â†’ https://context7.com/websites/ffmpeg_doxygen_8_0/llms.txt\n   ```\n\n   **Topic-specific searches** (when user asks about specific feature):\n   ```\n   Pattern: https://context7.com/{path}/llms.txt?topic={query}\n   Examples:\n   - https://context7.com/shadcn-ui/ui/llms.txt?topic=date\n   - https://context7.com/shadcn-ui/ui/llms.txt?topic=button\n   - https:"
  },
  {
    "id": "devops",
    "name": "devops",
    "description": "Deploy and manage cloud infrastructure on Cloudflare (Workers, R2, D1, KV, Pages, Durable Objects, Browser Rendering), Docker containers, and Google Cloud Platform (Compute Engine, GKE, Cloud Run, App Engine, Cloud Storage). Use when deploying serverless functions to the edge, configuring edge compu",
    "category": "devops",
    "source": "claudekit",
    "triggers": [
      "devops",
      "cloud",
      "infrastructure",
      "docker",
      "containers",
      "engine",
      "edge",
      "deploy",
      "manage",
      "cloudflare"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/devops",
    "fullDescription": "\n# DevOps Skill\n\nComprehensive guide for deploying and managing cloud infrastructure across Cloudflare edge platform, Docker containerization, and Google Cloud Platform.\n\n## When to Use This Skill\n\nUse this skill when:\n- Deploying serverless applications to Cloudflare Workers\n- Containerizing applications with Docker\n- Managing Google Cloud infrastructure with gcloud CLI\n- Setting up CI/CD pipelines across platforms\n- Optimizing cloud infrastructure costs\n- Implementing multi-region deployments\n- Building edge-first architectures\n- Managing container orchestration with Kubernetes\n- Configuring cloud storage solutions (R2, Cloud Storage)\n- Automating infrastructure with scripts and IaC\n\n## Platform Selection Guide\n\n### When to Use Cloudflare\n\n**Best For:**\n- Edge-first applications with global distribution\n- Ultra-low latency requirements (<50ms)\n- Static sites with serverless functions\n- Zero egress cost scenarios (R2 storage)\n- WebSocket/real-time applications (Durable Objects)\n- AI/ML at the edge (Workers AI)\n\n**Key Products:**\n- Workers (serverless functions)\n- R2 (object storage, S3-compatible)\n- D1 (SQLite database with global replication)\n- KV (key-value store)\n- Pages (static hosting + functions)\n- Durable Objects (stateful compute)\n- Browser Rendering (headless browser automation)\n\n**Cost Profile:** Pay-per-request, generous free tier, zero egress fees\n\n### When to Use Docker\n\n**Best For:**\n- Local development consistency\n- Microservices architectures\n- Multi-language stack applications\n- Traditional VPS/VM deployments\n- Kubernetes orchestration\n- CI/CD build environments\n- Database containerization (dev/test)\n\n**Key Capabilities:**\n- Application isolation and portability\n- Multi-stage builds for optimization\n- Docker Compose for multi-container apps\n- Volume management for data persistence\n- Network configuration and service discovery\n- Cross-platform compatibility (amd64, arm64)\n\n**Cost Profile:** Infrastructure cost only (compute + storage)\n\n### When to U"
  },
  {
    "id": "databases",
    "name": "databases",
    "description": "Work with MongoDB (document database, BSON documents, aggregation pipelines, Atlas cloud) and PostgreSQL (relational database, SQL queries, psql CLI, pgAdmin). Use when designing database schemas, writing queries and aggregations, optimizing indexes for performance, performing database migrations, c",
    "category": "sci-databases",
    "source": "claudekit",
    "triggers": [
      "databases",
      "queries",
      "performance",
      "work",
      "mongodb",
      "document",
      "bson",
      "documents",
      "aggregation",
      "pipelines"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/databases",
    "fullDescription": "\n# Databases Skill\n\nUnified guide for working with MongoDB (document-oriented) and PostgreSQL (relational) databases. Choose the right database for your use case and master both systems.\n\n## When to Use This Skill\n\nUse when:\n- Designing database schemas and data models\n- Writing queries (SQL or MongoDB query language)\n- Building aggregation pipelines or complex joins\n- Optimizing indexes and query performance\n- Implementing database migrations\n- Setting up replication, sharding, or clustering\n- Configuring backups and disaster recovery\n- Managing database users and permissions\n- Analyzing slow queries and performance issues\n- Administering production database deployments\n\n## Database Selection Guide\n\n### Choose MongoDB When:\n- Schema flexibility: frequent structure changes, heterogeneous data\n- Document-centric: natural JSON/BSON data model\n- Horizontal scaling: need to shard across multiple servers\n- High write throughput: IoT, logging, real-time analytics\n- Nested/hierarchical data: embedded documents preferred\n- Rapid prototyping: schema evolution without migrations\n\n**Best for:** Content management, catalogs, IoT time series, real-time analytics, mobile apps, user profiles\n\n### Choose PostgreSQL When:\n- Strong consistency: ACID transactions critical\n- Complex relationships: many-to-many joins, referential integrity\n- SQL requirement: team expertise, reporting tools, BI systems\n- Data integrity: strict schema validation, constraints\n- Mature ecosystem: extensive tooling, extensions\n- Complex queries: window functions, CTEs, analytical workloads\n\n**Best for:** Financial systems, e-commerce transactions, ERP, CRM, data warehousing, analytics\n\n### Both Support:\n- JSON/JSONB storage and querying\n- Full-text search capabilities\n- Geospatial queries and indexing\n- Replication and high availability\n- ACID transactions (MongoDB 4.0+)\n- Strong security features\n\n## Quick Start\n\n### MongoDB Setup\n\n```bash\n# Atlas (Cloud) - Recommended\n# 1. Sign up at mongodb.com/atlas\n# 2."
  },
  {
    "id": "context-engineering",
    "name": "context-engineering",
    "description": "Master context engineering for AI agent systems. Use when designing agent architectures, debugging context failures, optimizing token usage, implementing memory systems, building multi-agent coordination, evaluating agent performance, or developing LLM-powered pipelines. Covers context fundamentals,",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "context",
      "engineering",
      "agent",
      "systems",
      "architectures",
      "memory",
      "multi-agent",
      "patterns",
      "master",
      "designing"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/context-engineering",
    "fullDescription": "\n# Context Engineering\n\nContext engineering curates the smallest high-signal token set for LLM tasks. The goal: maximize reasoning quality while minimizing token usage.\n\n## When to Activate\n\n- Designing/debugging agent systems\n- Context limits constrain performance\n- Optimizing cost/latency\n- Building multi-agent coordination\n- Implementing memory systems\n- Evaluating agent performance\n- Developing LLM-powered pipelines\n\n## Core Principles\n\n1. **Context quality > quantity** - High-signal tokens beat exhaustive content\n2. **Attention is finite** - U-shaped curve favors beginning/end positions\n3. **Progressive disclosure** - Load information just-in-time\n4. **Isolation prevents degradation** - Partition work across sub-agents\n5. **Measure before optimizing** - Know your baseline\n\n## Quick Reference\n\n| Topic | When to Use | Reference |\n|-------|-------------|-----------|\n| **Fundamentals** | Understanding context anatomy, attention mechanics | [context-fundamentals.md](./references/context-fundamentals.md) |\n| **Degradation** | Debugging failures, lost-in-middle, poisoning | [context-degradation.md](./references/context-degradation.md) |\n| **Optimization** | Compaction, masking, caching, partitioning | [context-optimization.md](./references/context-optimization.md) |\n| **Compression** | Long sessions, summarization strategies | [context-compression.md](./references/context-compression.md) |\n| **Memory** | Cross-session persistence, knowledge graphs | [memory-systems.md](./references/memory-systems.md) |\n| **Multi-Agent** | Coordination patterns, context isolation | [multi-agent-patterns.md](./references/multi-agent-patterns.md) |\n| **Evaluation** | Testing agents, LLM-as-Judge, metrics | [evaluation.md](./references/evaluation.md) |\n| **Tool Design** | Tool consolidation, description engineering | [tool-design.md](./references/tool-design.md) |\n| **Pipelines** | Project development, batch processing | [project-development.md](./references/project-development.md) |\n\n## "
  },
  {
    "id": "code-review",
    "name": "code-review",
    "description": "Use when receiving code review feedback (especially if unclear or technically questionable), when completing tasks or major features requiring review before proceeding, or before making any completion/success claims. Covers three practices - receiving feedback with technical rigor over performative ",
    "category": "skill-dev",
    "source": "claudekit",
    "triggers": [
      "code",
      "review",
      "claims",
      "receiving",
      "feedback",
      "requiring",
      "completion",
      "especially",
      "unclear",
      "technically"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/code-review",
    "fullDescription": "\n# Code Review\n\nGuide proper code review practices emphasizing technical rigor, evidence-based claims, and verification over performative responses.\n\n## Overview\n\nCode review requires three distinct practices:\n\n1. **Receiving feedback** - Technical evaluation over performative agreement\n2. **Requesting reviews** - Systematic review via code-reviewer subagent\n3. **Verification gates** - Evidence before any completion claims\n\nEach practice has specific triggers and protocols detailed in reference files.\n\n## Core Principle\n\n**Technical correctness over social comfort.** Verify before implementing. Ask before assuming. Evidence before claims.\n\n## When to Use This Skill\n\n### Receiving Feedback\nTrigger when:\n- Receiving code review comments from any source\n- Feedback seems unclear or technically questionable\n- Multiple review items need prioritization\n- External reviewer lacks full context\n- Suggestion conflicts with existing decisions\n\n**Reference:** `references/code-review-reception.md`\n\n### Requesting Review\nTrigger when:\n- Completing tasks in subagent-driven development (after EACH task)\n- Finishing major features or refactors\n- Before merging to main branch\n- Stuck and need fresh perspective\n- After fixing complex bugs\n\n**Reference:** `references/requesting-code-review.md`\n\n### Verification Gates\nTrigger when:\n- About to claim tests pass, build succeeds, or work is complete\n- Before committing, pushing, or creating PRs\n- Moving to next task\n- Any statement suggesting success/completion\n- Expressing satisfaction with work\n\n**Reference:** `references/verification-before-completion.md`\n\n## Quick Decision Tree\n\n```\nSITUATION?\nâ”‚\nâ”œâ”€ Received feedback\nâ”‚  â”œâ”€ Unclear items? â†’ STOP, ask for clarification first\nâ”‚  â”œâ”€ From human partner? â†’ Understand, then implement\nâ”‚  â””â”€ From external reviewer? â†’ Verify technically before implementing\nâ”‚\nâ”œâ”€ Completed work\nâ”‚  â”œâ”€ Major feature/task? â†’ Request code-reviewer subagent review\nâ”‚  â””â”€ Before merge? â†’ Request code-reviewer subagent review"
  },
  {
    "id": "claude-code",
    "name": "claude-code",
    "description": "Claude Code is Anthropic's agentic coding tool that lives in the terminal and helps turn ideas into code faster. It combines autonomous planning, execution, and validation with extensibility through skills, plugins, MCP servers, and hooks. Use when users need help with: - Understanding Claude Code f",
    "category": "tools",
    "source": "claudekit",
    "triggers": [
      "claude",
      "code",
      "anthropic",
      "agentic",
      "coding",
      "tool",
      "lives",
      "terminal",
      "turn",
      "ideas"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/claude-code",
    "fullDescription": "# Claude Code Expert\n\nClaude Code is Anthropic's agentic coding tool that lives in the terminal and helps turn ideas into code faster. It combines autonomous planning, execution, and validation with extensibility through skills, plugins, MCP servers, and hooks.\n\n## When to Use This Skill\n\nUse when users need help with:\n- Understanding Claude Code features and capabilities\n- Installation, setup, and authentication\n- Using slash commands for development workflows\n- Creating or managing Agent Skills\n- Configuring MCP servers for external tool integration\n- Setting up hooks and plugins\n- Troubleshooting Claude Code issues\n- Enterprise deployment (SSO, sandboxing, monitoring)\n- IDE integration (VS Code, JetBrains)\n- CI/CD integration (GitHub Actions, GitLab)\n- Advanced features (extended thinking, caching, checkpointing)\n- Cost tracking and optimization\n\n**Activation examples:**\n- \"How do I use Claude Code?\"\n- \"What slash commands are available?\"\n- \"How to set up MCP servers?\"\n- \"Create a new skill for X\"\n- \"Fix Claude Code authentication issues\"\n- \"Deploy Claude Code in enterprise environment\"\n\n## Core Architecture\n\n**Subagents**: Specialized AI agents (planner, code-reviewer, tester, debugger, docs-manager, ui-ux-designer, database-admin, etc.)\n\n**Agent Skills**: Modular capabilities with instructions, metadata, and resources that Claude uses automatically\n\n**Slash Commands**: User-defined operations in `.claude/commands/` that expand to prompts\n\n**Hooks**: Shell commands executing in response to events (pre/post-tool, user-prompt-submit)\n\n**MCP Servers**: Model Context Protocol integrations connecting external tools and services\n\n**Plugins**: Packaged collections of commands, skills, hooks, and MCP servers\n\n## Quick Reference\n\nLoad these references when needed for detailed guidance:\n\n### Getting Started\n- **Installation & Setup**: `references/getting-started.md`\n  - Prerequisites, installation methods, authentication, first run\n\n### Development Workflows\n- **Slash Com"
  },
  {
    "id": "chrome-devtools",
    "name": "chrome-devtools",
    "description": "Browser automation, debugging, and performance analysis using Puppeteer CLI scripts. Use for automating browsers, taking screenshots, analyzing performance, monitoring network traffic, web scraping, form automation, and JavaScript debugging.",
    "category": "lab-automation",
    "source": "claudekit",
    "triggers": [
      "chrome",
      "devtools",
      "automation",
      "debugging",
      "performance",
      "browser",
      "puppeteer",
      "cli",
      "scripts",
      "automating"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/chrome-devtools",
    "fullDescription": "\n# Chrome DevTools Agent Skill\n\nBrowser automation via executable Puppeteer scripts. All scripts output JSON for easy parsing.\n\n## Quick Start\n\n**CRITICAL**: Always check `pwd` before running scripts.\n\n### Installation\n\n#### Step 1: Install System Dependencies (Linux/WSL only)\n\nOn Linux/WSL, Chrome requires system libraries. Install them first:\n\n```bash\npwd  # Should show current working directory\ncd .claude/skills/chrome-devtools/scripts\n./install-deps.sh  # Auto-detects OS and installs required libs\n```\n\nSupports: Ubuntu, Debian, Fedora, RHEL, CentOS, Arch, Manjaro\n\n**macOS/Windows**: Skip this step (dependencies bundled with Chrome)\n\n#### Step 2: Install Node Dependencies\n\n```bash\nnpm install  # Installs puppeteer, debug, yargs\n```\n\n#### Step 3: Install ImageMagick (Optional, Recommended)\n\nImageMagick enables automatic screenshot compression to keep files under 5MB:\n\n**macOS:**\n```bash\nbrew install imagemagick\n```\n\n**Ubuntu/Debian/WSL:**\n```bash\nsudo apt-get install imagemagick\n```\n\n**Verify:**\n```bash\nmagick -version  # or: convert -version\n```\n\nWithout ImageMagick, screenshots >5MB will not be compressed (may fail to load in Gemini/Claude).\n\n### Test\n```bash\nnode navigate.js --url https://example.com\n# Output: {\"success\": true, \"url\": \"https://example.com\", \"title\": \"Example Domain\"}\n```\n\n## Available Scripts\n\nAll scripts are in `.claude/skills/chrome-devtools/scripts/`\n\n**CRITICAL**: Always check `pwd` before running scripts.\n\n### Script Usage\n- `./scripts/README.md`\n\n### Core Automation\n- `navigate.js` - Navigate to URLs\n- `screenshot.js` - Capture screenshots (full page or element)\n- `click.js` - Click elements\n- `fill.js` - Fill form fields\n- `evaluate.js` - Execute JavaScript in page context\n\n### Analysis & Monitoring\n- `snapshot.js` - Extract interactive elements with metadata\n- `console.js` - Monitor console messages/errors\n- `network.js` - Track HTTP requests/responses\n- `performance.js` - Measure Core Web Vitals + record traces\n\n## Usage Patterns\n\n### "
  },
  {
    "id": "better-auth",
    "name": "better-auth",
    "description": "Implement authentication and authorization with Better Auth - a framework-agnostic TypeScript authentication framework. Features include email/password authentication with verification, OAuth providers (Google, GitHub, Discord, etc.), two-factor authentication (TOTP, SMS), passkeys/WebAuthn support,",
    "category": "sci-databases",
    "source": "claudekit",
    "triggers": [
      "better",
      "auth",
      "authentication",
      "authorization",
      "oauth",
      "applications",
      "framework-agnostic",
      "typescript",
      "email",
      "password"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/better-auth",
    "fullDescription": "\n# Better Auth Skill\n\nBetter Auth is comprehensive, framework-agnostic authentication/authorization framework for TypeScript with built-in email/password, social OAuth, and powerful plugin ecosystem for advanced features.\n\n## When to Use\n\n- Implementing auth in TypeScript/JavaScript applications\n- Adding email/password or social OAuth authentication\n- Setting up 2FA, passkeys, magic links, advanced auth features\n- Building multi-tenant apps with organization support\n- Managing sessions and user lifecycle\n- Working with any framework (Next.js, Nuxt, SvelteKit, Remix, Astro, Hono, Express, etc.)\n\n## Quick Start\n\n### Installation\n\n```bash\nnpm install better-auth\n# or pnpm/yarn/bun add better-auth\n```\n\n### Environment Setup\n\nCreate `.env`:\n```env\nBETTER_AUTH_SECRET=<generated-secret-32-chars-min>\nBETTER_AUTH_URL=http://localhost:3000\n```\n\n### Basic Server Setup\n\nCreate `auth.ts` (root, lib/, utils/, or under src/app/server/):\n\n```ts\nimport { betterAuth } from \"better-auth\";\n\nexport const auth = betterAuth({\n  database: {\n    // See references/database-integration.md\n  },\n  emailAndPassword: {\n    enabled: true,\n    autoSignIn: true\n  },\n  socialProviders: {\n    github: {\n      clientId: process.env.GITHUB_CLIENT_ID!,\n      clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n    }\n  }\n});\n```\n\n### Database Schema\n\n```bash\nnpx @better-auth/cli generate  # Generate schema/migrations\nnpx @better-auth/cli migrate   # Apply migrations (Kysely only)\n```\n\n### Mount API Handler\n\n**Next.js App Router:**\n```ts\n// app/api/auth/[...all]/route.ts\nimport { auth } from \"@/lib/auth\";\nimport { toNextJsHandler } from \"better-auth/next-js\";\n\nexport const { POST, GET } = toNextJsHandler(auth);\n```\n\n**Other frameworks:** See references/email-password-auth.md#framework-setup\n\n### Client Setup\n\nCreate `auth-client.ts`:\n\n```ts\nimport { createAuthClient } from \"better-auth/client\";\n\nexport const authClient = createAuthClient({\n  baseURL: process.env.NEXT_PUBLIC_BETTER_AUTH_URL || \"http://localhost:"
  },
  {
    "id": "aesthetic",
    "name": "aesthetic",
    "description": "Create aesthetically beautiful interfaces following proven design principles. Use when building UI/UX, analyzing designs from inspiration sites, generating design images with ai-multimodal, implementing visual hierarchy and color theory, adding micro-interactions, or creating design documentation. I",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "aesthetic",
      "design",
      "ai-multimodal",
      "beautiful",
      "principles",
      "analyzing",
      "inspiration",
      "micro-interactions",
      "chrome-devtools",
      "aesthetically"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/aesthetic",
    "fullDescription": "\n# Aesthetic\n\nCreate aesthetically beautiful interfaces by following proven design principles and systematic workflows.\n\n## When to Use This Skill\n\nUse when:\n- Building or designing user interfaces\n- Analyzing designs from inspiration websites (Dribbble, Mobbin, Behance)\n- Generating design images and evaluating aesthetic quality\n- Implementing visual hierarchy, typography, color theory\n- Adding micro-interactions and animations\n- Creating design documentation and style guides\n- Need guidance on accessibility and design systems\n\n## Core Framework: Four-Stage Approach\n\n### 1. BEAUTIFUL: Understanding Aesthetics\nStudy existing designs, identify patterns, extract principles. AI lacks aesthetic senseâ€”standards must come from analyzing high-quality examples and aligning with market tastes.\n\n**Reference**: [`references/design-principles.md`](references/design-principles.md) - Visual hierarchy, typography, color theory, white space principles.\n\n### 2. RIGHT: Ensuring Functionality\nBeautiful designs lacking usability are worthless. Study design systems, component architecture, accessibility requirements.\n\n**Reference**: [`references/design-principles.md`](references/design-principles.md) - Design systems, component libraries, WCAG accessibility standards.\n\n### 3. SATISFYING: Micro-Interactions\nIncorporate subtle animations with appropriate timing (150-300ms), easing curves (ease-out for entry, ease-in for exit), sequential delays.\n\n**Reference**: [`references/micro-interactions.md`](references/micro-interactions.md) - Duration guidelines, easing curves, performance optimization.\n\n### 4. PEAK: Storytelling Through Design\nElevate with narrative elementsâ€”parallax effects, particle systems, thematic consistency. Use restraint: \"too much of anything isn't good.\"\n\n**Reference**: [`references/storytelling-design.md`](references/storytelling-design.md) - Narrative elements, scroll-based storytelling, interactive techniques.\n\n## Workflows\n\n### Workflow 1: Capture & Analyze Inspirati"
  },
  {
    "id": "backend-development",
    "name": "backend-development",
    "description": "Build robust backend systems with modern technologies (Node.js, Python, Go, Rust), frameworks (NestJS, FastAPI, Django), databases (PostgreSQL, MongoDB, Redis), APIs (REST, GraphQL, gRPC), authentication (OAuth 2.1, JWT), testing strategies, security best practices (OWASP Top 10), performance optimi",
    "category": "sci-databases",
    "source": "claudekit",
    "triggers": [
      "backend",
      "development",
      "systems",
      "apis",
      "authentication",
      "security",
      "practices",
      "microservices",
      "robust",
      "modern"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/backend-development",
    "fullDescription": "\n# Backend Development Skill\n\nProduction-ready backend development with modern technologies, best practices, and proven patterns.\n\n## When to Use\n\n- Designing RESTful, GraphQL, or gRPC APIs\n- Building authentication/authorization systems\n- Optimizing database queries and schemas\n- Implementing caching and performance optimization\n- OWASP Top 10 security mitigation\n- Designing scalable microservices\n- Testing strategies (unit, integration, E2E)\n- CI/CD pipelines and deployment\n- Monitoring and debugging production systems\n\n## Technology Selection Guide\n\n**Languages:** Node.js/TypeScript (full-stack), Python (data/ML), Go (concurrency), Rust (performance)\n**Frameworks:** NestJS, FastAPI, Django, Express, Gin\n**Databases:** PostgreSQL (ACID), MongoDB (flexible schema), Redis (caching)\n**APIs:** REST (simple), GraphQL (flexible), gRPC (performance)\n\nSee: `references/backend-technologies.md` for detailed comparisons\n\n## Reference Navigation\n\n**Core Technologies:**\n- `backend-technologies.md` - Languages, frameworks, databases, message queues, ORMs\n- `backend-api-design.md` - REST, GraphQL, gRPC patterns and best practices\n\n**Security & Authentication:**\n- `backend-security.md` - OWASP Top 10 2025, security best practices, input validation\n- `backend-authentication.md` - OAuth 2.1, JWT, RBAC, MFA, session management\n\n**Performance & Architecture:**\n- `backend-performance.md` - Caching, query optimization, load balancing, scaling\n- `backend-architecture.md` - Microservices, event-driven, CQRS, saga patterns\n\n**Quality & Operations:**\n- `backend-testing.md` - Testing strategies, frameworks, tools, CI/CD testing\n- `backend-code-quality.md` - SOLID principles, design patterns, clean code\n- `backend-devops.md` - Docker, Kubernetes, deployment strategies, monitoring\n- `backend-debugging.md` - Debugging strategies, profiling, logging, production debugging\n- `backend-mindset.md` - Problem-solving, architectural thinking, collaboration\n\n## Key Best Practices (2025)\n\n**Security:** "
  },
  {
    "id": "ai-multimodal",
    "name": "ai-multimodal",
    "description": "Process and generate multimedia content using Google Gemini API. Capabilities include analyze audio files (transcription with timestamps, summarization, speech understanding, music/sound analysis up to 9.5 hours), understand images (captioning, object detection, OCR, visual Q&A, segmentation), proce",
    "category": "ml-ai",
    "source": "claudekit",
    "triggers": [
      "multimodal",
      "images",
      "process",
      "generate",
      "gemini",
      "audio",
      "hours",
      "detection",
      "documents",
      "pdf"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/ai-multimodal",
    "fullDescription": "\n# AI Multimodal Processing Skill\n\nProcess audio, images, videos, documents, and generate images using Google Gemini's multimodal API. Unified interface for all multimedia content understanding and generation.\n\n## Core Capabilities\n\n### Audio Processing\n- Transcription with timestamps (up to 9.5 hours)\n- Audio summarization and analysis\n- Speech understanding and speaker identification\n- Music and environmental sound analysis\n- Text-to-speech generation with controllable voice\n\n### Image Understanding\n- Image captioning and description\n- Object detection with bounding boxes (2.0+)\n- Pixel-level segmentation (2.5+)\n- Visual question answering\n- Multi-image comparison (up to 3,600 images)\n- OCR and text extraction\n\n### Video Analysis\n- Scene detection and summarization\n- Video Q&A with temporal understanding\n- Transcription with visual descriptions\n- YouTube URL support\n- Long video processing (up to 6 hours)\n- Frame-level analysis\n\n### Document Extraction\n- Native PDF vision processing (up to 1,000 pages)\n- Table and form extraction\n- Chart and diagram analysis\n- Multi-page document understanding\n- Structured data output (JSON schema)\n- Format conversion (PDF to HTML/JSON)\n\n### Image Generation\n- Text-to-image generation\n- Image editing and modification\n- Multi-image composition (up to 3 images)\n- Iterative refinement\n- Multiple aspect ratios (1:1, 16:9, 9:16, 4:3, 3:4)\n- Controllable style and quality\n\n## Capability Matrix\n\n| Task | Audio | Image | Video | Document | Generation |\n|------|:-----:|:-----:|:-----:|:--------:|:----------:|\n| Transcription | âœ“ | - | âœ“ | - | - |\n| Summarization | âœ“ | âœ“ | âœ“ | âœ“ | - |\n| Q&A | âœ“ | âœ“ | âœ“ | âœ“ | - |\n| Object Detection | - | âœ“ | âœ“ | - | - |\n| Text Extraction | - | âœ“ | - | âœ“ | - |\n| Structured Output | âœ“ | âœ“ | âœ“ | âœ“ | - |\n| Creation | TTS | - | - | - | âœ“ |\n| Timestamps | âœ“ | - | âœ“ | - | - |\n| Segmentation | - | âœ“ | - | - | - |\n\n## Model Selection Guide\n\n### Gemini 2.5 Series (Recommended)\n- **gemini-2.5-pro**: Highest quality, al"
  },
  {
    "id": "when-stuck---problem-solving-dispatch",
    "name": "When Stuck - Problem-Solving Dispatch",
    "description": "Dispatch to the right problem-solving technique based on how you're stuck",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "stuck",
      "problem",
      "solving",
      "dispatch",
      "problem-solving",
      "right",
      "technique"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/when-stuck",
    "fullDescription": "\n# When Stuck - Problem-Solving Dispatch\n\n## Overview\n\nDifferent stuck-types need different techniques. This skill helps you quickly identify which problem-solving skill to use.\n\n**Core principle:** Match stuck-symptom to technique.\n\n## Quick Dispatch\n\n```dot\ndigraph stuck_dispatch {\n    rankdir=TB;\n    node [shape=box, style=rounded];\n\n    stuck [label=\"You're Stuck\", shape=ellipse, style=filled, fillcolor=lightblue];\n\n    complexity [label=\"Same thing implemented 5+ ways?\\nGrowing special cases?\\nExcessive if/else?\"];\n    innovation [label=\"Can't find fitting approach?\\nConventional solutions inadequate?\\nNeed breakthrough?\"];\n    patterns [label=\"Same issue in different places?\\nFeels familiar across domains?\\nReinventing wheels?\"];\n    assumptions [label=\"Solution feels forced?\\n'This must be done this way'?\\nStuck on assumptions?\"];\n    scale [label=\"Will this work at production?\\nEdge cases unclear?\\nUnsure of limits?\"];\n    bugs [label=\"Code behaving wrong?\\nTest failing?\\nUnexpected output?\"];\n\n    stuck -> complexity;\n    stuck -> innovation;\n    stuck -> patterns;\n    stuck -> assumptions;\n    stuck -> scale;\n    stuck -> bugs;\n\n    complexity -> simp [label=\"yes\"];\n    innovation -> collision [label=\"yes\"];\n    patterns -> meta [label=\"yes\"];\n    assumptions -> invert [label=\"yes\"];\n    scale -> scale_skill [label=\"yes\"];\n    bugs -> debug [label=\"yes\"];\n\n    simp [label=\"skills/problem-solving/\\nsimplification-cascades\", shape=box, style=\"rounded,filled\", fillcolor=lightgreen];\n    collision [label=\"skills/problem-solving/\\ncollision-zone-thinking\", shape=box, style=\"rounded,filled\", fillcolor=lightgreen];\n    meta [label=\"skills/problem-solving/\\nmeta-pattern-recognition\", shape=box, style=\"rounded,filled\", fillcolor=lightgreen];\n    invert [label=\"skills/problem-solving/\\ninversion-exercise\", shape=box, style=\"rounded,filled\", fillcolor=lightgreen];\n    scale_skill [label=\"skills/problem-solving/\\nscale-game\", shape=box, style=\"rounded,filled\", fillcol"
  },
  {
    "id": "simplification-cascades",
    "name": "Simplification Cascades",
    "description": "Find one insight that eliminates multiple components - \"if this is true, we don't need X, Y, or Z\"",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "simplification",
      "cascades",
      "find",
      "insight",
      "eliminates",
      "components",
      "true"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/simplification-cascades",
    "fullDescription": "\n# Simplification Cascades\n\n## Overview\n\nSometimes one insight eliminates 10 things. Look for the unifying principle that makes multiple components unnecessary.\n\n**Core principle:** \"Everything is a special case of...\" collapses complexity dramatically.\n\n## Quick Reference\n\n| Symptom | Likely Cascade |\n|---------|----------------|\n| Same thing implemented 5+ ways | Abstract the common pattern |\n| Growing special case list | Find the general case |\n| Complex rules with exceptions | Find the rule that has no exceptions |\n| Excessive config options | Find defaults that work for 95% |\n\n## The Pattern\n\n**Look for:**\n- Multiple implementations of similar concepts\n- Special case handling everywhere\n- \"We need to handle A, B, C, D differently...\"\n- Complex rules with many exceptions\n\n**Ask:** \"What if they're all the same thing underneath?\"\n\n## Examples\n\n### Cascade 1: Stream Abstraction\n**Before:** Separate handlers for batch/real-time/file/network data\n**Insight:** \"All inputs are streams - just different sources\"\n**After:** One stream processor, multiple stream sources\n**Eliminated:** 4 separate implementations\n\n### Cascade 2: Resource Governance\n**Before:** Session tracking, rate limiting, file validation, connection pooling (all separate)\n**Insight:** \"All are per-entity resource limits\"\n**After:** One ResourceGovernor with 4 resource types\n**Eliminated:** 4 custom enforcement systems\n\n### Cascade 3: Immutability\n**Before:** Defensive copying, locking, cache invalidation, temporal coupling\n**Insight:** \"Treat everything as immutable data + transformations\"\n**After:** Functional programming patterns\n**Eliminated:** Entire classes of synchronization problems\n\n## Process\n\n1. **List the variations** - What's implemented multiple ways?\n2. **Find the essence** - What's the same underneath?\n3. **Extract abstraction** - What's the domain-independent pattern?\n4. **Test it** - Do all cases fit cleanly?\n5. **Measure cascade** - How many things become unnecessary?\n\n## Red Flags Yo"
  },
  {
    "id": "scale-game",
    "name": "Scale Game",
    "description": "Test at extremes (1000x bigger/smaller, instant/year-long) to expose fundamental truths hidden at normal scales",
    "category": "testing",
    "source": "claudekit",
    "triggers": [
      "scale",
      "game",
      "test",
      "extremes",
      "1000x",
      "bigger",
      "smaller",
      "instant",
      "year-long",
      "expose"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/scale-game",
    "fullDescription": "\n# Scale Game\n\n## Overview\n\nTest your approach at extreme scales to find what breaks and what surprisingly survives.\n\n**Core principle:** Extremes expose fundamental truths hidden at normal scales.\n\n## Quick Reference\n\n| Scale Dimension | Test At Extremes | What It Reveals |\n|-----------------|------------------|-----------------|\n| Volume | 1 item vs 1B items | Algorithmic complexity limits |\n| Speed | Instant vs 1 year | Async requirements, caching needs |\n| Users | 1 user vs 1B users | Concurrency issues, resource limits |\n| Duration | Milliseconds vs years | Memory leaks, state growth |\n| Failure rate | Never fails vs always fails | Error handling adequacy |\n\n## Process\n\n1. **Pick dimension** - What could vary extremely?\n2. **Test minimum** - What if this was 1000x smaller/faster/fewer?\n3. **Test maximum** - What if this was 1000x bigger/slower/more?\n4. **Note what breaks** - Where do limits appear?\n5. **Note what survives** - What's fundamentally sound?\n\n## Examples\n\n### Example 1: Error Handling\n**Normal scale:** \"Handle errors when they occur\" works fine\n**At 1B scale:** Error volume overwhelms logging, crashes system\n**Reveals:** Need to make errors impossible (type systems) or expect them (chaos engineering)\n\n### Example 2: Synchronous APIs\n**Normal scale:** Direct function calls work\n**At global scale:** Network latency makes synchronous calls unusable\n**Reveals:** Async/messaging becomes survival requirement, not optimization\n\n### Example 3: In-Memory State\n**Normal duration:** Works for hours/days\n**At years:** Memory grows unbounded, eventual crash\n**Reveals:** Need persistence or periodic cleanup, can't rely on memory\n\n## Red Flags You Need This\n\n- \"It works in dev\" (but will it work in production?)\n- No idea where limits are\n- \"Should scale fine\" (without testing)\n- Surprised by production behavior\n\n## Remember\n\n- Extremes reveal fundamentals\n- What works at one scale fails at another\n- Test both directions (bigger AND smaller)\n- Use insights to valid"
  },
  {
    "id": "meta-pattern-recognition",
    "name": "Meta-Pattern Recognition",
    "description": "Spot patterns appearing in 3+ domains to find universal principles",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "meta",
      "pattern",
      "recognition",
      "spot",
      "patterns",
      "appearing",
      "domains",
      "find",
      "universal",
      "principles"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/meta-pattern-recognition",
    "fullDescription": "\n# Meta-Pattern Recognition\n\n## Overview\n\nWhen the same pattern appears in 3+ domains, it's probably a universal principle worth extracting.\n\n**Core principle:** Find patterns in how patterns emerge.\n\n## Quick Reference\n\n| Pattern Appears In | Abstract Form | Where Else? |\n|-------------------|---------------|-------------|\n| CPU/DB/HTTP/DNS caching | Store frequently-accessed data closer | LLM prompt caching, CDN |\n| Layering (network/storage/compute) | Separate concerns into abstraction levels | Architecture, organization |\n| Queuing (message/task/request) | Decouple producer from consumer with buffer | Event systems, async processing |\n| Pooling (connection/thread/object) | Reuse expensive resources | Memory management, resource governance |\n\n## Process\n\n1. **Spot repetition** - See same shape in 3+ places\n2. **Extract abstract form** - Describe independent of any domain\n3. **Identify variations** - How does it adapt per domain?\n4. **Check applicability** - Where else might this help?\n\n## Example\n\n**Pattern spotted:** Rate limiting in API throttling, traffic shaping, circuit breakers, admission control\n\n**Abstract form:** Bound resource consumption to prevent exhaustion\n\n**Variation points:** What resource, what limit, what happens when exceeded\n\n**New application:** LLM token budgets (same pattern - prevent context window exhaustion)\n\n## Red Flags You're Missing Meta-Patterns\n\n- \"This problem is unique\" (probably not)\n- Multiple teams independently solving \"different\" problems identically\n- Reinventing wheels across domains\n- \"Haven't we done something like this?\" (yes, find it)\n\n## Remember\n\n- 3+ domains = likely universal\n- Abstract form reveals new applications\n- Variations show adaptation points\n- Universal patterns are battle-tested\n"
  },
  {
    "id": "inversion-exercise",
    "name": "Inversion Exercise",
    "description": "Flip core assumptions to reveal hidden constraints and alternative approaches - \"what if the opposite were true?\"",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "inversion",
      "exercise",
      "flip",
      "core",
      "assumptions",
      "reveal",
      "hidden",
      "constraints",
      "alternative",
      "approaches"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/inversion-exercise",
    "fullDescription": "\n# Inversion Exercise\n\n## Overview\n\nFlip every assumption and see what still works. Sometimes the opposite reveals the truth.\n\n**Core principle:** Inversion exposes hidden assumptions and alternative approaches.\n\n## Quick Reference\n\n| Normal Assumption | Inverted | What It Reveals |\n|-------------------|----------|-----------------|\n| Cache to reduce latency | Add latency to enable caching | Debouncing patterns |\n| Pull data when needed | Push data before needed | Prefetching, eager loading |\n| Handle errors when occur | Make errors impossible | Type systems, contracts |\n| Build features users want | Remove features users don't need | Simplicity >> addition |\n| Optimize for common case | Optimize for worst case | Resilience patterns |\n\n## Process\n\n1. **List core assumptions** - What \"must\" be true?\n2. **Invert each systematically** - \"What if opposite were true?\"\n3. **Explore implications** - What would we do differently?\n4. **Find valid inversions** - Which actually work somewhere?\n\n## Example\n\n**Problem:** Users complain app is slow\n\n**Normal approach:** Make everything faster (caching, optimization, CDN)\n\n**Inverted:** Make things intentionally slower in some places\n- Debounce search (add latency â†’ enable better results)\n- Rate limit requests (add friction â†’ prevent abuse)\n- Lazy load content (delay â†’ reduce initial load)\n\n**Insight:** Strategic slowness can improve UX\n\n## Red Flags You Need This\n\n- \"There's only one way to do this\"\n- Forcing solution that feels wrong\n- Can't articulate why approach is necessary\n- \"This is just how it's done\"\n\n## Remember\n\n- Not all inversions work (test boundaries)\n- Valid inversions reveal context-dependence\n- Sometimes opposite is the answer\n- Question \"must be\" statements\n"
  },
  {
    "id": "collision-zone-thinking",
    "name": "Collision-Zone Thinking",
    "description": "Force unrelated concepts together to discover emergent properties - \"What if we treated X like Y?\"",
    "category": "thinking",
    "source": "claudekit",
    "triggers": [
      "collision",
      "zone",
      "thinking",
      "force",
      "unrelated",
      "concepts",
      "together",
      "discover",
      "emergent",
      "properties"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/problem-solving/collision-zone-thinking",
    "fullDescription": "\n# Collision-Zone Thinking\n\n## Overview\n\nRevolutionary insights come from forcing unrelated concepts to collide. Treat X like Y and see what emerges.\n\n**Core principle:** Deliberate metaphor-mixing generates novel solutions.\n\n## Quick Reference\n\n| Stuck On | Try Treating As | Might Discover |\n|----------|-----------------|----------------|\n| Code organization | DNA/genetics | Mutation testing, evolutionary algorithms |\n| Service architecture | Lego bricks | Composable microservices, plug-and-play |\n| Data management | Water flow | Streaming, data lakes, flow-based systems |\n| Request handling | Postal mail | Message queues, async processing |\n| Error handling | Circuit breakers | Fault isolation, graceful degradation |\n\n## Process\n\n1. **Pick two unrelated concepts** from different domains\n2. **Force combination**: \"What if we treated [A] like [B]?\"\n3. **Explore emergent properties**: What new capabilities appear?\n4. **Test boundaries**: Where does the metaphor break?\n5. **Extract insight**: What did we learn?\n\n## Example Collision\n\n**Problem:** Complex distributed system with cascading failures\n\n**Collision:** \"What if we treated services like electrical circuits?\"\n\n**Emergent properties:**\n- Circuit breakers (disconnect on overload)\n- Fuses (one-time failure protection)\n- Ground faults (error isolation)\n- Load balancing (current distribution)\n\n**Where it works:** Preventing cascade failures\n**Where it breaks:** Circuits don't have retry logic\n**Insight gained:** Failure isolation patterns from electrical engineering\n\n## Red Flags You Need This\n\n- \"I've tried everything in this domain\"\n- Solutions feel incremental, not breakthrough\n- Stuck in conventional thinking\n- Need innovation, not optimization\n\n## Remember\n\n- Wild combinations often yield best insights\n- Test metaphor boundaries rigorously\n- Document even failed collisions (they teach)\n- Best source domains: physics, biology, economics, psychology\n"
  },
  {
    "id": "root-cause-tracing",
    "name": "Root Cause Tracing",
    "description": "Systematically trace bugs backward through call stack to find original trigger",
    "category": "skill-dev",
    "source": "claudekit",
    "triggers": [
      "root",
      "cause",
      "tracing",
      "systematically",
      "trace",
      "bugs",
      "backward",
      "call",
      "stack",
      "find"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/debugging/root-cause-tracing",
    "fullDescription": "\n# Root Cause Tracing\n\n## Overview\n\nBugs often manifest deep in the call stack (git init in wrong directory, file created in wrong location, database opened with wrong path). Your instinct is to fix where the error appears, but that's treating a symptom.\n\n**Core principle:** Trace backward through the call chain until you find the original trigger, then fix at the source.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Bug appears deep in stack?\" [shape=diamond];\n    \"Can trace backwards?\" [shape=diamond];\n    \"Fix at symptom point\" [shape=box];\n    \"Trace to original trigger\" [shape=box];\n    \"BETTER: Also add defense-in-depth\" [shape=box];\n\n    \"Bug appears deep in stack?\" -> \"Can trace backwards?\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Trace to original trigger\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Fix at symptom point\" [label=\"no - dead end\"];\n    \"Trace to original trigger\" -> \"BETTER: Also add defense-in-depth\";\n}\n```\n\n**Use when:**\n- Error happens deep in execution (not at entry point)\n- Stack trace shows long call chain\n- Unclear where invalid data originated\n- Need to find which test/code triggers the problem\n\n## The Tracing Process\n\n### 1. Observe the Symptom\n```\nError: git init failed in /Users/jesse/project/packages/core\n```\n\n### 2. Find Immediate Cause\n**What code directly causes this?**\n```typescript\nawait execFileAsync('git', ['init'], { cwd: projectDir });\n```\n\n### 3. Ask: What Called This?\n```typescript\nWorktreeManager.createSessionWorktree(projectDir, sessionId)\n  â†’ called by Session.initializeWorkspace()\n  â†’ called by Session.create()\n  â†’ called by test at Project.create()\n```\n\n### 4. Keep Tracing Up\n**What value was passed?**\n- `projectDir = ''` (empty string!)\n- Empty string as `cwd` resolves to `process.cwd()`\n- That's the source code directory!\n\n### 5. Find Original Trigger\n**Where did empty string come from?**\n```typescript\nconst context = setupCoreTest(); // Returns { tempDir: '' }\nProject.create('name', context.tempDir); "
  },
  {
    "id": "defense-in-depth-validation",
    "name": "Defense-in-Depth Validation",
    "description": "Validate at every layer data passes through to make bugs impossible",
    "category": "skill-dev",
    "source": "claudekit",
    "triggers": [
      "defense",
      "depth",
      "validation",
      "validate",
      "layer",
      "passes",
      "bugs",
      "impossible",
      "defense-in-depth"
    ],
    "path": "/Users/marovole/GitHub/fastskills/claudekit-skills/.claude/skills/debugging/defense-in-depth",
    "fullDescription": "\n# Defense-in-Depth Validation\n\n## Overview\n\nWhen you fix a bug caused by invalid data, adding validation at one place feels sufficient. But that single check can be bypassed by different code paths, refactoring, or mocks.\n\n**Core principle:** Validate at EVERY layer data passes through. Make the bug structurally impossible.\n\n## Why Multiple Layers\n\nSingle validation: \"We fixed the bug\"\nMultiple layers: \"We made the bug impossible\"\n\nDifferent layers catch different cases:\n- Entry validation catches most bugs\n- Business logic catches edge cases\n- Environment guards prevent context-specific dangers\n- Debug logging helps when other layers fail\n\n## The Four Layers\n\n### Layer 1: Entry Point Validation\n**Purpose:** Reject obviously invalid input at API boundary\n\n```typescript\nfunction createProject(name: string, workingDirectory: string) {\n  if (!workingDirectory || workingDirectory.trim() === '') {\n    throw new Error('workingDirectory cannot be empty');\n  }\n  if (!existsSync(workingDirectory)) {\n    throw new Error(`workingDirectory does not exist: ${workingDirectory}`);\n  }\n  if (!statSync(workingDirectory).isDirectory()) {\n    throw new Error(`workingDirectory is not a directory: ${workingDirectory}`);\n  }\n  // ... proceed\n}\n```\n\n### Layer 2: Business Logic Validation\n**Purpose:** Ensure data makes sense for this operation\n\n```typescript\nfunction initializeWorkspace(projectDir: string, sessionId: string) {\n  if (!projectDir) {\n    throw new Error('projectDir required for workspace initialization');\n  }\n  // ... proceed\n}\n```\n\n### Layer 3: Environment Guards\n**Purpose:** Prevent dangerous operations in specific contexts\n\n```typescript\nasync function gitInit(directory: string) {\n  // In tests, refuse git init outside temp directories\n  if (process.env.NODE_ENV === 'test') {\n    const normalized = normalize(resolve(directory));\n    const tmpDir = normalize(resolve(tmpdir()));\n\n    if (!normalized.startsWith(tmpDir)) {\n      throw new Error(\n        `Refusing git init out"
  }
]